%{author: "", text: "", title: "", url: "https://www.erlang-solutions.com/blog.html"}
%{author: "by Francesco Cesarini", text: "Welcome to our new blog!!2015-11-18\n        by Francesco Cesarini\n      Sharing has always been a big part of Erlang Solutions’ core value as a company, but for some reason we never got around to blogging. Maybe because we felt the Erlang community already had that covered. There are a lot of great Erlang bloggers out there, and they have been doing a great job at spreading the word to new users whilst aiding existing ones. If you have missed them, have a look here and here.From our end, we have been active organising and speaking at conferences, meetups, workshops and tutorials, giving lectures at universities, and hosting hackathons. Quite a few of us contribute to academic papers, journal entries, chapters and in some cases, even co-author books. But as Erlang Solutions keeps growing, we’re finding these channels aren’t enough to share everything we have to say. We work on diverse and often groundbreaking software systems, we develop our own products, and we participate in research projects – all these things expand our view on how Erlang is used, and what the future might hold. Our new website is the perfect excuse to give everyone at ESL a platform to continue the tradition of sharing, both amongst ourselves and with anyone that may be interested in what we’re keeping ourselves busy with everyday. Better late than never!We’re going to write about Erlang/OTP and a range of related topics, such as: how the Erlang ecosystem is opening up to new users; Elixir; Lisp Flavoured Erlang; Riak; RabbitMQ; Phoenix; the Internet of Things; XMPP and beyond. We’re also going to write about technology in general, development tools and practices, new products and tools within our company, and our developers will share their personal projects and preoccupations.So if you’re an existing Erlang developer, or interested in Erlang and Elixir, or simply want to find out more about ESL and what we’re all about, keep an eye on this blog. We’re open to suggestions, so join in the discussion in the comments, and tell us what you’d like to hear about.See you soon, FrancescoFounder and Technical DirectorGo back to the blog\n\nTags:introgeneralErlang OTPElixirPhoenixriakLFERabbitMQloTXMPPMongooseIMShare  Facebook Twitter Linkedin E-mail", title: "Welcome to our new blog!!", url: "https://www.erlang-solutions.com/blog/welcome-to-our-new-blog.html"}
%{author: "by Nicolas Vérité and Joseph Yasemides", text: "MongooseIM 1.6: Riak, DevOps love, and so much more!2015-11-25\n        by Nicolas Vérité and Joseph Yasemides\n      Most of the development work around MongooseIM is done by working closely with our clients. Many of the new features in MongooseIM 1.6 are the result of building and testing around particular client requirements. We are particularly excited about this release, as it means the beginning of an improved team dynamic, new high-value features, and many improvements.What’s new in MongooseIM 1.6Riak KVMongooseIM 1.6 introduces support for Riak - the scalable, fault-tolerant, distributed database written in Erlang. For this release, four modules can be configured with Riak, but more are on their way.Currently, MongooseIM supports Riak as a storage backend for:AuthenticationMessage Archive Management (MAM, XEP-0313) for one-to-one conversationsvCards (XEP-0054)Private XML storage (XEP-0049)This brings more flexibility in terms of database choice for any infrastructure, as you are free to choose between a RDBMS or NOSQL data store.Powerful metrics, DevOps loveVersion 1.6 offers very powerful metrics and monitoring infrastructure. For the underlying instrumentation, MongooseIM relies on Exometer. It reports OS-level and Erlang VM metrics, in addition to business metrics. You can then push those metrics to any ingesting and graphing system, such as Grafana or Kibana.This greatly improves DevOps’ visibility for managing systems, no matter the size of the installation. Other departments will benefit from having more data to dig into (big data, analytics), thus better understanding the end-users and eventually discovering new opportunities to improve UX, core competencies, and selling points.Additionally, we have improved how session data from the DB is cleaned up when a node goes down. It eases the support for more database backends in the future, and it brings better cluster handling for DevOps.Also, it is now possible to change log-level dynamically with a custom log path. For DevOps, once again, it helps consolidated logging for easier deployment, administration, and analysis.Get your own easy-to deploy Docker image of MongooseIM. As it is still experimental and will improve over time, please handle it with care: https://hub.docker.com/r/mongooseim/mongooseim-docker/. Give it a test drive, come back to us with feedback or questions and tell us and what you’d like to see in the future. Feel free to fork it from: https://github.com/ppikula/mongooseim-docker.Additional high value improvementsExtensive technical investment means we can continue to deliver a better MongooseIM with the Open Source community: we made changes to the core and integrated our test suite, the first of its kind, in the hope of seeing even more Open Source contribution.Selected improvements:Supported XEPs are now documented on https://github.com/esl/MongooseIMSubstantial refactoring: authentication mechanism, c2s, simplified MAMErlang/OTP 18 supportBetter RFC & XEP conformanceWe encourage everybody to review the release notes on GitHub.Coming up nextMongooseIM 1.6 will continue to bring many benefits such as: extensive and powerful business metrics, flexibility for DevOps, a rock-solid code base and stability for server and backend developers, more conformance for client developers, and extensive testing for all.1.6.x maintenance seriesWe will be working on a maintenance version, 1.6.1 (and perhaps a 1.6.2 later), with more complete Riak support, and of course the usual bug fixes, optimisations, and general improvements.1.7 and subsequent releasesThe development cycle for version 1.7 has already begun! We will focus on cloud, mobile, and testing. That is all we can share for now, but feel free to tell us what you think. We will also put more effort and commitment into making release schedules more predictable - in fact we already are.InvitationsBe the first to get informed!We have set up a new public mailing-list for all announcements of major events happening on the MongooseIM front. Expect one or two emails per month, the archives are free and op" <> ..., title: "MongooseIM 1.6: Riak, DevOps love, and so much more!", url: "https://www.erlang-solutions.com/blog/mongooseim-1-6-riak-devops-love-and-so-much-more.html"}
%{author: "by Michal Piotrowski and Nicolas Vérité", text: "XMPP Summit 19 & FOSDEM 2016: our thoughts2016-02-02\n        by Michal Piotrowski and Nicolas Vérité\n      We just got back from Brussels, where we had an amazing time at the XMPP Summit 19 which was held on 28th and 29th of January, and at FOSDEM on 30th and 31st. Erlang Solutions proudly represented the MongooseIM XMPP server through us: Michal Piotrowski, Tech Lead, and Nicolas Vérité, Product Owner. With all the excitement still fresh in our minds, we sat down and did a review of the most interesting things we saw and heard at the events.XMPP Summit 19Each XMPP Summit is an opportunity to talk face to face, which is always good for trust, understanding, and… social events. We had really in-depth, detailed discussions with all the XSF protocol experts, and came out with a few great insights.These points are all subject to existing, or future XEPs:MIX (see XEP-0369: Mediated Information eXchange (MIX)) is an upcoming, very flexible framework for a large variety of applications, including group chatE2E, for end-to-end encryption, wants to enable state-of-the-art encryptionPAM is the account model, which focuses more on the account (bare JID) than the client (full JID)We brought in the necessity of a faster and simplified client to server reconnectionWe will also draft a XEP around token authentication which we already have implemented in MongooseIM and will be part of 1.7 releaseSocial discussions have also been very productive:\n    We discovered the real value and importance of CSI (see XEP-0352: Client State Indication) which will be added to MongooseIM soonWe had very productive discussion around XMPP load balancing and how JID-based load balancing can be efficient by using undervalued from attribute in the opening stream header. We are going to implement this in escalus and amoc.XEP-0308: Last Message Correction should be made compatible with XEP-0313: Message Archive ManagementOverall, it has been an enlightenment for us, and we came back with loads of ideas on how to continue the progress on each item.FOSDEM 2016For us, the first day focus was the Real Time devroom.Our contribution was Nicolas’ talk: “The state of XMPP and instant messaging, The awakening”. Its aim was to present a market analysis: the three generations of Instant Messaging, and the ‘Trough of Disillusionment’. Also introducing our view on a few of the most important tasks that need to be done in the near future of XMPP messaging.FOSDEM 2016: The State of XMPP and Instant Messaging, The Awakening from Nyco We also enjoyed Matthew Wild’s talk, which had a lot of common denominators, such as the state of XMPP, and the actions to enhance the situation, outside the only scope of specifications.On Sunday, Daniel Pocock, who deployed XMPP servers for the Fedora and Debian communities, further enlarged the emerging vision to SIP and WebRTC, in the main track. He proposed to build a common mission statement, and a list of high-level requirements.One of our favourite features of FOSDEM was the real-world chatting with attendees while comfortably sitting on very large cushions in the Real Time lounge.Our shared impression of the two events is that globally, there is a massive wave of renewed energy coming from the XMPP community, but also from the free and open source software developers attending FOSDEM.Go back to the blog\n\nTags:XMPPMongooseIMFOSDEMBrusselsopen source softwareXMPP SummitMIMjabberShare  Facebook Twitter Linkedin E-mail", title: "XMPP Summit 19 & FOSDEM 2016: our thoughts", url: "https://www.erlang-solutions.com/blog/xmpp-summit-19-fosdem-2016-our-thoughts.html"}
%{author: "by Nicolas Vérité, Ludwik Bukowski, and Stefan Strigler", text: "MongooseIM 1.6.1 is released2016-01-18\n        by Nicolas Vérité, Ludwik Bukowski, and Stefan Strigler\n      MongooseIM 1.6.1 is releasedMongooseIM 1.6.1 is now out, and we are pretty happy with the work we’ve done. This release starts the maintenance series 1.6.x. MongooseIM 1.6.1 is about “more”: more Riak KV, more tests, more enhancements. Read below to find out what’s new.Riak KVWe extended the support for Riak KV by continuing the work with modules such as the roster (the XMPP contact list) and XEP-0012: Last Activity (a pretty venerable XEP!). Riak KV support for the remaining modules will be completed with release 1.6.2.TestsTest coverage has been significantly improved and extended with the latest release: admin module, encrypted S2S, C2S ciphers, ACL, inband registration. We already have a solid, clean code base but you can never have enough of a good thing, so test coverage brings you even more confidence.Enhancements and fixesMany bugs got smashed in 1.6.1. Furhermore, to show our love for DevOps we improved cleanup after a node’s death and added a new reliable API for JID manipulation.Final wordSpecial thanks to our contributors @ppikula and @dharamgollapudi. Everybody is welcome to suggest their ideas, so please don’t be shy!Read the MongooseIM Product page on our website. Or read the detailed changelog on GitHub, and check out the MongooseIM repository.Get the latest news: Subscribe to the announcements mailing-list.  Go back to the blog\n\nTags:mongooseim1.6.1MongooseIMmongooseim1.6riakRiakKVmongooseErlangXMPPDevOpsShare  Facebook Twitter Linkedin E-mail", title: "MongooseIM 1.6.1 is released", url: "https://www.erlang-solutions.com/blog/mongooseim-1-6-1-is-released.html"}
%{author: "by Marc Sugiyama", text: "Secure Shell for Your Erlang Node2016-01-14\n        by Marc Sugiyama\n      Secure Shell for Your Erlang NodeSay you want to connect to the shell of your Erlang node. It’s easy. You connect a remote shell from another Erlang node - if you’re on the same subnet - and know the cookie - and have Erlang installed. OK, maybe not that easy.How about connecting via ssh? You don’t need to know the cookie, you don’t need Erlang installed, and you can connect from anywhere.Here’s how you add an ssh server to your Erlang node.Unlocking the KeyWith Public Key Encryption (PKE) the cryptographic key has a private key and a public key. Messages encrypted with the public key can only be decrypted with the private key. You have to keep the private key secret but you can freely distribute the public key. It’s difficult (or at least very time consuming) to guess the private key from the public key which makes this kind of encryption secure.We’ll use PKE to control access to our Erlang node. Used this way, the client copies its public key onto the server. The client holds onto the corresponding private key. When connecting, ssh uses the public key of the client and the private key from the client to authenticate the client. The server also holds onto its own private key and copies its public key into the client’s known_host file. This way, the client can tell if it’s talking to the right host.ssh:daemon/[1,2,3]Starting the Erlang ssh daemon (sshd), the process that listens for ssh client connections, is easy. The ssh:daemon/[1,2,3]starts sshd. The hard part is getting it configured properly so it accepts connections from our clients.The key configuration parameters are:Port - the listener port numbersystem_dir - directory holding the host’s keysuser_dir - directory holding the authorized_keys fileIf you’re fmiliar with ssh on Unix/Linux systems, /etc/ssh is the same as system_dir and ~/.ssh on the server is the same as user_dir. For simplicity, we’ll use the same directory for user_dir and system_dir.You can also specify the functions that implement the interactive shell, but when not told otherwise, ssh:daemon/[1,2,3]uses the standard Erlang shell. That’s what we’ll do here.Creating keysFor this exercise, we’ll use a new public and private key rather than one you might already have in your ~/.ssh directory.$ mkdir ssh_client\n$ ssh-keygen -t rsa -f ssh_client/id_rsa\nGenerating public/private rsa key pair.\nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in ssh_client/id_rsa.\nYour public key has been saved in ssh_client/id_rsa.pub.\nThe key fingerprint is:\nSHA256:FzL7BUTwozLLhNrghMt5mEHsqKi/xcmMKNVEZuuXhwI me@My-MacBook-Pro.local\nThe key's randomart image is:\n[...]\nUse a blank passphrase so you won’t have to type a passphrase when you connect.Next we need public and private keys for the server.$ mkdir ssh_dir\n$ ssh-keygen -t rsa -f ssh_dir/ssh_host_rsa_key\nGenerating public/private rsa key pair.\nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in ssh_dir/ssh_host_rsa_key.\nYour public key has been saved in ssh_dir/ssh_host_rsa_key.pub.\nThe key fingerprint is:\nSHA256:NA6WEnFOLSIBBDHZGgx2zrAsVTwciA1f5pPToxmBdts me@My-MacBook-Pro.local\nThe key's randomart image is:\n[...]\nAgain, use a blank passphrase.Finally we need a authorized_keys file. Users who want to connect to our server put their client’s public key in the authorized_keys file. For the first key, you can just copy the public key you made in ssh_client into the authorized_keys file.% cp ssh_client/id_rsa.pub ssh_dir/authorized_keys\nTesting our setupTo test out our setup, we can start the ssh daemon from the Erlang shell:$ erl\nErlang/OTP 17 [erts-6.4] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false]\nEshell V6.4  (abort with ^G)\n1> ssh:start().\nok\n2> ssh:daemon(11111, [{system_dir, \"ssh_dir\"}, {user_dir, \"ssh_dir\"}]).\n{ok,<0.44.0>}\n3> \n11111 is the port number. We’ll use the same directory, ssh_dir for system_dir and user_dir.Then from another ter" <> ..., title: "Secure Shell for Your Erlang Node", url: "https://www.erlang-solutions.com/blog/secure-shell-for-your-erlang-node.html"}
%{author: "by Rafal Studnicki", text: "How to analyse a BEAM core dump?2016-01-26\n        by Rafal Studnicki\n      How to analyse a BEAM core dump?TL;DR It’s relatively easy to debug Erlang system by connecting to the Erlang VM with gdb. To see an example, click here.IntroductionHas this ever happened to you? You have your Erlang system running for a long time now and all of a sudden the BEAM process disappears on one of the nodes. In the OS logs you can see that the process was killed because of a segmentation fault, but besides that you have nothing. Obviously, you hadn’t been prepared for such a scenario and a core dump of the crashed process wasn’t generated. This has definitely happened to me (too many times), so now I don’t even start without enabling core dumps in the operating system, by setting ulimit -c unlimited. Now, after waiting (too long) for the segmentation fault to occur again, you ended up with a precious core.xxx file. But what’s next?A story of one core dumpIn this section I’m going to describe an example analysis of a core dump file, that was generated while load-testing MongooseIM. In fact that was the first core dump analysis I had ever done, and it was suprisingly successful (or it was just beginner’s luck). This is why no prior knowledge of gdb is necessary here. Still, you should understand how calling a function works (it’s using a stack), what pointers are and roughly how Erlang terms are built internally.Starting gdbLet’s assume that the generated core dump file was named core.1474. gdb is started simply by pointing it at the BEAM executable that generated the core dump file and the core dump file itself. It’s also useful to pass the directory with the source of the VM (the same version), the C level output will then be more comprehensible:gdb erts-6.3/bin/beam.smp -core core.14747 -d /home/azureuser/otp_src_17.4/erts/emulatorgdb should tell us what caused the crash and where in the code this has happened:Program terminated with signal 11, Segmentation fault.\n#0  do_minor (nobj=2, objv=0x7f209849e5c0, new_sz=233, p=0x7f20a36010d0) at beam/erl_gc.c:1095\n1095            val = *ptr;\nAs we can see, the segmentation fault happened in a piece of code that belongs to the garbage collector. gdb told us exactly in which function this happened, with what argument it was called and what line is reponsible. We can see clearly that the function tried to dereference an invalid pointer (ptr).Where does the pointer point?Considering we used only one command, we already know a lot. Now we just need to answer the question ‘what was the pointer and why was it corrupted’?Let’s start with the most basic gdb command: backtrace -which prints the current stacktrace. A more chatty version backtrace full also exists and prints values of local variables for each function.Here’s the output:(gdb) backtrace\n#0  do_minor (nobj=2, objv=0x7f209849e5c0, new_sz=233, p=0x7f20a36010d0) at beam/erl_gc.c:1095\n#1  minor_collection (recl=<synthetic pointer>, nobj=2, objv=0x7f209849e5c0, need=7, p=0x7f20a36010d0) at beam/erl_gc.c:876\n#2  erts_garbage_collect (p=0x7f20a36010d0, need=7, objv=0x7f209849e5c0, nobj=2) at beam/erl_gc.c:450\n#3  0x00000000005669bb in process_main () at x86_64-unknown-linux-gnu/opt/smp/beam_hot.h:47\n#4  0x000000000049c4b2 in sched_thread_func (vesdp=0x7f209b560a80) at beam/erl_process.c:7743\n#5  0x00000000005d5fc5 in thr_wrapper (vtwd=0x7fffa342fff0) at pthread/ethread.c:106\n#6  0x00007f20a6ee1df3 in start_thread (arg=0x7f20863b0700) at pthread_create.c:308\n#7  0x00007f20a6a071ad in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:113\nUnfortunately, this is not very helpful. On a positive note, we actually confirmed that the garbage collection has been triggered from inside the Erlang processes and then things went bad.BEAM gdb macrosWhat if we could print a similar thing, but not from the BEAM, C code standpoint, but for the Erlang process that caused the crash? It turns out that it is possible, thanks to the set of macros that are available in the Erlang VM source code. They allow to dump stack, heap, message queue, inspect Erlang terms in" <> ..., title: "How to analyse a BEAM core dump?", url: "https://www.erlang-solutions.com/blog/how-to-analyse-a-beam-core-dump.html"}
%{author: "by Radek Szymczyszyn", text: "Docs in the Shell2016-02-09\n        by Radek Szymczyszyn \n      TL;DR: To access module documentation in the Erlang shell use docsh.Docsh status update (29 June 2016): https://medium.com/@erszcz/docsh-status-update-117f39bb68df#.8ybao9k4mHi! I’m Radek Szymczyszyn, an Erlang dev. This is my first post here. You can also read it on Medium.For quite some time now I’ve been envying a few of Elixir’s features: protocols, a consistent standard library, the pipe operator, macros and online documentation (as in “when connected to a system”). Personally, I don’t like Elixir’s syntax, but I “love” it when people use this same argument as an excuse not to use Erlang. Joking apart, some of these features could be present in Erlang, but they are not yet.Therefore, I want to present you an idea which hopefully will alleviate one of Erlang’s deficiencies - the lack of shell-accessible docs, anywhere and everywhere a piece of code written in the language is deployed. So without further ado, here be Docs in the Shell or docsh for short:> recon:h().\nRecon, as a module, provides access to the high-level functionality contained in the Recon application.\n...\n> recon:h(get_state, 1).\nShorthand call to recon:get_state(PidTerm, 5000)\nok\n> recon:h(get_state, 2).\nFetch the internal state of an OTP process.\nCalls sys:get_state/2 directly in R16B01+, and fetches\nit dynamically on older versions of OTP.\nok\n>\nThough some may argue that a REPL or a language-specific shell is just a toy unsuitable for real work, or a learning tool at best, I dare to disagree. Using the Erlang shell we can inspect live production systems, trace system components, profile, initiate hot code reloading, and if a dire need arises, perform surgical cuts to solve performance or scalability emergencies.Fiddling in the shell is necessary when troubleshooting a system and docs for the system might not be available as manpages (for basically any library apart from OTP), or you might not have them installed, or the project documentation site is down, or you have a crappy connection, or you’re in an enterprise where the only host you can access is Jira and no regular internet access… Or simply none of the above is quick enough, or convenient enough, for checking the information you need: whether it’s ets:lookup(Tab, Key) or ets:lookup(Key, Tab). For me this is enough rationale for easy shell access to docs.To remind my future self and let you know of the intended project direction, I tried to clarify some goals:Provide added value to existing community projects and libraries as well as OTP. There are a number of tools I use daily and I’d like to equip them with shell doc access as frictionless and efficient as possible. These are community built Recon and Cowboy, but also the “batteries included” into OTP such as dbg, lists, and proplists.Require minimum fuss to enable this in a project. Either an erl_opts directive in rebar.config or inclusion of a single header file should be enough to embed docs, respectively, in all or select modules of a project.Elixir IEx doesn’t provide access to documentation for Erlang modules. If possible, make docsh-embedded documentation compatible with Elixir’s format for IEx to use.There are some issues outstanding - the first of them might be perpetual, I’m slightly afraid, the second one is definitely solvable, though I’m not convinced yet as to what the best approach would be:Different projects use disparate documentation formats and even OTP isn’t standardized on the issue - some modules have inline docs, some use external XML. Documentation extraction will require multiple converters from the various formats and maybe some heuristics to extract documentation not formatted according to any particular format at all. In the long run it would be ideal if the community converged to a single format.The storage format in use aims for compatibility with Elixir, but it’s not there yet. The docs aren’t stored as an ExDc chunkthe way Elixir does it, as it’s not possible to affect the layout of a .beam file at the parse tree transformation phase and that’s w" <> ..., title: "Docs in the Shell", url: "https://www.erlang-solutions.com/blog/docs-in-the-shell.html"}
%{author: "by Michal Piotrowski and Rafal Studnicki", text: "MongooseIM 1.6.2 is out. Time to upgrade!2016-03-22\n        by Michal Piotrowski and Rafal Studnicki\n      MongooseIM 1.6.2 is out. Time to upgrade!by Michał Piotrowski and Rafał StudnickiWe are pleased to announce the release of MongooseIM 1.6.2. This is last release in the 1.6.x family. Please read below to find out more about our demo, load tests and all the significant changes. We encourage everyone to upgrade.MongooseIM 1.6.2 is about “stability”: finished Riak for all major modules, docker-based demo, load test, improved tests, new enhancements.RiakWe finished our work on implementing missing Riak backends. Now all major functionalities like:authenticationlast_activitymessage archive for one-to-one and MUC conversation (MUC archive was added in this release)privateprivacy (added in this release)offline messages (added in this release)rostersvcardCan be configured to store data in Riak database.Docker-based demoThe use caseIn this demo we wanted to show, that cluster of MongooseIM nodes can handle node failures gracefully and users will be able to reconnect to remaining nodes in the cluster.Set upDuring Lambda Days we showed a MongooseIM demo built with docker containers. The set up was very simple:DNS server5 nodes cluster of MongooseIM 1.6.2HAProxy in front of all the nodesMySQL as the database backendGraphite/Grafana to collect all metricsFrom the MongooseIM/XMPP standpoint, this setup can be depicted by the following diagram:The code is on GitHub studzien/mongooseim-docker. Please follow the very quick start guide if you want to setup a similar infrastructure.ScenarioWe prepared Amoc’s scenario where every single session is trying to reconnect after node failure. The scenario can be found here.MetricsThe dashboard for interactive starting or stopping nodes and adding or removing XMPP users during an example run looked as follows:You can check out the snapshot of this run to see how MongooseIM nodes reacted for nodes going up or down here.Load testTo proof that we didn’t break anything in the 1.6.x road, we ran load tests comparing 1.6.2 with 1.6.0. These load tests proved that we in fact improved memory footprint since 1.6.0. All other parameters stayed the same.Exported Grafana dashboards can be found here:MongooseIM 1.6.0MongooseIM 1.6.2TestsAs usual we are increasing test coverage and improving tests quality. The most important changes are:extended privacy testsimproved ejabberd_c2s testsadded tests for MAM preferenceEnhancements and fixesWe finally added support for new MAM XEP-0313 versions. Now MongooseIM understands MAM version from 0.2 to 0.5! Also we implemented Dialback Key Generation and Validation (XEP-0185) which is important to have trusted S2S connections.Since 1.6.2, MongooseIM no longer supports Erlang/OTP versions older than R16B03-1. Thanks to that we simplified our codebase by removing some workarounds for older Erlang versions.Join us!As we finished our work on 1.6.x release we are now starting work on 1.7.x, please suggest features on our tracker.Special thanks to our contributors @gbour, @bartekgorny and @jfjalburquerque. We encourage everybody to code and do a Pull Request!Read the MongooseIM Product page on Erlang Solutions website. Or read on GitHub the detailed changelog, and check out the MongooseIM repository.Get the news! Subscribe to the announcements mailing-list.Go back to the blog\n\nTags:MongooseIMMongoossIM 1.6.2riakXMPPdockermessaging platformopen sourceErlangRiakKVShare  Facebook Twitter Linkedin E-mail", title: "MongooseIM 1.6.2 is out. Time to upgrade!", url: "https://www.erlang-solutions.com/blog/mongooseim-1-6-2-is-out-time-to-upgrade.html"}
%{author: "by Andra Dinu", text: "Improving Erlang Enterprise Tooling: An Open Source Initiative by bet3652016-03-14\n        by Andra Dinu\n      bet365 decided to address the need for better support documentation and tooling in Erlang by open sourcing the code for Erlang SOAP support and by releasing ODBC code that enables Erlang systems to interact with SQL databases in a much easier manner. We took advantage of the working relationship we have with bet365 to ask Chandru Mullaparthi, Head of Software Architecture at bet365 a few questions about the initiative.Q: Hi Chandru, let’s start with a little bit about you. How long have you been working with Erlang?Chandru: (laughs) Not that long. Since 1999. I worked in telecoms for about 15 years, building real-time systems in Erlang. I’ve been with bet365 for nearly 2 years, and they had been working in Erlang for about 2-3 years before I joined. It’s a business that deals in high traffic volumes, so Erlang is a perfect fit.Q: What do you use Erlang for at bet365?Chandru: The first project was to rewrite a key system that pushes real-time odds data to our millions of users. We then built it into our Cash Out service, which enables customers to close bets early. It has brought a lot of benefits. Since we started using it, code complexity has decreased significantly, we scaled from 10s of thousands to 100s of thousands of users on a single machine and we ship much faster.Q: Why an open source release and why SOAP and ODBC?Chandru: We’ve been using open-source code in our work and this donation is a way to give something back to the community. But it also creates a start for more enterprise-friendly Erlang libraries. The Erlang tool chain needs to be made more user-friendly. As to why SOAP and ODBC in particular? Our IT environment is a mix of Windows and Linux servers and we needed to connect these systems as well as our database systems. We discovered that there was next to no support for SOAP in Erlang. The ODBC support had various issues which made it very difficult to integrate into relational SQL databases. Ericsson has an ODBC database connector, but we needed to improve on what was already there. Also, SOAP and ODBC are widely used in enterprise environments and would be likely starting points for anyone coming to Erlang for the first time. So it made sense to start the open-source initiative there. Erlang is a valuable tool in our toolkit and we think it has the potential to become a dominant language for web infrastructure. We have committed to using Erlang in parts of our infrastructure for the long run, so improving these aspects will benefit bet365 a great deal in the future.Q: While it makes a lot of sense from a community perspective, business-wise doesn’t it mean you’re helping your competitors?Chandru: We don’t really compete on technology. Our success is driven by our business model, our people, processes and the quality of the service we deliver to end users.Q: So what’s next in this open-source initiative?Chandru: We have already contributed resources to help get rebar3 adopted as the official build tool for Erlang. We will open source more components as and when we feel they are ready and are sufficiently generic to be of widespread use in the community. Open source efforts work best when everyone contributes what they are actively using and keeping up to date. So while I can’t say what’s next, I can definitely say that we are committed to giving back to the community we benefit from. In the meantime, we invite everybody to take a look and contribute to the libraries available on github.Go back to the blog\n\nTags:bet365ErlangSOAPODBCSQLShare  Facebook Twitter Linkedin E-mail", title: "Improving Erlang Enterprise Tooling: An Open Source Initiative by bet365", url: "https://www.erlang-solutions.com/blog/improving-erlang-enterprise-tooling-an-open-source-initiative-by-bet365.html"}
%{author: "by Ayanda Dube", text: "Take Control of your RabbitMQ queues2016-03-23\n        by Ayanda Dube\n      Erlang Solutions offers world-leading RabbitMQ consultancy, support & tuning solutions. Learn more >You’re a support engineer and your organisation uses a 3-node RabbitMQ cluster to manage its inter-application interactions across your network. On a regular basis, different departments in your organisation approach you with requests to integrate their new microservices into the network, for communication with other microservices via RabbitMQ.With the organisation being so huge, and offices spread across the globe, onus is on each department’s application developers to handle the integration to the RabbitMQ cluster, only after you’ve approved and given them the green light to do so. Along with approving integration requests, you also provide general conventions which you’ve adopted from prior experience. Part of the conventions you enforce is that the connecting microservices must create their own dedicated queues on integration to the cluster, as the best approach to isolating services and easily managing them. Unless of course, the microservices would be seeking to only consume messages from already existing queues.So, average message rate across your cluster is almost stable at 1k/s, both from internal traffic, and external traffic which is being generated by some mobile apps publicised by the organisation. Everything is smooth sailing, till you get to a point where you realise that the total number of queues in your cluster is nearing the order of thousands, and one of the three servers seems to be over burdened, using more system resources than rest. Memory utilisation on that server starts reaching alarming thresholds. At this point, you realise that things can only get worse, yet you still have more pending requests for integration of more microservices onto the cluster, but can’t approve them without figuring out how to solve the growing imbalance in system resources across your deployment.Fig 1. RabbitMQ cluster imbalance illustrationAfter digging up on some RabbitMQ documentation, you come to light with the fact that since you’re using HA queues, which you’ve adopted to enforce availability of service, all your message operations only reference your master queues. Microservices have been creating queues on certain nodes at will, implying that the provisioning of queues has been random and unstructured across the cluster. Concentration of HA queue masters on one node significantly surpass that on the other nodes, and as a result, with all message consumptions referencing master queues only, the server with the most queue masters is feeling the operational burden in comparison to the rest.Your load balancer hasn’t been of much help, since whenever you experience a network partition, or purposefully make one of your nodes unavailable for maintenance work, queue provisioning has proceeded uncontrolled on the remaining running nodes. This retains the queue count imbalance upon cluster restoration. A possible immediate solution would be to purge some of the queues, to relieve the memory footprint on the burdened server(s), but you can’t afford to do this as most queued up messages are crucial to all business operations transacting through the cluster. New and existing microservices also can’t continue timelessly creating and adding more queues into the cluster until this problem has been addressed. So what do you do?Well, as of version 3.6.0, RabbitMQ has introduced a mechanism to grant its users more control in determining a queue master’s location in a cluster, on creation. This is based on some predefined rules and strategies, configured prior to the queue declaration operations. If you can relate with the situation above, or would like to plan ahead and make necessary amendments to your RabbitMQ installation before encountering similar problems, then read on, and give this feature a go.So how does it work?Prior to introducing the queue master location mechanism, declaration of queues, by default, had been characterized by the queue master " <> ..., title: "Take Control of your RabbitMQ queues", url: "https://www.erlang-solutions.com/blog/take-control-of-your-rabbitmq-queues.html"}
%{author: "by Zsolt Laky", text: "Erlang gen_server Reloaded2016-03-30\n        by Zsolt Laky\n      Writing gen_servers has become a routine. We have dozens of gen_servers in our applications, but when we get to a point of extending the server behaviour, we start scratching our heads. Which of our servers have the lowest response time ? How long does it take for a request to be processed? Implementing these metrics may involve changing the code in all of our servers. With Common Service Interface (CSI) we can manage our server’s behaviour and metrics in one place. Road to use CSIIntroductionIn an Erlang application, usually we have a number of services communicating to process the incoming requests from the clients. Most of the time these services are implemented by writing gen_server code. Some of them may be processor intensive, others could be I/O intensive. When we face a situation in which our system slows down, it is hard to find the root cause of the performance degradation. We may have a clue about which service (or gen_server) takes the resources causing the bottleneck, but on the other hand if we were able to measure basic metrics for all the services, the quest for the root cause would be much easier.Implementing the metrics in each and every service takes time and carries the risk of non-conformity as different developers may have different ways and ideas on how to implement a common metric.If we had a generalised gen_server that all the services comply with, implementing common behaviours for all services would mean creating the code once and then reusing it as many times as necessary.So instead of writing a gen_server for a service, we can use a generealised gen_server, to handle the request by making calls to our callback module that implements the functionalities.The Common Service Interface (CSI)In short, the CSI sits between the service API and the service logic. When a request is made the service API calls the CSI and tells it how to process the request. Then CSI takes the order, makes the call to the service logic (a callback module), and responds to the caller with the value the service logic gives back.So we have two things to consider:The way to handle the incoming requests.The behavior for the callback module where the requests are processed.Handling incoming requestsThe call flow for any incoming requests is as follows: The caller executes a servicename:function(Parameters) call in order to have a result from the service. In the servicename.erl file (which is the API for the service) all functions have the same format so that they’re able to call the csi:calltype(Parameters) API of the CSI server. There are a couple of call types available that are described later on.For a given service, this is all that is needed to set up the API.Processing the request in the callback moduleAs the CSI server is the gen_server for the implemented service, ithandles the calls made in the service.erl API in it’s handle_call function, by calling the callback module’s function(Parameters). The callback module returns the results to the CSI gen_server that forwards it to the original requester. Let’s assume the callback module name is servicename_service.erl. The following figure shows the call flow:The service API module is my.erl, the business logic is in my_service.erl. The generic part of the service is in csigenserver.erl.A tiny example.In order to quickly understand the usage of CSI, we will implement a small service, called em_service that provides three functionalities:process_foo(Atom). - Returns the atom hello_world.process_too_long(Atom). - Sleeps for a long time to test the timeout kill functionalityprocess_crashing(Atom). - Throws an exception.There are two main parts of our em_service.erl callback module:1. Behavioural functionsImplementing a service needs some housekeeping. When the service server is launched through a start() or astart_link() function call, init_service() is called in the callback module. Here, the service initialises its global state and returns an {ok, ServiceState} tuple. This `ServiceState is used to pass the globa" <> ..., title: "Erlang gen_server Reloaded", url: "https://www.erlang-solutions.com/blog/erlang-gen_server-reloaded.html"}
%{author: "by Erlang Solutions", text: "Keep in touch with Erlang & Elixir2016-04-04\n        by Erlang Solutions\n      Scroll down to see our latest Erlang & Elixir newsEvery month we send our selection of Erlang and Elixir news, blogs, case studies, videos and podcasts to over 3000 subscribers. Our goal is to showcase interesting technical issues AND companies of all sizes that use Erlang and Elixir in production. Maybe something in our newsletter could help you convince upper management to take a leap and try some Erlang or Elixir :) Scroll down to take a look at the last newsletter issue and if you like what you read subscribe to our mailing list. Erlang Solutions Newsletter - March Issue Getting sporty with Erlang & Elixir! Don’t know about you, but here at Erlang Solutions we get very sporty come spring. Some of us are running marathons, others are just really keen on football (soccer for US based readers) league matches. Either way, you’ll be hearing a lot more about our Erlang tech & sports related exploits over the next few months.Why is bet365 open sourcing its Erlang code?Get answers from bet365 Head of Architecture Chandru Mullapharti on Thursday 14 April. World leading online gambling group bet365 recently open sourced code that makes Erlang a lot more enterprise-friendly. If you are in London on 14 April at 6:30 pm, you can ask bet365’s Head of Architecture your questions right after his talk ‘Erlang @ bet365 - Past, Present and Future’ at the London Erlang User Group.RSVPBuilding a mobile chat app for fast-expanding sports social network Sqor Sports - Webinar 7 AprilEuropa League is in full swing, and Sqor Sports might soon be your favourite way to keep up with your club. They just started their Europe expansion by partnering with FC Bayern Munich. We developed a unique MongooseIM based mobile chat feature in their app, and on April 7th Sqor Sports project lead Chuck Pinkert and Inaka senior project manager Tatiana Oudine will talk you through the challenges faced and the lessons learned in this project. Register to attend this webinar.Register Using a scalable platform to expand your app’s range of services - a Grindr case studyOne of world’s largest dating apps, Grindr is expanding services from dating to lifestyle needs. Their platform set up will allow them to expand without the corresponding IT pain - a lesson form many of today’s enterprises. We are and have been helping Grindr in this process for a while, and we can’t wait to see where they will go to next!Read case study Take Control of your RabbitMQ queues - blog postYou’re a support engineer and your company uses a 3-node RabbitMQ cluster to manage its inter-application interactions across your network? If you ever struggled with determining queue locations within a cluster this post will show you how to use a new feature and take control over distribution of queues. Read MoreErlang gen_server Reloaded - blog postWe have dozens of gen_servers in our applications, but when we get to extending server behaviour, we start scratching our heads. Which of our servers has the lowest response time? How long does it take for a request to be processed? This is a solution to manage servers’ behaviour and metrics in one place.Read MoreStartup tech pack: Elixir, Phoenix, Riak KV - 28 April LondonElixir, Phoenix, and Riak KV are Open Source technologies that can get your startup up and running quickly with a stack you won’t outgrow. If you’re in London on the evening of 28 April, come get a practical introduction to these techs and meet some startups who are using them.Read moreManaging two million web servers Joe Armstrong’s blogTime and again Joe Armstrong has heard this said: 'We have a (Erlang or Elixir) web server managing 2 million user sessions.“ In his blog, he shows this statement to be incorrect and stemming from a fundamental misconception. Go back to the blog\n\nTags:newsletterShare  Facebook Twitter Linkedin E-mail", title: "Keep in touch with Erlang & Elixir", url: "https://www.erlang-solutions.com/blog/keep-in-touch-with-erlang-elixir.html"}
%{author: "by Andra Dinu", text: "Erlang Innovation Race: The Winners!2016-04-12\n        by Andra Dinu\n      On Saturday 10 million people turned on their tellies to watch the Grand National race, and we wanted to celebrate this beloved British tradition in our own way. Alas, we know little about horses and racing, but we take pride in knowing a lot about technology. We picked some pretty cool Erlang companies and over the weekend we allowed everybody to push them ahead in the race with one click. Rumor has it that our office manager played the bookie and ran the bets in the office, but we can neither confirm nor deny these allegations :P Before we review the winner, take a look at the companies in the race and their use of Erlang:Klarna: Europe’s leading payment solutions providers. Klarna was valued at $2.25 billion before their U.S launch in 2015. They use Erlang for concurrent, realtime domains, along with Riak for storing data where availability trumps consistency.Grindr: The world’s largest gay social network, recently announced they geared up their scalable platform to expand from app into lifestyle service. They use Erlang in their core platform and MongooseIM in their chat.Fermilab: There are very few things cooler or more innovative than a particle accelerator. USA’s particle accelerator uses Erlang extensively in their control systems.Ericsson: The birthplace of Erlang. Ericsson now supports and maintains it through their OPT unit. The company turned 140 years old last week, and their innovation accomplishments speak for themselves.Machine Zone: The mobile gaming phenomenon announced yesterday the launch of RTplatform, a cloud platform that, “connects and engages people-devices-data simultaneously in real time…at unparalleled speed, capacity and affordability. They use Erlang extensively, including in their Game of War chat app.Sqor Sports: This Erlang startup uses Erlang for their backend application and MongooseIM in their chat app. Set out to revolutionise how sports fans interact with athletes, and after taking over the US they are now expanding to Europe, starting with Bayern Munchen FC partnership.bet365: UK’s leading online betting and gambling company switched to Erlang 3 years ago and never looked back. They have become such fierce Erlang advocates they recently open sourced Erlang tools. (Thank you bet365!)Aol: Their leading real-time ad exchange platform Marketplace revolutionised the RTB market in 2013. The platform is a merger of Erlang, Java and C++ and serves up to 40 billion auction requests per day.Whatsapp: The poster child of Erlang companies serves over 1 billion users with a team of 50 engineers. They recently switched to end-to-end encryption, possibly the world’s largest-ever implementation of this standard of encryption in a messaging service.EE: As of 12 February 2016, EE’s 4G network reaches more than 95% of the UK population, with double speed 4G reaching 80%. Erlang/OTP has been in use at EE for the past 15 years.Why an “Innovation Race” ? The importance a company gives to innovation is a sure marker of their growth and success, and world’s most successful companies are the most innovative ones. What drives innovation? According to the Boston Consulting Group there are 4 interrelated factors: quickly adopting new technologies; leveraging existing technology platforms to expand into new sectors; lean R&D processes and adopting technology across the entire business instead keeping it only in the IT department. Erlang is not exactly a new technology, but it seems that more and more companies are just discovering it. Initially developed for telecomms, Erlang is finding more and more usage in new sectors such as above and there are excellent use cases for Big Data and the Internet of Things.For many companies, getting over a certain number of users means that the ability to innovate quickly is lost. Precious time is spent constantly rewriting software so it runs at the scale needed to run the business and getting a new innovation to scale often means that they can’t get it out of the door fast enough. Here’s where Erlang" <> ..., title: "Erlang Innovation Race: The Winners!", url: "https://www.erlang-solutions.com/blog/erlang-innovation-race-the-winners.html"}
%{author: "by Lukas Larsson", text: "Erlang 19.0 Garbage Collector2016-04-07\n        by Lukas Larsson\n      Learn more about how Erlang Solutions’ Erlang and Elixir Solutions or sign up to our mailing list to be the first to know about our future blog posts.Disclaimer: This blog post describes the state of the Erlang garbage collector in Erlang/OTP 19.0. The things that will change in 19.0 are clearly marked in each of the sections. The Erlang/OTP master branch is a moving target and some of the things may have changed by the time 19.0 is released.Erlang manages dynamic memory with a tracing garbage collector. More precisely a per process generational semi-space copying collector using Cheney’s [1] copy collection algorithm together with a global large object space.OverviewEach Erlang process has its own stack and heap which are allocated in the same memory block and grow towards each other. When the stack and the heap meet, the garbage collector is triggered and memory is reclaimed. If not enough memory was reclaimed, the heap will grow.Creating DataTerms are created on the heap by evaluating expressions. There are two major types of terms; immediate terms which require no heap space (small integers, atoms, pids, port ids etc) and cons or boxed terms (tuple, big num, binaries etc) that do require heap space. Immediate terms do not need any heap space because they are embedded into the containing structure.Let’s look at an example that returns a tuple with the newly created data.data(Foo) ->\n   Cons = [42|Foo],\n   Literal = {text, \"hello world!\"},\n   {tag, Cons, Literal}.In this example we first create a new cons cell with an integer and a tuple with some text. Then a tuple of size three wrapping the other values with an atom tag is created and returned.On the heap tuples require a word size for each of its elements as well as for the header. Cons cells always require two words. Adding these things together, we get seven words for the tuples and 26 words for the cons cells. The string \"hello world!\" is a list of cons cells and thus requires 24 words. The atom tag and the integer 42 do not require any additional heap memory since it is an immediate. Adding all the terms together, the heap space required in this example should be 33 words.Compiling this code to beam assembly (erlc +S) shows exactly what is happening.\n    ...\n    {test_heap,6,1}.\n    {put_list,{integer,42},{x,0},{x,1}}.\n    {put_tuple,3,{x,0}}.\n    {put,{atom,tag}}.\n    {put,{x,1}}.\n    {put,{literal,{text,\"hello world!\"}}}.\n    return.Looking at the assembler code we can see three things; The heap requirement in this function turns out to be only six words, as seen by the {test_heap,6,1} instruction. All the allocations are combined to a single instruction. The bulk of the data {text, \"hello world!\"} is a literal. Literals, sometimes referred to as constants, are not allocated in the function since they are a part of the module and allocated at load time.If there is not enough space available on the heap to satisfy the test_heap instructions request for memory, then a garbage collection is initiated. It may happen immediately in the test_heap instruction, or it can be delayed until a later time depending on what state the process is in. If the garbage collection is delayed, any memory needed will be allocated in heap fragments. Heap fragments are extra memory blocks that are a part of the young heap, but are not allocated in the contigious area where terms normally recide. See The Young Heap for more details.The CollectorErlang has a copying semi-space garbage collector. This means that when doing a garbage collection, the terms are copied from one distinct area, called the from space, to a new clean area, called the to space. The collector starts by scanning the root-set (stack, registers, etc).It follows all the pointers from the root-set to the heap and copies each term word by word to the to space.After the header word has been copied a move marker is destructively placed in it pointing to the term in the to space. Any other term that points to the already moved term will see this move ma" <> ..., title: "Erlang 19.0 Garbage Collector", url: "https://www.erlang-solutions.com/blog/erlang-19-0-garbage-collector.html"}
%{author: "by Nicolas Verite", text: "Welcome to the third generation of Instant Messaging! Part 2/22016-04-20\n        by Nicolas Verite \n      CC by-sa, Creative Commons Attribution-ShareAlike 4.0 internationalThis is the second and last part of my “Welcome to the third generation of Instant Messaging!” post, you can read part 1 here.The first generation was lead by ICQ and followed by all its clones and is characterised by multi-window desktop software, with through sporadic internet connection, all centered around the concept of ‘presence’.The second generation was triggered by the multi-touch smartphone revolution and includes was lead by WhatsApp and followed by all its clones, with the main focus on making chats less synchronous.This is the third generation.3rd generation: group messagingThe group messaging revolution began around 2015-2016, with the advent of Slack and HipChat. Other services in the third generation are Zulip, Otalk, Kaiwa, Mattermost, Let’s Chat, Rocket.Chat. Since the third genration revolution is still ongoing, observing and understanding what is happening is much harder. We don’t yet have any strong long-term feedback, and the race is ongoing. But again, a new generation, a new disruption is evolving.a. Continuous computing experienceThe context evolved once again. Mobile have overtaken sales of other forms of computer. People use smartphones as their first (sometimes only) device. But, overall, the smartphone revolution calmed down a little. Many companies now practice “BYOD” (“Bring Your Own Device”), allowing employees to use their personal smartphone and laptop for work. People generally use a laptop at work, a tablet on the couch, and a smartphone on their commute, coffee pause, and lunch break, not to mention parties, family dinners and toilet breaks.b. Presence makes a shy comeback, but remains a secondary featureWe learned that in the 2nd generation presence was missed by users when removed from apps, or still used as a secondary feature. When it comes to presence, there is continuity between 2nd and 3rd generation, but with a slight come back: although presence does not always comes as a central feature, it is only one click or tap away.c. Mobile AND desktop in the real worldThe 3rd generation IMs come in different flavors: the app is available on one or two (or more) mobile platforms and on one or two (or more) desktop platforms. These software pieces may not come with feature parity due to all these apps’ lifecycles, but the overall user experience is mostly there already. On desktop, software is often available in the web browser. And when it comes as desktop software, it is often just the web app that is delivered into a packaged software working on web technologies.d. Single window mode, for simplicity, and flat designAll the 2nd generation IMs that now provide some desktop experience offer single window software. Not because of the web technologies they are based on, just because multi-window is far too complex for massive user bases.The responsive design of the few desktop apps and websites of the 2nd generation has been generalised, and consequently brought about the 3rd generation. If you resize your desktop app window to a tiny size, you have a UX close to that of the mobile app (minus multi touch input), when you resize it to average size, you get a tablet-like experience, and when you really enlarge it, you have the full blown desktop experience.Flat design is the default of the 3rd generation, whether it is done in Apple style, Material design by Google, Metro-style by Microsoft. This is a minimalist UI design genre or language, getting away from the skeuomorphic paradigm, that immitates previous generations’ interfaces. Even 2nd generation apps are now phasing out non-flat design.e. Group chat is the main core featureGroup apps of the 3rd generation IM naturally prioritise group chats, or at least do not relegate them as a secondary feature. Conceptually, in group apps, the chat rooms or channels are not just an extension of one-to-one chats, but rather one-to-one chats are a downsized version of group chats" <> ..., title: "Welcome to the third generation of Instant Messaging! Part 2/2", url: "https://www.erlang-solutions.com/blog/welcome-to-the-third-generation-of-instant-messaging-part-2-2.html"}
%{author: "by Nicolas Verite", text: "Welcome to the third generation of Instant Messaging! Part 1/22016-04-14\n        by Nicolas Verite   \n      CC by-sa, Creative Commons Attribution-ShareAlike 4.0 internationalReal-time, synchronous text messaging has come a long way!In the “old days” (some would call that pre-history), the concept was simple - we used Talk on Unix to log in to a machine remotely and chat with another local user on that machine. There were no chat rooms, authentication, authorisation or basic encryption that seem so obvious, ubiquitous and indispensable today.Then IRC came as an open standard, introducing multi-party chat rooms as a main feature. Different flavors of non-standard extensions, and disjointed networks soon followed. One of the most irritating issues was (and still is) the infamous netsplits. The sum of all IRC networks now only totals fewer than a stable 1 million users worldwide.This era was very diverse and laid the ground for future developments; however the concept introduced in this period was just that of “chat”. The next step - moving to actual Instant Messaging - is where our journey really begins.1st generation: instant messengers, ICQ-likeThe instant messenger revolution started around 1998 and 1999 with ICQ as the very first successful player. Then Yahoo!Messenger, AIM and MSN/WLM followed, as well as Gadu-Gadu, QQ, NateOn, LiveJournal, MySpaceIM, Google Talk, and many more, including the only open standard, XMPP or Jabber (not mentioning SIP/SIMPLE here).a. Sporadic internet connectionIn those times, most people connected to the internet using a landline modem. It was slow, expensive and worst of all - loud and annoying (who can forget the “iiiiiiii-eeeeeeee-iii” sound accompanying every session?). No one would connect to the internet for longer than one, maybe two hours since it blocked the phone and ended up costing a fortune.b. Presence, synchronicity of the user experienceIn the very first instant messengers, the concept around which everything revolved was presence, as a core and central feature. When you opened the app you saw a roster listing all your contacts and their status indicated whether they were online or not. Large, blinking icons informed you who was available, busy or away at the moment. Prominent sound notifications let you know the current status of your friends. When logging in, by default, you too were broadcasting to the world that you were online. In both directions, people just wanted to know in real-time who was available to chat, and then engaged in discussion sessions.c. Desktop-only clientObviously, the first generation of IM was desktop-only (laptops were still a minority). That meant low bandwidth (before ADSL), but large, comfortable computing resources. Mobile phone screens were just about one or two lines of text in large black LCD pixels, and had no data network (spoiler: the second generation of IM is all about the smartphone).d. Multi-window software is coolSince presences and availabilities in the contact list were the main focus, the second most important was the chat window(s). IM clients were multi-window (one window per chat) or dual-window (all chats in one window with tabs). Multi-window software was a cool thing at that time, in photo editing, non-linear video editing, and many more. These were more or less targetted at power users.e. Group chat as a secondary featureGroup chat was a secondary feature. Lots of room types and features were available: public vs hidden, permanent vs short-lived, whitelists vs blacklists, kick vs ban, etc. You could join group chats after you connected, but participants were not necessarily there all at the same time. Anyone could be suddenly disconnected, for whatever reason (modem stability, or parents taking over the phone). You would miss all the conversations happening while you were offline, and besides this, rooms were cluttered with automatic status messages (Mary joined, John disconnected).f. Offline messages and logs, easing the suffering of absenceOffline messages (sometimes called store-and-forward) and chat logs were made to " <> ..., title: "Welcome to the third generation of Instant Messaging! Part 1/2", url: "https://www.erlang-solutions.com/blog/welcome-to-the-third-generation-of-instant-messaging-part-1-2.html"}
%{author: "by Marcos Almonacid", text: "Exploring with, the Elixir special form 2016-05-27\n        by Marcos Almonacid\n      This is my short exploration of with, the new Elixir special form introduced in v1.2.DefinitionIf we check the documentation, it says that withis used to combine matching clauses. And if all the clauses match, the do block is executed, returning its result. Otherwise the chain is aborted and a non-matched value is returned:\nopts = %{width:10, height:15}\nwith {:ok, width} <-Map.fetch(opts, :width),\n     {:ok, height} <-Map.fetch(opts, :height),\n     do: {:ok, width * height}\n#=> {:ok, 150}\n\nopts = %{width:10}\nwith {:ok, width} <-Map.fetch(opts, :width),\n     {:ok, height} <-Map.fetch(opts, :height),\n     do: {:ok, width * height}\n#=> :errorThe documentation also says: variables bound inside with won’t leak, and also it allows “bare expressions”:\nwidth =nil\nopts = %{width:10, height:15}\nwith {:ok, width} <-Map.fetch(opts, :width),\n     double_width = width *2,\n     {:ok, height} <-Map.fetch(opts, :height),\n     do: {:ok, double_width * height}\n#=> {:ok, 300}\n\nwidth\n#=> nilSome usagesThis looks cool. But when should we use it? There are some situations where using with is a good idea. I’m going to mention 2 of them.Replacing nested case statementsLet’s say we have a function to setup a socket that listens on a specific port, accept a connection on this socket, and wait for incoming packets. We could have something like:defserver(port, opts) docase:gen_tcp.listen(port, opts) do\n    {:ok, lsock} ->case:gen_tcp.accept(lsock) do\n        {:ok, sock} ->\n          do_recv(sock)\n        error ->\n          error\n      end\n    error ->\n      error\n  endenddefdo_recv(sock) docase:gen_tcp.recv(sock, 0) do\n    {:ok, packet} ->\n      handle_packet(packet)\n      do_recv(sock)\n    {:error, :closed} ->:okendendserver/2 has 2 nested case’s. We can rewrite it using with:defserver(port, opts) do\n  with {:ok, lsock} <-:gen_tcp.listen(port, opts),\n       {:ok, sock}  <-:gen_tcp.accept(lsock),\n       do: do_recv(sock)\nendThis new implementation is shorter and more readable.Validationswith can also be used to validate data before doing something with this data.Let’s say we want to create a new user in our database by storing it in our database; but in order to do so, we have to run some validations over the data.If we use with, we could write something like:defcreate(user) do\n  with :ok<- validate_name(user),\n       :ok<- validate_email(user),\n       :ok<- validate_token(user),\n       :ok<- validate_location(user),\n       do: persist(user)\nendThe code looks pretty simple.We run every validation before calling persist/1. If one of the validations returns something different than :ok, for example, validate_email/1 returns {:error, :invalid_email}, the chain will be aborted and create/1 will return the error tuple.(We can implement create/1 in a few different ways. Using with is just one more)What about the ‘Let it crash’ culture?Ok, with is a nice special form, our code looks simple and readable when we use it. But I’m an Erlang developer, so if something doesn’t return the result that I’m expecting, the process running that code must die and its supervisor might restart it (depending on the restart strategy).We could say that with hides MatchError crashes. So that, using with is kind of using try/catch statements. Well, I think that’s not really true. Because whatever with returns is going to be an expected result, regardless if it’s a successful response or an error response. For instance, if we call our create/1 function and it returns {:error, reason}, we might want to do something with that error (log it, send a notification, etc) before finishing the process.case create(user) do\n  {:ok, id} ->\n    {:ok, id}\n  {:error, reason} ->\n    handle_creation_error(user, reason)\nendConclusionThis new special form is a good tool to write simple code when it’s used in the right situation. As any other tool, trying to use it everywhere would be a mistake.It doesn’t hide MatchError crashes, it simply has different possible returns. So it’s not breaking the 'Let it crash’ rul" <> ..., title: "Exploring with, the Elixir special form ", url: "https://www.erlang-solutions.com/blog/exploring-with-the-elixir-special-form.html"}
%{author: "by Magnus Henoch", text: "Erlang distribution over TLS2016-06-28\n        by Magnus Henoch\n      Erlang Solutions offers world-leading RabbitMQ consultancy, support & tuning solutions. Learn more >What is Erlang distribution?The “distribution protocol” is the means by which multiple Erlang nodes join together to form a cluster. When Erlang nodes are clustered, any process can send messages to processes on any other node, and spawn new processes on any other node. This forms the basis for distributed applications such as Mnesia, the database implementation that comes with Erlang/OTP, and RabbitMQ, the message broker.The Erlang distribution protocol was designed assuming that it’s running on a trusted network. While nodes connecting to each other are required to prove that they possess a shared secret, called a “cookie”, this is mostly aimed at ensuring that different Erlang clusters on the same network don’t accidentally merge; it’s not recommended to rely on the cookie mechanism to keep an attacker out.Furthermore, all Erlang nodes in a cluster trust each other completely. Any node in the cluster can run any code on any of the other nodes, including running arbitrary commands with os:cmd. This is why the Distribunomicon chapter of Learn You Some Erlang describes Erlang’s security model with the words * this space intentionally left blank *.In this blog post, I describe how to run the Erlang distribution protocol over TLS, and what problems that may or may not solve.Why TLS? What problems does it solve?Let’s say you have an existing Erlang cluster in your data centre, and you’re going to upgrade it to use TLS. (You might think that using TLS means that you can run an Erlang cluster over the Internet, in which case I’ll say that you are very brave, and I’d like to hear about your experiences!) In the simplest possible configuration, communication between nodes is encrypted, but the nodes don’t verify certificates.What does that mean? It means that given two Erlang nodes called Alice and Bob, if Eve (an eavesdropper) is already inside your network, and can listen to network traffic, she still cannot see what your Erlang nodes are sending to each other, which might be sensitive data that you want to protect. This is thus an example of defence in depth: even if an attacker has penetrated your firewall, they still encounter further obstacles in getting what they want. However, if the attacker inside your network is Mallory, who can perform a man-in-the-middle (MITM) attack, he can just present a different certificate to each node, and proxy the connection.The usual way to verify TLS certificates is to check that they are signed by a trusted Certificate Authority (CA). This ensures that Mallory cannot intercept the connection unless he gets hold of the private key of the CA. However, it also introduces a new important question: which CAs do you trust? Since any Erlang node with a certificate issued by a trusted CA gets full access to your node, you probably want to trust as few CAs as possible, perhaps creating your own CA to issue certificates for the nodes in your cluster and trusting only that one.Another way to reduce that risk is to create a whitelist of trusted certificates. This is not available out of the box, but you can do it by implementing your own verification function.How to use distribution over TLS?This is described in the official documentation (http://erlang.org/doc/apps/ssl/ssl_distribution.html), so I’ll just give some hints and examples here to get you started.First of all, since this involves passing many long command line arguments to erl, I’d suggest writing a shell script that starts erl appropriately, so you don’t have to fiddle with the arguments in the terminal.The documentation says that you need to either include the SSL application in your boot script, or explicitly include the SSL ebin directory in the code path. Eventually you’ll probably want to do the former, using your favourite release generation tool, but while you’re experimenting you can make do with the latter. Here is a snippet that saves the right directory in a" <> ..., title: "Erlang distribution over TLS", url: "https://www.erlang-solutions.com/blog/erlang-distribution-over-tls.html"}
%{author: "by Michał Piotrowski", text: "MongooseIM 2.0.0beta1 is out! Explore the new features2016-07-05\n        by Michał Piotrowski\n      MongooseIM 2.0.0beta1: strong mobile focusWe are proud to present the latest step on our road to the MongooseIM 2.0.0 release. Enjoy MongooseIM 2.0.0beta1 - now available on GitHub, and see the scope of changes that made us jump to 2.0.0.What’s newMongooseIM 2.0 is about new features. We added support for several XEPs and we created our own open extensions to the XMPP protocol developed as solutions to customer problems.New XMPP extensionsPublish Subscribe for real-time non-chat applicationsOver the last year or more, many customers required the XEP-0060: Publish Subscribe extension. We decided to restore the support for it along with XEP-0163: Personal Eventing Protocol. This opens doors for many use cases which were hard to achieve before. It is now possible to seamlessly integrate MongooseIM with services such as Movim or other micro blogging engines based on XMPP. More generally, it opens a wide range of possibilities in the real-time application space.Blocking Command for enhanced and simpler privacy enforcementIn many cases XEP-0191: Blocking Command (which is simpler version of XEP-0016: Privacy Lists) does the required job which is blocking a communication with specified users. These two functionalities do not exclude each other, so it is still possible to have more sophisticated privacy settings when required. The added support for this extension makes the life of a client side developer significantly easier.Client State Indications for bandwidth and battery savingsThe XEP-0352: Client State Indication is a very important extension for mobile clients. It allows the application to notify the server that from now on it is in an inactive state. The server then reduces the amount of data sent to the user which lowers the battery and bandwidth consumption.Innovative extensionsMUC light for contemporary and simpler group chatsFor over 2 years now we noticed that mobile-first and mobile-only approaches in application development are the most popular. For the majority of our customers the current MUC as described in XEP-0045: Multi-User Chat was too big and too focused on presence, so they had to invent workarounds.This is why we came up with a simpler, presence-less version of MUC: “MUC light”. When the user goes offline, the user automatically leaves the MUC room, but stays subscribed to the MUC light room. When back online, the user must automatically re-join the MUC room in order to receive the latest messages (potentially losing some of them), while, using the MUC light room feature, it is a matter of only retrieving a message archive (no message loss).We believe this is a good step towards making a group chat more straightforward and up-to-date from both client developer’s and user’s perspective. There is already some traction and support for the MUC light.Token-based authenticationMobile clients (and some laptops with wifi) can lose the connection more often than desktop clients. In such cases it is required to quickly reconnect (including re-authentication) the client when Internet connectivity is back. One way of doing this is to store user’s password on the device and use it while reconnecting. This is not the most secure solution. In order to avoid the password storage on the device we propose a new authentication mechanism based on tokens obtained from the server. More info is available hereOther changes and improvementsParallelised testsAs a team we always think about how to test what we create and how to improve existing tests. Adding new test cases may have its downfalls, especially when you want feedback quickly or you run on a public infra like travis-ci.org and you are closing the max allowed job time (which is around 50 min). In order to optimise we decided to rewrite many of our test suites to run test cases in parallel. This shortens a single job execution significantly but there is still room for further optimisations which we’re going to do.Many more valuable improvementsThere is also many other sma" <> ..., title: "MongooseIM 2.0.0beta1 is out! Explore the new features", url: "https://www.erlang-solutions.com/blog/mongooseim-2-0-0beta1-is-out-explore-the-new-features.html"}
%{author: "by Brujo Benavides", text: "Learn to forget2016-07-20\n        by Brujo Benavides\n      I have many roles/positions inside Erlang Solutions. I’m Inaka’s CTO, I’m one of Erlang Solution’s Tech Leads. I’m also an Erlang Trainer sometimes. But what I truly am is an Erlang Developer. And as such, I want to share with you an experience I had when I was learning Erlang a couple of years ago, which is incidentally something I also have seen (this time from a different perspective) as an Erlang Trainer.In a NutshellThe thing I keep seeing when someone is learning Erlang (and it happened to people learning other languages, like Haskell for instance) is that, at the very beginning…You keep learning things you have to forget later. You’re probably never going to use them anymore. But you need to know them if you want to understand what you’re doing.And this concept is so intrinsically tied to the philosophy of the language that one of those things that renders so many other building blocks forgettable is usually seen attached to the language name itslef: Erlang/OTP. Let me show you what I mean…Sequential ErlangLet’s leave OTP aside for a second. When you start learning Erlang, you usually start with Sequential Erlang, right? Most Erlang books, courses and tutorials start this way.Erlang being a functional language, one of the very first things everyone learns is how to write recursive functions. It all starts with a database which is actually a list:\nfetch(_Key, []) -> undefined;\nfetch(Key, [{Key, Value} | _]) -> Value;\nfetch(Key, [_ | Db]) -> fetch(Key, Db). But then, somebody introduces you to anonymous functions and, of course, high-order functions. Suddenly, you don’t use recursion anymore. Cool kids use lists:dropwhile/3 instead:\n\nfetch(Key, Db) ->\n    case lists:dropwhile(fun({K, _}) -> K =/= Key end, Db) of\n        [] -> undefined;\n        [{_, Value}|_] -> Value\n    end. Of course, eventually you realize that someone else must have had that same issue before. More often than not, that’s exactly the case and there is a function that you can just use:\nfetch(Key, Db) -> proplists:get_value(Key, Db). Concurrent ErlangOk, so writing Sequential Erlang is easier than expected because a lot of things are already written. That’s good, but what about those things that make people choose Erlang in the first place? If you’ve chosen Erlang to develop your system, you probably have a concurrency problem or rather a problem that’s best solved by using a concurrent language.To me, at least, it wasn’t so intuitive at first that the situation described for Sequential Erlang could apply to Concurrent Erlang as well. But then again, it all starts with a database:\nnew(DbValues) -> spawn(?MODULE, init, [DbValues]).\n\ninit(DbValues) -> loop(DbValues).\nloop(Db) ->\n    receive\n        {fetch, From, Key} ->\n            From ! {reply, proplists:get_value(Key, Db)}\n    end,\n    loop(Db).\n\nfetch(Key, Db) ->\n    Db ! {fetch, self(), Key},\n    receive\n        {reply, Result} -> Result\n    end. As you can see, to implement that example you have to learn to spawn processes (using erlang:spawn/3 or other variants) and then send and receive messages. Then again, our database is just a process that receives messages and for each message it receives, using its internal state, builds a response and sends it back to the caller as a message. Yeah, it has a tiny bit of internal logic (proplists:get_value(Key, Db)) that’s unique to it. But the rest is pretty generic. Even from the caller side, everything boils down to just sending messages and waiting for responses.As you might have guessed by now, lots of people faced this same issue before and the condensed experiences helped create no other thing than OTP. When you learn how to work with OTP and its behaviours, you no longer need to spawn processes and send messages explicitly:\nnew(DbValues) -> gen_server:start(?MODULE, DbValues, []).\n\ninit(DbValues) -> {ok, DbValues}.\n\nhandle_call({fetch, Key}, _From, Db) ->\n    {reply, proplists:get_value(Key, Db), Db}.\n\nfetch(Key, Db) -> gen_server:call(Db, {fetch, Key}).\n\nterminate(_, _) -> ok. Did you s" <> ..., title: "Learn to forget", url: "https://www.erlang-solutions.com/blog/learn-to-forget.html"}
%{author: "by Guest author: Andy Oram, Senior Editor  O'Reilly Media", text: "The continuing headaches of distributed programming2016-08-10\n        by Guest author: Andy Oram, Senior Editor  O'Reilly Media\n      Why scaling and parallelism remain hard even with new tools and languagesDespite ground-breaking advances in languages and utilities that purport to simplify parallel or distributed computing, designing a system that supports modern commerce and other high-priority applications remains one of the most difficult tasks in computing. Having dealt with such systems for too long–I wrote tests and documentation for a Unix pthreads implementation at a manufacturing firm in the 1980s, for instance, and edited O’Reilly’s PThreads Programming book in 1996–I have gotten so familiar seeing the same difficulties over and over that I’ve learned to look for them in every distributed system I hear about. And I recently started to wonder why there had been so limited progress in the field after I was assigned a cluster of books on languages (Erlang, Haskell, Scala, OCaml), messaging (ZeroMQ), and DevOps/scheduling tools (Mesos, ZooKeeper).I expect language and tool designers to deal with the difficulties of distributed computing. What surprises me is that users out in the field–application developers and operations personnel–have to do so as well. The complexities are not completely hidden by the tools. And I think I have identified the reason: efficient and robust distributed computing requires careful tuning of your architectural parameters. These parameters must be exposed to the programmers or operations people. At least a few of the following issues will intrude into their decisions:How many nodes you want for each function in your application (front-end, application back-end, database, load balancing, etc.)The memory and CPU capacity of each nodeThe geographic distributions of nodes and which share a data centerHow to partition and replicate your data, the number of replicas needed, and the distribution of nodesHow many systems at each site should be alive simultaneously to handle availability and loadHow many nodes constitute a quorum when replicating state or electing a leaderWhat consistency models (eventual, causal, strong, etc.) you want during data replicationThe recovery policy in case of failures or unresponsive systemsData maintenance policies, such as whether to cache the intermediate results of calculations or recalculate them when necessary The demands on operations pile up fast, and a lot of configuration is required no matter how easy the tool-makers try to render it. This article discusses the design of such systems.Languages facilitate distributed computing–but only to a degreeErlang, Go, and several other languages tout their solutions for people writing for multiple cooperating nodes. Support for distributing computing has certainly been refined in these languages, particularly through the message-passing model, which now seems almost universal.Good old threads and multiprocessing have been relegated to the most performance-critical applications on single systems. Applications spanning nodes can’t benefit from the data sharing that threads and processes on a single system can exploit, and even the blessings of sharing data on a single node run into headaches because of cache consistency issues–along with threads’ notorious vulnerability to hard-to-debug errors. It’s definitely convenient to use a single programming model to cover communication among both local and remote processes, so messaging wins out. Its asynchronous communication allows the same mechanisms to be used for both local and remote processes transparently. You can write code that runs on a single node, and with little or no changes, distribute the code to a cluster of nodes.Asynchronous messaging can even be used through the Network Time Protocol (NTP) to synchronize clocks on different computers, so that when they do have to engage in shared memory activities (such as writing files to a shared disk), their views of the external world are roughly in agreement.But processes still have to deal with backed-up queues, ch" <> ..., title: "The continuing headaches of distributed programming", url: "https://www.erlang-solutions.com/blog/the-continuing-headaches-of-distributed-programming.html"}
%{author: "by Francesco Cesarini", text: "Erlang & Elixir DevOps From The Trenches - Why we felt the need to formalize operational experience with the BEAM virtual machine2016-09-14\n        by Francesco Cesarini\n       Let’s backtrack to the late 90s, when I was working on the AXD301 switch, one of Erlang’s early flagship products. A first line support engineer broke procedure and tried to fix a bug in a live system. They compiled the Erlang module, put it in the patches directory and loaded it in one of the nodes. The patch did not solve the problem, so they deleted the BEAM file but were unaware they had to load the old version again and purge the patched module. So the switch was still running the wrong version of the module. The issue was eventually escalated to third line support, where just to figure out the node was running a different version of the code than originally thought ended up taking a colleague of mine forty hours. All this time was wasted before they could start troubleshooting the issue itself.Year after year, we came across similar incidents, so I started asking myself how we could formalize these experiences in reusable code. Our aim was to ensure no one would ever have to spend 40 hours figuring out that a first line engineer had not followed procedure. At the same time, I wanted to make sure no one had to reinvent the wheel every time they started on a new project. This is how the idea for WombatOAM was born, a standalone Erlang node that acts as a generic operations and maintenance node (O&M for short) for Erlang clusters. Any system with requirements on high availability should follow a similar pattern and approach. Why not formalize it in reusable code?Much of what we do here at Erlang Solutions, is developing, supporting and maintaining systems. Every incident we ever experienced which could have been avoided by analyzing symptoms and taking action has been formalized. Take the AXD301 example. WombatOAM will generate a unique module identifier using the md5 digest of the source code in every beam file, omitting information such as compilation date and attributes which do not affect the execution. If two nodes running the same release have different md5 digests of the same module, we raise an alarm that alerts an operator. If a module is loaded or purged in the system, we log it. If something gets typed into the shell, we log it as well. So not only are we alerted that nodes running the same release have different versions of a module, we also have the audit trail which lead to that state for post mortem debugging purposes.Every system that never stops needs mechanisms for collecting and suppressing alarms, monitoring logs and generating and analyzing metrics. It is one or more subsystem that collects functionality used for monitoring, pre-emptive support, support automation and post-mortem debugging. Applications such as exometer, folsom, elarm, eper, lager and recon will help, but only so far. In the telecom world, this functionality is put in a standalone node to minimize the impact on live traffic, both in terms of throughput and downtime. If the O&M node crashes or is taken offline, the system will still switch calls. This is the operations and maintenance node approach we believe should be adopted by other verticals, as high availability is today relevant to most server side systems. Let’s look at some stories from behind the trenches, and see how a proper O&M system would have reduced downtime and saved $$ in the form of person months of troubleshooting efforts and reduced hardware requirements.AlarmsI’ve rarely seen the concept of alarms being properly used outside of telecoms. In some cases, threshold based alarms are applied, but that is where it often stops. A threshold based alarm is when you gather a metric (such as memory consumption or requests per second) and raise an alarm if the node on which it is gathered on reaches a certain upper or lower bound. But the potential of alarms goes beyond monitoring thresholds in collected metrics. The concept is easy; if something that should not be happening is happening, an alarm " <> ..., title: "Erlang & Elixir DevOps From The Trenches - Why we felt the need to formalize operational experience with the BEAM virtual machine", url: "https://www.erlang-solutions.com/blog/erlang-elixir-devops-from-the-trenches-why-we-felt-the-need-to-formalize-operational-experience-with-the-beam-virtual-machine.html"}
%{author: "by Viktoria Fordos and Csaba Hoch", text: "Operational nightmare fun: dealing with misconfigured Riak Clusters2016-09-21\n        by Viktoria Fordos and Csaba Hoch\n      Everyone has a strong opinion about DevOps. Either you love it, or you hate it. Personally, we believe in DevOps. In the Erlang world, we were doing DevOps even before the term was invented. The power of the Erlang Virtual Machine and the visibility you have when troubleshooting is second to none, but you need to know what you are doing, as you can affect the system and even cause outages. Speaking with developers who dislike DevOps, we are often told that the fun ends with delivering the product. They believe support is boring, and is only about being able to master the stack’s configuration possibilities. We believe they are so wrong! Give us a few minutes to tell you a story, and then you can make up your own mind.This is a battle story from the trenches. It is a battle story about supporting and operating a production system where outages result in extensive financial losses.BackgroundWe were providing 24/7 support to a customer running a Riak[1] cluster with 6 nodes. Riak is an open source NoSQL database from Basho Technologies. The operations team were masters at general pre-emptive support. They monitored the CPU, IO, memory and the network utilisation; checked and analysed the graphs regularly. However, they weren’t Erlang or Riak experts, so we often helped them recover from the failure of individual nodes and understand and adjust their cluster configuration. What they lacked, however, was an Erlang centric view of the system.The nodes were using a relatively old version of Riak, but the DevOps team was happy with the performance. Their policy was to upgrade only when they came across issues which were fixed in later versions. We came across one of these issues that required an upgrade from to the latest stable Riak release, which at the time had reached 2.0.6. As is customary with huge hops between versions, upgrades that require no downtime are done in steps, using intermittent releases where upgrades between them have been tested thoroughly. This mitigates risk and reduces the need to customize upgrade scripts.We started preparing for this particular upgrade, planning to first upgrade to version 1.4.12, followed by an upgrade to version 2.0.6. We provided a proposal and discussed the upgrade process in detail. Our customer upgraded their test cluster to gain the necessary experience. The trial run went smoothly, resolved all of the issues they were experiencing, giving everyone, us included, a false sense of optimism. Our customer couldn’t wait to see the upgraded production cluster in action.The first upgrade to version 1.4.12 went as planned, although much slower than expected. Immediately after the upgrade, we ran our routine health checks together with the operations team. The results were positive and the cluster was able to serve all the requests. Everyone was now looking forward to upgrading to version 2.0.6. Unfortunately, it did not happen as quickly as we hoped.Early warning signsHistorically, the cluster was always close to hit its performance limits, but it always seemed to cope. The most serious problems were the large IO latency and at times, the unreliable network. The physical machines were equipped with slow disks and the network cards occasionally dropped packets. Also, the partitions handled by each Riak node were too many and too large. The cluster would have had much better performance if one or two new Riak nodes would had been added, as well as replacing the slow disks with new SSDs. Nonetheless, the cluster was able to serve requests but had no spare capacity to tolerate extra load.A week after the first upgrade (to version 1.4.12), the operations team noticed that the trends of the IO graphs had changed. Disk usage of the Riak nodes had increased dramatically (by around 600 GB per week and node) and wasn’t in line with the application’s usage pattern. Also, the memory usage of the Riak processes was increasing. Operations decided to reboot the cluster in a rol" <> ..., title: "Operational nightmare fun: dealing with misconfigured Riak Clusters", url: "https://www.erlang-solutions.com/blog/operational-nightmare-fun-dealing-with-misconfigured-riak-clusters.html"}
%{author: "by Karol Urbanski", text: "Erlang Installer: A Better Way To Use Erlang On OSX2016-09-22\n        by Karol Urbanski\n      Back in 2013, I joined Erlang Solutions to work on providing something more convenient for Erlang developers than self-compiled bundles of OTP apps. I’m happy to say that in that time, we’ve managed to significantly improve the ease of deploying Erlang on a variety of systems, especially variants of Linux.More recently, we’ve decided to make obtaining Erlang/OTP as painless as possible on OS X. To that end, we’ve recruited the wonderful people at Inaka Networks to help us create a better, slicker version of the Erlang Solutions OS X Installer.Motivation for changesThe previous iteration of the Installer supports auto-updating when a new version comes out.This can be a very useful feature for the people who like to stay on the cutting edge, but a lot of serious developers like to stick to an older version they know is supported by the software they are using. Moreover, looking around our own company, we have noticed people forgo downloading our own Installer because it does not offer an indispensable feature: the ability to quickly switch between different versions. To many devs, it is important to be able to switch to an old Erlang version in order to test a patch on a legacy system, before quickly popping back to 19.0. Some people keep 4-5 different versions of Erlang on their machine! This is why we’ve decided to change the ESL Installer to allow this kind of feature, while incorporating changes that will make the app feel more modern.InstallationInstallation of the new ESL Installer is as easy as downloading and then drag&dropping it into your Applications folder.The app will show up in the tray, and its preferences can be accessed through the OS X System Preferences.UsageWhen clicked, the tray icon expands a menu that allows you to download releases, start a shell with one of the releases you already downloaded, force a check for new releases or updates, and to quickly access the preferences.Downloading releasesThe Releases tab of the installer allows you install or uninstall various versions of Erlang. At release, we will be providing the newest version of each numbered release since R15; if you find the list is missing a version you would like to be there let us know and we’ll try to provide it for you!SettingsThe General tab of the Installer allows you to setup your preferences, including the default terminal and release you’d like to use, automatic checks for updates and automatically starting the Installer on system boot, all to ensure you stay up to date with new things in the world of Erlang.Other perksThe new Installer app should now look more similar to the other OS X apps you know and love, and instead of an ugly, annoying popup you should now be getting much less obstructive notifications.Download linkTo try out the new Installer, go to the direct link on our webpage.In conclusionWe’re hoping that the release of this new, more comprehensive ESL installer will convince some of the developers who previously found it lacking features to try it out again and see if it improves their Erlang coding experience. If you have any suggestions on features you’d like to see or improvements you think we can make, give us a note at packages@erlang-solutions.com.We thought you might also be interested in:  Erlang Solutions - what we doOur Erlang and Elixir productsErlang based tech solutionsGo back to the blog\n\nTags:Erlangerlang packagesMacOSinstaller appShare  Facebook Twitter Linkedin E-mail", title: "Erlang Installer: A Better Way To Use Erlang On OSX", url: "https://www.erlang-solutions.com/blog/erlang-installer-a-better-way-to-use-erlang-on-osx.html"}
%{author: "by Ayanda Dube", text: "RabbitMQ Monitoring WombatOAM and the RabbitMQ Management Plugin2016-10-04\n        by Ayanda Dube\n      Erlang Solutions offers world-leading RabbitMQ consultancy, support & tuning solutions. Learn more >1. Introduction If you’re a RabbitMQ user, then you must be accustomed to monitoring and keeping track of the status of your Rabbit installation by use of the native RabbitMQ Management plugin, or, alternatively, using third party monitoring tools such as Sensu, which internally make use of the RabbitMQ Management API for metrics acquisition, to present them on custom UIs. Regardless of the user’s preferred tool, a common aspect which cuts across most of these off-the-shelf tools is full dependency on the RabbitMQ Management plugin. In other words, for you to monitor and manage your RabbitMQ installation via a web interface, the RabbitMQ Management plugin has to be enabled at all times on the RabbitMQ nodes. The downside of this approach lies mainly on the overhead the RabbitMQ Management plugin introduces per each node it is enabled on. The following image depicts the accompanying and required applications introduced on a node when the RabbitMQ Management plugin is enabled;A total of 13 additional applications are required by the RabbitMQ Management Plugin, which aren’t related to, or required to run any of the AMQP operations. Internally, the RabbitMQ Management Plugin creates multiple Erlang ETS tables, which are RAM based, in order to store, aggregate and compute statistics and various RabbitMQ specific node metrics. Unless the hardware has been dimensioned to take this into account, it can place a huge demand on the node’s memory, and could potentially contribute to a number of unknown side effects when traffic load patterns vary from peak to peak. Ironically, a common recommendation in the RabbitMQ community for troubleshooting is to disable and re-enable the RabbitMQ Management Plugin!In an ideal world, RabbitMQ nodes should be dedicated to delivery of the AMQP protocol (queueing and message interchange logic between connected clients). All potential burdensome operations like UI monitoring and management should ideally be taken care of on a completely independant node; deployable on a separate physical machine from the RabbitMQ nodes, for all OAM functions. This is how telecoms systems have addressed monitoring and operations for decades. This inflexibility of the RabbitMQ Management plugin and other monitoring tools dependant on its API brings to light the main strengths and advantages of using our tool WombatOAM [4]. Illustrated below, is the application overhead WombatOAM introduces on a RabbitMQ node;So what is different about the WombatOAM approach of monitoring RabbitMQ? Firstly, only 1 additional application is introduced, which is the wombat_plugin, unlike the 13 additional applications which are introduced by the RabbitMQ Management plugin. The reason behind this is the fact that WombatOAM only requires a single and very lightweight application, which is the wombat_plugin, on the node it’s monitoring, to relay all metrics and events to a separate and independent node, responsible for carrying out all heavy computations and UI related operations. This implies a much less, if not negligible, application overhead on the RabbitMQ node in comparison to that introduced by RabbitMQ Management plugin, which carries out all of its computations and operations on the RabbitMQ node, itself.WombatOAM thus fully leverages distributed Erlang by carrying out its major operations and maintenance functions in a loosely coupled manner, on an independent and separate node. This grants much more freedom to the RabbitMQ nodes to predominantly be focused on carrying out AMQP functions, only, with very little or no chance at all, of experiencing any problems relating to UI operations and maintenance functions.NOTE: The RabbitMQ Management Plugin does attempt to reduce the amount of overhead when used in a cluster setup. Not all nodes in a cluster need the full RabbitMQ Management plugin enabled, but just one. The rest of the no" <> ..., title: "RabbitMQ Monitoring WombatOAM and the RabbitMQ Management Plugin", url: "https://www.erlang-solutions.com/blog/rabbitmq-monitoring-wombatoam-and-the-rabbitmq-management-plugin.html"}
%{author: "by Nicolas Verite, Michał Piotrowski", text: "MongooseIM 2.0.0beta2: the power of an XMPP platform, with the simplicity of a REST API2016-10-11\n        by Nicolas Verite, Michał Piotrowski\n      We are thrilled to announce the MongooseIM platform version 2.0.0beta2. MongooseIM platform 2.0.0beta2 is about one massive change: a REST API, both for backend integration, and for client/server development. This is a major step towards the game-changing version 2.0.0, which will be released in the coming weeks. MongooseIM 2.0.0 will tremendously lower the barrier of entry to our platform for most developers worldwide.REST API for backend integrationFollowing popular and obvious demand, MongooseIM now implements a new REST API, for backend integration.Integration problem for backend developers and DevOpsThe MongooseIM platform is mostly used in very large and complex infrastructures, in various types of data centers (cloud, bare metal, or hybrid). In that context, there is always a high need for tight integration and coupling between the MongooseIM platform, and the full ecosystem in the data center.For most backend developers, as well as for DevOps, this is very difficult as such an integration requires understanding the powerful hooks system in the core of MongooseIM server or the command line interface, and how they relate to the purpose of the infrastructure.It was thus very difficult to develop interconnected pieces of architectures.The obvious solution: a REST APISince most techies use modern REST APIs these days, this was the obvious and natural choice, and our customers and prospects confirmed and supported this thinking.The MongooseIM platform now offers a very simple backend REST API:management: users and sessionsmessaging:\n    send one-to-one messagessend group chat messages (both MUC and MUC light)retrieve users’ message historyThe documentation is simply the de facto standard: Swagger. With Swagger, it is even more handy, as many code generators can help build code from scratch, with little human customisation. This doc is supporting the Open API Specification. Check out the backend REST API of MongooseIM.Ease of development and maintenance, plus consistency in infrastructureAs a result, it is now much easier for backend developers to write code against MongooseIM, and maintain it. Also it is much easier for DevOps to interconnect MongooseIM with other servers. Overall, CTOs will be thrilled to have a more consistent set of backends that all discuss over REST APIs, for a seamless infrastructure maintenance experience.Further…The list of methods made available today is quite narrow, and it is on purpose: we will extend the MongooseIM REST API methods to answer your needs.REST API for the clients developersThis part may sound less understandable, maybe a bit “revolutionary” and unorthodox for an XMPP platform. To be honest, we thought a lot about it, and hesitated for a long time. But our customers and prospects have sent the signal loud and clear.Putting it simply: we are not breaking out of XMPP! We are offering the power of an XMPP platform to REST API developers worldwide!Let us walk you through this thinking.The problem with XMPP and XMLThe MongooseIM platform is based on the XMPP protocol and philosophy. And XMPP is awesome. It is an open standards protocol, backed by both the XSF and the IETF, offering high flexibility and outstanding extensibility. It is always surprising in many ways, as mature features often reveal themselves as highly efficient in modern and contemporary contexts.XMPP has evolved a lot over the years, to the point that it can look complex and too massive for a lot of developers. As a result, it might seem discouraging to learn so much for most developers.Additionally, XMPP relies on XML, which is not very trendy, to say the least. The crowds massively prefer JSON these days. We won’t argue here.As a result, a large audience of developers do not like XMPP nor XML anymore. The consequence for business owners and recruiters is that it has become difficult and painful to find good (and available) XMPP developers. It would be a missed oppor" <> ..., title: "MongooseIM 2.0.0beta2: the power of an XMPP platform, with the simplicity of a REST API", url: "https://www.erlang-solutions.com/blog/mongooseim-2-0-0beta2-the-power-of-an-xmpp-platform-with-the-simplicity-of-a-rest-api.html"}
%{author: "by Magnus Henoch", text: "Erlang (and Elixir) distribution without epmd2016-10-26\n        by Magnus Henoch\n      When you deploy a distributed Erlang application, you’ll most likely have to answer the question “which ports need to be open in the firewall?”. Unless configured otherwise, the answer is:port 4369 for epmd, the Erlang Port Mapper Daemon, andan unpredictable high-numbered port for the Erlang node itself. That answer usually doesn’t translate neatly into firewall rules. The usual solution to that is to use the environment variables inet_dist_listen_min and inet_dist_listen_max (described in the kernel documentation) to limit the distribution ports to a small port range, or even a single port.But if we’ve limited the Erlang node to a single port, do we really need a port mapper? There are a few potential disadvantages with running epmd:We may want to run epmd under the same user as the Erlang node — but as we’ll see, it can be hard to guarantee that.We may want to configure epmd to listen only on a certain interface — again, that relies on us being the first to start epmd on this host.Anyone who can connect to epmd can list the local Erlang nodes, without any authentication.Connections to epmd are not encrypted, so even if you use distribution over TLS, epmd connections are not protected, and potentially vulnerable to man-in-the-middle attacks.While epmd is very stable, it can happen that it crashes. In that case, any distributed Erlang nodes will keep running but not reconnect to epmd if it comes up again. That means that existing distribution connections will work, but new connections to those nodes cannot be made. It’s possible to fix this situation without restarting the nodes; see Экстренная реанимация epmd (in Russian). So let’s explore how epmd works, and what we can do to run an Erlang cluster without it.How does epmd get started in the first place? Let’s have a look at the code! epmd is started in the function start_epmd in erlexec.c. In fact, epmd is started unconditionally every time a distributed node is started. If an epmd instance is already running, the new epmd will fail to listen on port 4369, and thus exits silently.In fact, that’s what will happen even if the existing epmd instance was started by another user. Any epmd instance is happy to serve Erlang nodes started by any user, so usually this doesn’t cause any problem.So who can connect to epmd? Anyone! By default, epmd listens on all available interfaces, and responds to queries about what nodes are present, and what ports they are listening on. Hearing this tends to make sysadmins slightly nervous.You can change that by manually starting epmd and specifying the -address option, or by setting the ERL_EPMD_ADDRESSenvironment variable before epmd gets started. This is described in the epmd documentation. That requires that the place where you do this is actually the first place where epmd gets started — otherwise, the existing epmd instance will keep running unperturbed.Why do we need a port mapper daemon? Clearly, epmd is just the middleman. Can we cut out the middleman?We could make every Erlang node listen on a well-known port — perhaps use the port reserved for epmd, 4369, if we’re going to get rid of epmd. But that means that we can only run one Erlang node on each host (of course, for some use cases that might be enough).So let’s specify some other port number. I mentioned inet_dist_listen_min and inet_dist_listen_max earlier. Those two variables define a port range, but if we set them to the same value, we narrow down the “range” to a single port:\nerl -sname foo \\\n    -kernel inet_dist_listen_min 4370 \\\n            inet_dist_listen_max 4370 That’s all well and good, but we’d also need a way to tell other nodes not to bother asking epmd about the port number, and just use this number instead. And if we have several nodes on the same host, we’d need some kind of configuration to specify the different port numbers for those nodes.Let’s use something else In Erlang/OTP 19.0, there are two new command line options:When you specify -start_epmd false, Erlang won’t try" <> ..., title: "Erlang (and Elixir) distribution without epmd", url: "https://www.erlang-solutions.com/blog/erlang-and-elixir-distribution-without-epmd.html"}
%{author: "by Thomas Hutchinson", text: " Elixir Module Attributes - Alchemy 101: Part 12016-11-08\n        by Thomas Hutchinson\n      This is Part 1 in our Alchemy 101 series. Catch up on Part 2: From Elixir Mix Configuration to Release Configuration and Part 3: Fault Tolerance Doesn’t Come Out Of The Box.Elixir is a joy to work with, an easy installation that comes packaged with a build tool, mix. In minutes you will be creating your own applications and performing releases. Over time you will question how and why things work and behave the way they do. You may even wonder if there are better ways to do things. This is where Alchemy 101 comes in. Each edition of Alchemy 101 will address common questions that are being asked throughout the community.Today we will be looking at when module attributes are evaluated and what this means. Take a look at the Set up section and then proceed to Module Attributes.Set upYou can follow along with the examples. You will require elixir and to perform the following steps. First create a new mix project.\nmix new my_app --module Twitter\ncd my_app Next add distillery (for creating releases) to mix.exs as a dependency.\ndefp deps do\n  [{:distillery, \"~> 0.10.1\"}]\nend Then download distillery and create the release configuration.\nmix deps.get\nmix release.init The rest of the blog assumes that you are in the my_app directory.Module AttributesModule attributes can be used to annotate your module (e.g. with documentation) and add constants. Module attributes are evaluated at compile time, not runtime. Not knowing this can lead to confusion. All occurrences of the module attribute are replaced with whatever it evaluates to at compile time. I will demonstrate this below using a pattern that I’ve seen a few times.Open lib/twitter_client.ex and add the following to it.\ndefmodule Twitter do\n  require Logger\n\n  @twitter_client Application.get_env(:my_app, :twitter_client)\n\n  def log_twitter_client do\n    Logger.info(\"Using \#{@twitter_client}\")\n  end\nend There will be 2 possible values for the application’s environment configuration: twitter_client, TwitterClient and MockTwitterClient. A small side note, an application’s environment configuration shouldn’t be used for global variables. The first value is for production and the second is for test and dev. The value used will be determined by the mix config file imported by config.exs. Go ahead and add the following files.\n# config/config.exs\nuse Mix.Config\nimport_config \"\#{Mix.env}.exs\"\n\n# config/prod.exs\nuse Mix.Config\nconfig :my_app, twitter_client: TwitterClient\n\n# config/dev.exs\nuse Mix.Config\nconfig :my_app, twitter_client: MockTwitterClient So when MIX_ENV (environmental variable) is dev then config.exs will import dev.exs, when prod it will import prod.exs.Go ahead and create the release and start it in the console.\nmix release\nrel/my_app/bin/my_app consoleNow check to see if the configuration has been applied.\niex(my_app@127.0.0.1)1> Twitter.log_twitter_client()\n09:32:16.220 [info]  Using Elixir.MockTwitterClient What? Why is it using the MockTwitterClient? That’s strange. Lets check sys.config (generated from the release).\ncat rel/my_app/releases/0.1.0/sys.config\n\n[{sasl,[{errlog_type,error}]},\n {my_app,[{twitter_client,'Elixir.MockTwitterClient'}]}]. So the value of twitter_client is MockTwitterClient. This is because we ran ‘mix release’ without specifying prod as MIX_ENV (defaults to dev). No big deal, lets just change sys.config to the following, restart the application and check again.\n[{sasl,[{errlog_type,error}]},\n {my_app,[{twitter_client,'Elixir.TwitterClient'}]}].\n\nrel/my_app/bin/my_app console\niex(my_app@127.0.0.1)1> Twitter.log_twitter_client()\n09:32:16.220 [info]  Using Elixir.MockTwitterClient The mock is still showing, but why? As mentioned before module attributes are evaluated at compile time, not runtime. All occurrences of @twitter_client at compile time were replaced with MockTwitterClient, it just so happens that this value came from a configuration file thus giving us the illusion that it can be changed.To have TwitterClient we must create another release and set" <> ..., title: " Elixir Module Attributes - Alchemy 101: Part 1", url: "https://www.erlang-solutions.com/blog/elixir-module-attributes-alchemy-101-part-1.html"}
%{author: "by Nicolas Verite", text: "MongooseIM platform 2.0.0: higher value and lower friction2016-11-14\n        by Nicolas Verite\n      If you haven’t heard of MongooseIM before, it is a mobile messaging platform that provides massive scalability and allows mobile and web app builders to add chat features to their new or existing apps.In the past months we worked hard on improving MongooseIM for all, and we managed to significantly lower the pain of integration by making it easier and faster; and lowering the barrier of entry for developers. The new features allow the addition of innovative real-time, social features to existing apps. Globally, the MongooseIM platform enables higher acquisition, retention, and engagement, by leveraging high-density, real-time network effects.In this post we will walk you through all the changes that differentiate the MongooseIM platform on the market. You can also join our webinar on 24 November at 16:00, where myself and my colleague Ludwik Bukovski will talk about the most important features and answer your questions. Enjoy the read and let others read it too, so share and comment below!Executive summary The purpose of this article is to update MongooseIM enthusiasts who are already familiar with the previous versions of MongooseIM.MongooseIM has made a huge jump forward with version 2.0.0 and its platform. Here are the major changes:Pivot from standalone server to a platform: you now benefit from the consistency of a platform, as we provide validated and consistent components, both on the client-side and the server-side so that you can integrate fasterA REST API, both on the client-side and the server-side, for a more natural and logical integration with the modern developer cultureA modern and simple group chat called “MUC light” (Multi-User Chat light), highly useful from fast prototyping to massively scalable production systemsPubSub, or Publish-and-Subscribe, for social innovation, in order to increase the value of your network, thus accelerating your growthAndroid and iOS libraries allow you to move at light-speed and deliver incredibly fast iterations with full confidenceWombatOAM plugins, for high transparency of running systems, both for optimisation purposes and metrics for business visibilityUseful documentation improvements that will help you plan and anticipate betterLarger range of tests for better trust in every single code change From server to platform, for consistency This change is important for both those in tech roles (developer, devops, sysadmin) and those in executive positions (CTO, COO, founder, owner).Integrating a discrete, standalone open source server is often a difficulty: although client/server interoperability is guaranteed by the strict use of open standards, the available third party software is not always consistent with the server in terms of features: some may lack in one side or the other.The consequences are that you still have to code for yourself, and potentially contribute the missing pieces. This slows you down and is quite costly.We now offer feature parity with the server. Features that have been designed, tested, and validated in real life together with the client and the server. Either we used our own backend software components, or we contributed to third party open source software components.. MongooseIM platform is made of:MongooseIM serverWombatOAM systemXMPPFramework and Jayme for iOSSmack and Retrofit for AndroidEscalus, an XMPP client written in Erlang, for functional testingFor all components in the platform, we consistently support features: the same as those available on the server. It allows you to integrate much faster, with significantly lower costs, and bring your products to market much faster.REST API: lowering the barrier of entry Maybe the most important of the new features on the platform is the REST API on two sides of the server: server-server for backend integration, and client/server for client development.Frontend, client-side: light speed developmentThis improvement will make a lot of client developers happy, regardless if they are mobile or web dev" <> ..., title: "MongooseIM platform 2.0.0: higher value and lower friction", url: "https://www.erlang-solutions.com/blog/mongooseim-platform-2-0-0-higher-value-and-lower-friction.html"}
%{author: "by Andres Canal", text: "Build a complete iOS messaging app using XMPPframework-tutorial-part 12016-11-30\n        by Andres Canal\n      YAXT??! Yet another XMPP tutorial? Well, this is going to be another tutorial, but I’m going to try to make it a little bit different. This is an XMPP tutorial from an iOS developer’s perspective. I’ll try to answer all the questions I had when I started working in this area. This journey is going to go from no XMPP knowldege at all to having a fully functional instant messaging iOS app using this cool protocol. We are going to be using the super awesome (yet overwhelming at the beginning…) XMPPFramework library, and the idea is also to also mix in some iOS concepts that you are going to need for your app.What’s XMPP? From Wikipedia: Extensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML.This basically means XMPP is a protocol for exchanging stuff. What kind of stuff? Messages and presences. We all know what messages are, but what about presences? A presence is just a way of sharing a “status”, that’s it. You can be ‘online’, 'offline’, 'having lunch’, or whatever you want. Also there’s another important word: Extensible meaning it can grow. It started as an instant messaging protocol and it has grown into multiple fields for example IoT (Internet of Things). And last, but not least: every piece of information we are going to exchange under this protocol is going to be XML. I can heard you complaining but… Come on, it’s not that bad!Why do we need XMPP? Why not just REST? Well what other options do we have? On the one hand, a custom solution means building everything from scratch, that takes time. On the other hand, we have XMPP, a super tested technology broadly used by millions of people every day, so we can say that’s an advantage over a custom approach.Everytime I talk about XMPP, someone asks me 'Why not just REST?’. Well, there is a misconception here. REST is not a protocol, it’s just a way of architecting a networked application; it’s just a standarized way of doing something (that I love btw). So let’s change the question to something that makes more sense: “Why not just build a custom REST chat application?”. The first thing that comes to my mind is what I already explained in the previous paragraph, but there is something else. How do I know when someone has sent me a message? For XMPP this is trivial: we have an open connection all the time so, as soon as a message arrives to the server, it will send us the message. We have a full-duplex. On the other hand, the only solution with REST is polling. We will need to ask the server for new messages from time to time to see if there is something new for us. That sucks. So, we will have to add a mechanism that allows us to receive the messages as soon as they are created, like SSE or WebSockets.There is one more XMPP advantage over a custom REST chat application. REST uses HTTP, an application level protocol that is built on top of a transport level protocol: TCP. So everytime you want to use your REST solution, you will need HTTP, a protocol that is not always available everywhere (maybe you need to embed this in a cheap piece of hardware?). Besides, we have XMPP built on top of TCP that’s going to be always available.What’s the basic stuff I need to know to get started? Well, you know a lot already but let’s make a list. Lists are always good:XMPP is built on top of TCP. It keeps an open connection all the time.Client/Server architecture. Messages always go through a server.Everything we send and receive is going to be XML and it’s called Stanza.We have three different types of stanzas: iq, message and presence.Every individual on the XMPP network is univocally identified by a JID (Jabber ID).All the stanzas are cointained in a Stream. Let’s imagine the Stream as a white canvas where you and the server write the stanzas.Stream, iq, message and presence are the core of XMPP. You can find everything perfectly detailed in RFC6120XMPP can be extended to accomplish different stuff. Each exten" <> ..., title: "Build a complete iOS messaging app using XMPPframework-tutorial-part 1", url: "https://www.erlang-solutions.com/blog/build-a-complete-ios-messaging-app-using-xmppframework-tutorial-part-1.html"}
%{author: "by Andres Canal", text: "Build a complete iOS messaging app using XMPPFramework - Part 22017-01-12\n        by Andres Canal\n      First steps: XMPPFrameworkBuild a complete iOS messaging app using XMPPFramework is a tutorial that shows you how to build a fully functional instant messaging iOS app using the very cool XMPPFramework protocol and Swift3. In this part, we are going to get our hands dirty! To recap on the theory, or if you just landed here randomly, have a quick read through the first part, then get your Xcode ready and let’s start!In this issue we are going to be integrating the library to our project, creating a connection with the server and authenticating. The XMPPFramework library is the most used XMPP library for iOS and macOS. At the beginning it may be a little bit overwhelming but after a few days working with it you will learn to love it.Installing the libraryLet’s create a brand new Xcode project and install the library. In this tutorial we are going to be using Swift 3. The easiest way to integrate XMPPFramework to the project is using CocoaPods.Let’s create our Podfile using the pod init command in the folder where our .xcodeproj lives. There are thousands of forks but the maintained one is the original: robbiehanson/XMPPFramework.So let’s add the pod to our Podfile and remember to uncomment the use_frameworks!.use_frameworks!\n\ntarget 'CrazyMessages' do\n    pod 'XMPPFramework', :git=> 'git@github.com:robbiehanson/XMPPFramework.git', :branch => 'master'\nend\n Then pod install and CocoaPods is going to do its magic and create a .xcworkspace with the library integrated. Now we just need to import XMPPFramework in the files we want to use the library and that’s it. Starting to build our Instant Messaging appThe most important thing in an XMPP application is the stream, that’s where we are going to “write” our stanzas, so we need an object that is going to hold it. We are going to create an XMPPController class with an XMPPStream:import Foundation\nimport XMPPFramework\n\nclass XMPPController: NSObject {\n    var xmppStream: XMPPStream\n\n    init() {\n        self.xmppStream = XMPPStream()  \n    }\n\n}\n We are dealing with a highly asynchronous library here. For every action we are going to have a response some time in the future. To handle this XMPPFramework defines the XMPPStreamDelegate. So implementing that delegate is going to help us answer lots of different questions like: “How do I know when XMPP has successfully connected?”, “How do I know if I’m correctly authenticated?”, “How do I know if I received a message?”. XMPPStreamDelegate is your friend!So we have our XMPPController and our XMPPStream, what do we need to do now? Configure our stream with the hostName, port and ourJID. To provide all this info to the controller we are going to make some changes to the init to be able to receive all these parameters:enum XMPPControllerError: Error {\n    case wrongUserJID\n}\n\nclass XMPPController: NSObject {\n    var xmppStream: XMPPStream\n\n    let hostName: String\n    let userJID: XMPPJID\n    let hostPort: UInt16\n    let password: String\n\n    init(hostName: String, userJIDString: String, hostPort: UInt16 = 5222, password: String) throws {\n        guard let userJID = XMPPJID(string: userJIDString) else {\n            throw XMPPControllerError.wrongUserJID\n        }\n\n        self.hostName = hostName\n        self.userJID = userJID\n        self.hostPort = hostPort\n        self.password = password\n\n        // Stream Configuration\n        self.xmppStream = XMPPStream()\n        self.xmppStream.hostName = hostName\n        self.xmppStream.hostPort = hostPort\n        self.xmppStream.startTLSPolicy = XMPPStreamStartTLSPolicy.allowed\n        self.xmppStream.myJID = userJID\n\n        super.init()\n\n        self.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main)\n    }\n}\n Our next step is going to actually connect to a server and authenticate using our userJID and password, so we are adding a connect method to our XMPPController.func connect() {\n    if !self.xmppStream.isDisconnected() {\n        return\n    }\n\n   try! self.xmppStream.connect(w" <> ..., title: "Build a complete iOS messaging app using XMPPFramework - Part 2", url: "https://www.erlang-solutions.com/blog/build-a-complete-ios-messaging-app-using-xmppframework-part-2.html"}
%{author: "by Thomas Hutchinson", text: "From Elixir Mix configuration to release configuration - Alchemy 101 Part 22017-01-19\n        by Thomas Hutchinson\n      This is Part 2 in our Alchemy 101 series. Catch up on Part 1: Elixir Module Attributes and Part 3: Fault Tolerance Doesn’t Come Out Of The Box.Today we will be looking at what happens to your Mix configuration when you perform a release. Take a look at the Set up section and then proceed to Application Configuration.Set upYou can follow along with the examples. You will require elixir and to perform the following steps.First create a new mix project.\nmix new my_app --module Twitter\ncd my_app Next add distillery (for creating releases) to mix.exs as a dependency.\ndefp deps do\n  [{:distillery, \"~> 0.10.1\"}]\nend Then download distillery and create the release configuration.\nmix deps.get\nmix release.init The rest of the blog assumes that you are in the my_app directory.Application ConfigurationWhen creating an Elixir OTP Application you will most probably need some configuration. There are 4 ways to supply application configuration on startup.       1. In your mix.exs file. Here you can specify default application environment variables. This file is used to generate the .app file which is used to start your application. Run ‘mix help compile.app’ for more information       2. In your config/config.exs file, this compiles down to sys.config. Alternatively with distillery you can supply your own sys.config file.       3. With an additional .config file. From what I can see distillery and exrm don’t seem to support this out the box. You can find out more here on how to use it.       4. You can supply it to the Erlang VM when it starts up. Distillery supports this via erl_opts in rel/config.exs. Simply add “-Application Key Value” to it for each application configuration variable e.g. set erl_opts: “-my_app magic_number 42”.From what I have seen most people tend to go with the option 2, supplying configuration via config/config.exs. As configuration is an Elixir script it gives us the potential to be very creative. When creating a release (with exrm or distillery) config.exs (by default) is evaluated and the result is written to rel/$app/releases/$version/sys.config which is picked up by your application on startup. Not knowing this can lead to confusion. Here comes another example where this can happen.Open lib/twitter_client.ex and add the following to it.\ndefmodule Twitter do\n  require Logger\n\n  def log_twitter_url do\n    url = Application.get_env(:my_app, :twitter_url)\n    Logger.info(\"Using \#{url}\")\n  end\nend\n Now add the following to config/config.exs.\nconfig :my_app, twitter_url: System.get_env(\"TWITTER_URL\")Pretty nice eh? It appears like we can get TWITTER_URL at runtime. Lets create the release and inspect it. Run the following.\nexport TWITTER_URL=\"https://api.mock.com\"\nMIX_ENV=prod mix release\n./rel/my_app/bin/my_app console\niex(my_app@127.0.0.1)1> Twitter.log_twitter_url()\n17:26:05.270 [info]  Using https://api.mock.twitter.com Perfect! Everything looks good, the url to the mock is being used. Just what I want during development. Now I want to test the integration with the real twitter API, time to change TWITTER_URL.\nexport TWITTER_URL=\"https://api.twitter.com/1.1\" Start your release in the console and invoke Twitter.log_twitter_url/0.\n./rel/my_app/bin/my_app console\niex(my_app@127.0.0.1)1> Twitter.log_twitter_url()\n17:26:05.270 [info]  Using https://api.mock.com Strange! It is still using the mock url, but why? As mentioned before when creating a release the configuration is evaluated and written to sys.config. Lets take a look.\ncat rel/my_app/releases/0.1.0/sys.config \n\n[{sasl,[{errlog_type,error}]},\n {my_app,[{twitter_url,<<\"https://api.mock.com\">>}]}]. As you can see twitter_url is “https://api.mock.com”. When the release is being created config.exs is evaluated and the results are placed in sys.config. Part of this involved executing System.get_env(“TWITTER_URL”) and having “https://api.mock.com” returned.This doesn’t have to be a problem though as you can set Application configuration at runt" <> ..., title: "From Elixir Mix configuration to release configuration - Alchemy 101 Part 2", url: "https://www.erlang-solutions.com/blog/from-elixir-mix-configuration-to-release-configuration-alchemy-101-part-2.html"}
%{author: "by Nicolas Vérité", text: "MongooseIM 2.0.1 more stability for app developers2017-02-22\n        by Nicolas Vérité\n      SSE for server to client real-time pushSSE stands for Server-Sent Events, it is a W3C recommendation where a browser receives automatic updates from a server via HTTP connection. It is for mobile and web developers using the MongooseIM REST API. It is not intended to be used with XMPP connections (TCP, websockets, BOSH).The problem with a simple REST API is that it is polling only: the client has to continuously poll the server at regular intervals, even when there is nothing to expect, “just in case”. This regular polling consumes a lot of battery on the client and bandwidth both on the client and server, all for nothing. Also, this introduces some delay, as data can be made available on the server between the polling interval.SSE allows a very simple and basic push from server to client, with just a tiny library to use in your app. SSE is very easy to integrate on the client, saves battery and bandwidth, and is fully real-time (no delay).Improved Cassandra for MAMSysadmins and devops will love the return of support for the Cassandra database.Our support for Cassandra in versions below 2.0.0 was average. Sometimes it was slow, and it had limited support of MAM (Message Archive Management) specifications, so we decided to remove it and bring it back once it was fully production ready.Now MongooseIM supports Cassandra again, with optimised code and improved support for MAM, and it comes bundled with a migration tool. Cassandra for MAM in MongooseIM is now faster and easier to upgrade.HTTP file uploadThis will help all app makers.The file exchange in XMPP is usually and historically off chats: it is made with a synchronous user experience, with an offer and an acceptation or refusal whereby you have to wait for the other party to accept or refuse. In many cases there are failures due to timeouts.The solution is an asynchronous user experience: you send files in chats, whether your contacts are online or not, available or not. You now have a single timeline with text messages and (links to) media files. It is also compatible with archiving.Further improvementsMUC hibernationAll the old and inactive MUC rooms are now hibernated and eventually flushed out of memory, which saves a significant amount of memory on the cluster.ODBC/RDBMS backend for MUC lightMUC light was only available on Mnesia, now it can also be stored in MySQL or PostgreSQL.Simplified MAM configurationBefore, MAM had to be configured in many ways in multiple places. Now, it is done in one central place, and there is fewer things to configure.ChangelogPlease feel free to read the raw changelog, you can even follow links and find the code changes.Special thanks to our contributors!Special thanks to our contributors: @kenstir, @sstrigler, @igors, @bernardd, @msantos!Next?From 2.0.0 to 2.0.1: please upgrade!Version 2.0.1 will probably be the last of the 2.0.x series, unless major issues are found. As this is a massive improvement, we advise everyone to upgrade.We are now focusing on the development of the 2.1.x series. This will deliver even more value to mobile developers and sysadmins.Mobile clients: social and groupsWe are planning to release open source iOS and Android clients. Please do not expect market killer apps. The aim is very limited: we want to provide a technology and use case demonstration.Mangosta iOS and Mangosta Android will deliver very basic group chat and social network. For example, these will not be distributed on mobile app stores, they will only be available as source code on our repositories.Flexible push notificationsYou can expect more improvements on the push notifications front. We have now an existing generic mod _ http _ notification, we will add push to Amazon SNS (Simple Notification Service) and XEP-0357: Push Notifications.Peer to peer or mediated binary streamingWe will deliver an ICE/STUN/TURN server, coded in Elixir, to allow peer to peer and one to one media streaming, like voice, video, screen sharing, and whiteboarding. The signa" <> ..., title: "MongooseIM 2.0.1 more stability for app developers", url: "https://www.erlang-solutions.com/blog/mongooseim-2-0-1-more-stability-for-app-developers.html"}
%{author: "by Piotr Nosek", text: "XMPP Protocol Use-Cases and Guide | Erlang Solution blog2017-03-02\n        by Piotr Nosek\n      Who will find this interestingIf you’re considering XMPP for your project but you are unsure if it can provide the functionality you need, you’ll eventually end up here:http://xmpp.org/extensions/I’m pretty sure you’ll be quite intimidated by such a long list of extensions. In some cases it will be pretty easy to find what you need. If you look for PubSub functionality, you’ll quickly notice “Publish-Subscribe”. Sometimes it’s not so obvious though. XMPP developers already know that in order to synchronise outgoing messages between several devices, they have to enable “Message Carbons”. Not very intuitive, isn’t it?The aim of this blog post is to guide you towards proper XMPP technologies and solutions, given your specific use cases. I’ve worked with and deployed solutions powered by XMPP, such as MongooseIM, for years; so let me be your personal Professor Oak, providing a perfect “companion(s)” to work with and begin your journey in XMPP world. There are almost 400 XEPs, will you catch them all? ;)The length of this article is caused not by a complexity of descriptions but by a count of use cases and features. :)All numbers and information on implementation status are valid for March 2017.What can you expect here?For every use case, I will list XMPP features you definitely should consider using. Each one of them will be briefly described. The goal here is to understand the usefulness without reading whole specification. Besides that, each item will include MongooseIM’s module name providing discussed extension and example client implementations. What you won’t find in this postThis post won’t cover any XMPP basics. It assumes you either know them already (what are JID, C2S, S2S, IQ, stanzas, stream etc.) or you intend to learn them from some other guide, like the excellent (iOS) tutorial written by Andres Canal Part 1, Part 2). It’s more of a cookbook, not Cooking For Dummies.ToCI’m creating …\n\n1.1 … a mobile application.\n\n1.2 … a desktop application.\n\n1.3 … a web application.\n\n1.4 … an application that just can’t speak XMPP.I need my application to …\n\n2.1 … show message status like Facebook does.\n\n2.2 … provide message archive to end users.\n\n2.2.1 I’d like to have a full text search feature.… display inbox (a list of conversations with unread count and a last message).… allow file transfers and media sharing between users.\n\n4.1 P2P\n\n4.2 File Upload… support groupchats …\n\n5.1 … and I need precise presence tracking in each group.\n\n5.2 … and I don’t need to broadcast presence information in each group.… be compatible with other public XMPP setups.… present the same view of each conversation on every user’s device.… allow users to block each other.… support end-to-end encryption.… be a part of Internet of Things.… receive push notifications.… publish messages to groups of subscribers.1. Creating …Before we proceed to more specific requirements, it’s important to identify crucial standards based on your application type.1.1 … a mobile application.Smartphones are omnipresent nowadays. It’s a fact. The whole software market considered, mobile apps are an important medium between various companies and their customers. Some of them are the actual products (games, communicators, car navigations, etc.), not only a “channel”. If you’re going to develop a mobile application, you will need…XEP-0198 Stream ManagementIt’s an extension that provides two features actually. One of them is stanza delivery confirmation (both server and client side), what allows early detection of broken connections or malfunctioning network layer. The other one is stream resumption. It makes reconnection faster by reducing the round-trip count and relieves the client of fetching message archive as pending, unacknowledged messages will be retransmitted from server buffer.It is enabled by default in MongooseIM and supported by major client libs like Smack or XMPPFramework. From a client developer perspective, it’s pretty transparent because the whole extension is " <> ..., title: "XMPP Protocol Use-Cases and Guide | Erlang Solution blog", url: "https://www.erlang-solutions.com/blog/xmpp-protocol-use-cases-and-guide-erlang-solution-blog.html"}
%{author: "by Karol Urbanski", text: "Erlang OS X Installer: Official Release2017-03-15\n        by Karol Urbanski\n      An update to the Erlang Solutions OTP InstallerWith Erlang/OTP 19.3 coming out today, we’ve decided to release our new Erlang Solutions OS X Installer. From now on, the old installer should be considered deprecated. During the Erlang/OTP 20 release cycle, it will stop being provided for new versions. The new installer is now our recommended option.Fear not, though! The new installer has a whole slew of options that are likely to please any serious coder. I’ve summarised them for you in this post.Motivation for changesThe previous iteration of the Installer supports auto-updating when a new version comes out.This can be a very useful feature for the people who like to stay on the cutting edge, but a lot of serious developers like to stick to an older version they know is supported by the software they are using. Moreover, looking around our own company, we have noticed people forgo downloading our own Installer because it does not offer an indispensable feature: the ability to quickly switch between different versions. To many devs, it is important to be able to switch to an old Erlang version in order to test a patch on a legacy system, before quickly popping back to 19.0. Some people keep 4-5 different versions of Erlang on their machine! This is why we’ve decided to change the ESL Installer to allow this kind of feature, while incorporating changes that will make the app feel more modern.InstallationInstallation of the new ESL Installer is as easy as downloading and then drag&dropping it into your Applications folder.The app will show up in the tray, and its preferences can be accessed through the OS X System Preferences.UsageWhen clicked, the tray icon expands a menu that allows you to download releases, start a shell with one of the releases you already downloaded, force a check for new releases or updates, and to quickly access the preferences.Downloading releasesThe Releases tab of the installer allows you install or uninstall various versions of Erlang.SettingsThe General tab of the Installer allows you to setup your preferences, including the default terminal and release you’d like to use, automatic checks for updates and automatically starting the Installer on system boot, all to ensure you stay up to date with new things in the world of Erlang.Other perksThe new Installer app should now look more similar to the other OS X apps you know and love, and instead of an ugly, annoying popup you should now be getting much less obstructive notifications.Download linkTo try out the new Installer, go to the direct link on our webpage.In conclusionWe at Erlang Solutions and Inaka Networks hope you have an excellent experience with the new Installer! Please report any feedback here, or on Twitter.Go back to the blog\n\nTags:ErlangOTP installerinstaller appMacOSerlang packagesShare  Facebook Twitter Linkedin E-mail", title: "Erlang OS X Installer: Official Release", url: "https://www.erlang-solutions.com/blog/erlang-os-x-installer-official-release.html"}
%{author: "by Gabriele Santomaggio", text: "Scaling RabbitMQ on a CoreOS cluster through Docker2017-03-22\n        by Gabriele Santomaggio\n      Erlang Solutions offers world-leading RabbitMQ consultancy, support & tuning solutions. Learn more >IntroductionRabbitMQ provides, among other features, clustering capabilities.\nUsing clustering, a group of properly configured hosts will behave the same as a single broker instance.All the nodes of a RabbitMQ cluster share the definition of vhosts, users, and exchanges but not queues. By default they physically reside on the node where they have been created, however as from version 3.6.1, the queue node owneriship can be configured using Queue Master Location policies. Queues are globally defined and reachable, by establishing a connection to any node of the cluster. Modern architectures often involve container based ways of scaling such as Docker .  In this post we will see how to create a dynamic scaling RabbitMQ cluster using \nCoreOS and Docker:We will take you on a step by step journey from zero to the cluster. Get readyWe are going to use different technologies, although we will not get into the details of all of them. For instance it is not required to have a deep CoreOS/Docker \nknowledge for the purpose of executing this test.It can be executed using your pc, and  what you need is: VagrantVirtualBoxGit\n\nWhat we will do:Configure CoreOS cluster machinesConfigure Docker SwarmConfigure RabbitMQ docker clusterConfigure CoreOS cluster machinesFirst we have to configure the CoreOS cluster:1. Clone the vagrant repository:$ git clone https://github.com/coreos/coreos-vagrant\n$ cd coreos-vagrant\n2. Use the user-data example file:$ cp user-data.sample user-data\n3. Configure the cluster parameters:$ cp config.rb.sample config.rb\n4. Open the file then uncomment num_instances and change it to 3, or execute: sed -i.bk  's/$num_instances=1/$num_instances=3/' config.rb\n5. Start the machines using vagrant up:$ vagrant up\nBringing machine 'core-01' up with 'virtualbox' provider...\nBringing machine 'core-02' up with 'virtualbox' provider...\nBringing machine 'core-03' up with 'virtualbox' provider…\n6. Add the ssh key:ssh-add ~/.vagrant.d/insecure_private_key7. Use vagrant ssh core-XX -- -A to login, ex:$ vagrant ssh core-01 -- -A \n$ vagrant ssh core-02 -- -A \n$ vagrant ssh core-03 -- -A \n8. Test your CoreOS cluster, login to the machine core-01:$ vagrant ssh core-01 -- -AThencore@core-01 ~ $ fleetctl list-machines\nMACHINE     IP      METADATA\n5f676932... 172.17.8.103    -\n995875fc... 172.17.8.102    -\ne4ae7225... 172.17.8.101    -\n9. Test the etcd service:core@core-01 ~ $ etcdctl set /my-message \"I love Italy\"\nI love Italy\n10. Login to vagrant ssh core-02:$ vagrant ssh core-02 -- -A\ncore@core-02 ~ $ etcdctl get /my-message\nI love Italy\n11. Login to vagrant ssh core-03:vagrant ssh core-02 -- -A\ncore@core-03 ~ $ etcdctl get /my-message\nI love Italy\nAs result you should have:12. Test Docker installation using docker -v :core@core-01 ~ $ docker -v\nDocker version 1.12.3, build 34a2ead\n13. (Optional step)  Run the first image with docker run :core@core-01 ~ $  docker run ubuntu /bin/echo 'Hello world'\n…\nHello world\nThe CoreOS the cluster is ready, and we are able to run Docker inside CoreOS.\nLet’s test our first RabbitMQ docker instance:14. Execute the official RabbitMQ docker image:core@core-01 ~ $ docker run -d --hostname my-rabbit --name first_rabbit -p 15672:15672 rabbitmq:3-management \n15. Check your eth1 vagrant IP (used to access the machine) :core@core-01 ~ $ ifconfig | grep -A1 eth1\neth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n      inet 172.17.8.101  netmask 255.255.255.0  broadcast 172.17.8.255\nGo to http://<your_ip>:15672/#/ in this case: http://172.17.8.101:15672/#/.You should see the RabbitMQ management UI as (guestguest ):In order to scale up  the node above, we should run another container with --link parameter and execute rabbitmqctl join_cluster rabbit@<docker_host_name>. In order to scale down we should stop the second container and execute  rabbitmqctl forget_cluster_node rabbit@<docker_host_name>.Turn into m" <> ..., title: "Scaling RabbitMQ on a CoreOS cluster through Docker", url: "https://www.erlang-solutions.com/blog/scaling-rabbitmq-on-a-coreos-cluster-through-docker.html"}
%{author: "by Nicholas Reid, SVP of Product Management, Vidyo", text: "How Would the World Embrace Video Collaboration if it Couldn’t Scale? 2017-03-28\n        by Nicholas Reid, SVP of Product Management, Vidyo \n      “How would the world embrace video collaboration if it couldn’t scale?”This is a big question that Vidyo spotted early on, way back in 2005, as it set out to pioneer the next generation of video conferencing. Video collaboration at that time was primarily used for communicating between one traditional conference room to another. Since then, the world has changed. Today, in a time when “the office” can increasingly mean “pretty much anywhere” for millions of workers, (and consumer-facing apps are turning to video to service millions of customers), building a scalable video platform presents a new set of requirements. We are happy to share what we’ve learned over the years with developers who are interested in the next wave of video communications. At 1 PM EST on 3/29, join us for our “Building a Global Video Chat Platform for Developers” webinar, as we discuss the challenges faced and solved when building a developer platform that delivers real-time, mobile, multiparty video. UPDATE: The webinar was recorded - watch it now.Today’s video collaboration landscapeToday, clear and reliable video collaboration has lept out of the conference room and into our pockets, letting us hop on a video call from our smartphone or tablet while on the train, in the airport or on the road - with more or less the same audio/visual quality as a dedicated room system that enjoys a perfect ethernet connection and high bandwidth. When hundreds of people can reliably connect face-to-face at the same time, from wherever they happen to be, this method of communicating is proving to be transformative for critical fields like healthcare, banking, government and education. This is especially true as we work to make nuisances like dropped calls, lag, grainy or blurry visuals and frozen screens a thing of the past - and stunning levels of clarity and consistency become more of the norm, from basically anywhere. Behind the scenesVidyo has diligently developed patented adaptive video layering and routing technologies that have ultimately given us a reputation as the go-to enterprise-grade video service, especially among industries with tight regulations and high security demands. For years, global enterprises have video-enabled their applications using our APIs and SDK. Now, however, the video conferencing market is shifting to embedded video - with the vision that developers should be able to easily video-enable any application on virtually any device - effectively “video-enabling the world”. When we decided to make the shift to embedded video and roll out our video API platform, Vidyo.io, we knew that our customers would continue to demand Vidyo’s specific brand of mobile, multiparty video that is highly scalable, without sacrificing its quality. Spoiler: it’s not all plain sailingOne of the challenges today of offering high-quality video collaboration at scale, is signaling. Initially, we built our own signaling protocol. We had a very scalable platform that was ideal for our enterprise customers, which could easily scale to tens of thousands of users. But, with Vidyo.io, we were building a global video API platform to be used to video-enable any concept or idea that application developers could think of, whether for enterprise business or consumer-facing applications. We chose MongooseIM because we needed signaling that could scale to millions of users. Why MongooseIM was the solution for usWe found MongooseIM to be simple, flexible and reliable, and designed for this type of global Internet scale. XMPP is the battle-hardened standard, with the interoperability and classical benefits (like chat, historical chat, etc.) that we, as a uniquely enterprise-grade service, needed for an architecture that could get to 99.999% uptime.This is how video collaboration has lept out of the conference room and into the pockets of millions of people around the world. As we brought Vidyo.io, to market, our priorities includ" <> ..., title: "How Would the World Embrace Video Collaboration if it Couldn’t Scale? ", url: "https://www.erlang-solutions.com/blog/how-would-the-world-embrace-video-collaboration-if-it-couldn-t-scale.html"}
%{author: "by Thomas Hutchinson", text: "Fault Tolerance doesn't come out of the box - Alchemy 101: Part 32017-03-29\n        by Thomas Hutchinson\n      Alchemy 101: Part 3 - Fault Tolerance doesn’t come out of the boxThis is Part 3 in our Alchemy 101 series. Catch up on Part 1: Elixir Module Attributes and Part 2: From Elixir Mix Configuration to Release Configuration.One of the biggest selling points of Elixir is the means it gives you to write fault tolerant applications via its concurrency model. Processes can broadcast their failure to dependant processes which can take appropriate action. You decide how processes should respond to failure based on your use case. There is no single solution. I’ll give you an example in which not handling failure led to, you guessed it, more failure.First install and start RabbitMQ.Then create a new project. mix new rabbit --module Rabbit\ncd rabbit\nThen add the amqp dependency to mix.exs.defpdepsdo[{:amqp,\"~> 0.1.5\"}]endNow add the following to lib/rabbit.ex.defmoduleRabbitdouseGenServerrequireLoggerdefstart_linkdoGenServer.start_link(__MODULE__,nil)enddefinit(_)do{:ok,connection}=AMQP.Connection.open(\"amqp://localhost\"){:ok,channel}=AMQP.Channel.open(connection){:ok,channel}enddefpublish(pid,payload)doGenServer.cast(pid,{:publish,payload})enddefhandle_cast({:publish,payload},channel)doAMQP.Basic.publish(channel,\"\",\"\",payload)Logger.info(\"Published \#{payload}\"){:noreply,channel}endendThat’s all you need, fetch the dependencies and test Rabbit.mixdeps.getiex-Smixiex(1)>{:ok,pid}=Rabbit.start_link(){:ok,#PID<0.139.0>}iex(2)>fori<-1..3,do:Rabbit.publish(pid,\"message \#{i}\")19:21:31.471[info]Publishedmessage119:21:31.471[info]Publishedmessage219:21:31.471[info]Publishedmessage3Head to the default exchange and you should see some activity on the Message rates chart. Keep the above IEx shell open, you will need it again soon.Time to introduce a problem. Restart RabbitMQ.brew services restart rabbitmq\nGo back to the IEx shell, notice how there is an OTP error report. Looks serious, the main takeaway from it is below. The socket to RabbitMQ closed causing a process to crash.19:22:57.994 [error] GenServer #PID<0.142.0> terminating\n** (stop) :socket_closed_unexpectedly\nLast message: :socket_closed\nBut it still appears like you can publish messages. Try it.iex(3)> for i <- 1..3, do: Rabbit.publish(pid, \"message \#{i}\")\n19:21:31.471 [info]  Published message 1\n19:21:31.471 [info]  Published message 2\n19:21:31.471 [info]  Published message 3\nBut if you head to the default exchange there appears to be no new messages coming in. But why? First of all we don’t see any failures in the Rabbit process because AMQP.Basic.publish/4 ultimately leads to a :gen_server.cast/2 (amqp_channel.erl in rabbit_common) being called with channel.pid. :gen_server.cast/2 will not return or throw an error if the PID (in this case channel.pid) does not exist. This means the failure was hard to detect. Now imagine if your application was running in the background, this could have been even more difficult to spot.Here comes the good part, how to handle the failure. We want Rabbit to be sent a message when the socket to RabbitMQ is closed. To do this we need to link to the channel process (to receive an exit message if it stops) we started and trap exits i.e. not crash if we receive an exit signal. To do this add the following code.definit(_)do{:ok,connection}=AMQP.Connection.open(\"amqp://localhost\")Process.flag(:trap_exit,true){:ok,channel}=AMQP.Channel.open(connection)Process.link(connection.pid){:ok,channel}enddefhandle_info({:EXIT,from,:socket_closed_unexpectedly},channel)doLogger.warn(\"Received :EXIT from \#{inspect(from)} for \#{:socket_closed_unexpectedly}\"){:stop,:lost_rabbitmq_connection}endKill and start the IEx shell and then run the following.brew services restart rabbitmq\nJump to the IEx shell and observe the output.19:27:33.497 [warn]  Received :EXIT from #PID<0.142.0> for :socket_closed_unexpectedly\nPerfect, now when the socket is closed the dependent process, Rabbit, is informed. Now to respond to the failure. This is something you must decide, no one includ" <> ..., title: "Fault Tolerance doesn't come out of the box - Alchemy 101: Part 3", url: "https://www.erlang-solutions.com/blog/fault-tolerance-doesn-t-come-out-of-the-box-alchemy-101-part-3.html"}
%{author: "by Michał Piotrowski", text: "MongooseIM 2.1.0beta1 what happens when you give your team freedom2017-04-13\n        by Michał Piotrowski\n      MongooseIM is a highly technical platform for businesses to build messaging and social apps, or add messaging and social features to an existing app. \nThe fullstack MongooseIM platform offers various components, both for the backend (Erlang, Elixir) and the frontend (iOS, Android, Web) for you to pick up and assemble like pieces of a puzzle. \nToday, the MongooseIM platform delivers a new beta version of the messaging server, as well as new push notification server.My name is Michał Piotrowski, and I’m MongooseIM platform tech lead. \nWith this blog post I’d like to announce and describe our latest release. \nMongooseIM 2.1.0beta1 is one of the strongest releases I have ever worked on. \nIt comes with new features on the XMPP level and it also contains much more internal, technical changes.For this release we created a roadmap and gave the team the freedom to implement it.\nThe end result is not only implementation of most of the items from the roadmap but also many corresponding changes resulting in improved code quality or performance.Push NotificationsFor mobile devicesThese days most of instant messaging applications are mobile first or mobile only. \nTo deliver great product for mobile devices you have to be able to send push notifications to offline users in one way or another. \nThis was possible so far with the mod_http_notification module.\nThe problem with this approach is that you need to create your own HTTP service talking to APNS or FCM.In this version we added support for push notifications as described in XEP-0357: Push Notifications.\nWe also added a new service to our platform MongoosePush which can be used to communicate with both APNS and FCM. \nConfiguration of all the required components to enable push notifications is no laughing matter.\nThat’s why we create a detailed tutorial on this topic.Thanks to this functionality you can enable push notifications in your application based on a standard way. \nThere is no need to create ad-hoc, custom solutions.For other servicesIn many cases you may want to get some of the events from MongooseIM in your other services. \nFor example, to apply some business logic or implement a custom archive. \nAgain, this was possible with MongooseIM so far by aforementioned mod_http_notification with the same limitations as described above.MongooseIM 2.1.0beta1 comes with a new and more flexible way to integrate with other services in the whole infrastructure. \nThanks to mod_aws_sns you can configure MongooseIM to push certain events to your Amazon SNS queues.\nThe sky’s the limit in applying any business logic you may want on all the delivered events.Full text search for MAMMost modern instant messaging applications need full text search on the messages from archive. \nWhile not officially described in any XEP, it’s possible to add custom queries to MAM requests for instant full text search.\nThis is exactly what we did in MongooseIM 2.1.0beta1. \nWith this version you can use custom field full-text-search in your MAM query to get all messages matching provided pattern. \nComplete example can be found in the PR implementing this functionality.\nBe warned, this has its limitations:It works only with MySQL, PostgreSQL or Riak KV backends.MySQL and PostgreSQL implementation is not the most efficient as it’s based on SQL’s full text search.Please take a look at mod_mam documentation to see how to enable this feature.Continuous load testingIn developing the MongooseIM platform we are always focused on the quality of our product. \nThat’s why we integrated MongooseIM with services like travis-ci,\ncoveralls.io and gadget-ci a long time ago.\nThanks to these improvements, every single change is properly tested. \nCode quality and test coverage are also monitored to ensure we deliver the best possible quality.For the past few months we’ve been working on another service which helps us deliver better products.\nTide is our own service integrated with MongooseIM build pipeline. \nThanks to this s" <> ..., title: "MongooseIM 2.1.0beta1 what happens when you give your team freedom", url: "https://www.erlang-solutions.com/blog/mongooseim-2-1-0beta1-what-happens-when-you-give-your-team-freedom.html"}
%{author: "by Claudio Ortolina", text: "5 Elixir highlights from Erlang & Elixir Factory 20172017-04-25\n        by Claudio Ortolina\n      Want more from the world of functional programming? We’re at Code Mesh 2017 in November!Erlang & Elixir Factory highlightsThe latest Erlang & Elixir Factory San Francisco was definitely worth the trip: new faces, interesting ideas and a buzzing hallway track.As usual, plenty of top-notch technical talks, but personally I found that two important trends emerged: teaching and embedded devices.In that respect, here are some highlights:Sarah Allen - Language encodes WisdomIn the opening keynote, Sarah Allen delivered a very powerful idea: the way we encode ideas in a language (whether it’s programming or not, it doesn’t really matter) also defines how we think about the world.\nIt’s a solid linguistic perspective that can help us driving new adoption and community growth. Erlang and Elixir have a rich vocabulary that can help solving the big technological challenges of tomorrow, so we should work and capitalise on that.Michal Slaski - Erlang Performance LabMichal Slaski introduced Erlang Performance Lab (EPL), a tool capable of visualising the traffic between nodes and processes in a Erlang/Elixir system.While walking through its features and capabilities, Michal touched on one of the most difficult challenges we face when teaching Erlang/Elixir: “seeing” processes.\nEPL has an incredible potential as an educational tool that can help in exploring applications and grasping how a process-based system works, especially for people whose previous development experience doesn’t include anything similar.Best of all, this tool is open-source and open to contributions from all levels of experience.Embedded devices galoreThere were quite a few talks related to the embedded device development space.Carl Hewitt - Concurrency and Strong Types for IoTOn the theoretical front, Carl Hewitt dove into strong types and concurrency to outline a mental model for the development of IoT devices, touching various topics from security to computational models.\nJustin Schneck - Building Devices with Elixir/Erlang using NervesIn terms of tools, Justin Schneck’s talk Building Devices with Elixir/Erlang using Nerves showed that by using Nerves, you can quickly create robust devices from a wide selection of off the shelf hardware and accessories. \nPeer Stritzinger - Wireless Embedded Erlang Applications with Grisp Hardware Boards and ToolchainPeer Stritzinger also showed how it’s possible to dive into hardware-based development with minimal investment in his talk, Wireless Embedded Erlang Applications with Grisp Hardware Boards and Toolchain. Ever wanted to know how to quickly prototype Erlang Embedded Wireless Applications? Look no further. \nIn general, the IoT space seems to be fertile ground for Erlang/Elixir based technologies and these talks reflect the effort the community is putting into creating affordable tools that can help fostering innovation.The hallway trackChatting to different people revealed quite a broad range of projects and use cases, from startups to big companies (some of them new in the Elixir/Erlang space).There’s a shared consensus that these technologies are solid and worth investing into, so we can safely say we’re past the phase where people are wondering about the commercial suitability of Erlang/Elixir (particularly the latter).At the same time, there’s a clear need to bridge a knowledge gap between people with multi-year expertise on distributed computing and a significant number of people joining the development community.Conversely, BEAM for a wider audience means more exposure to topics like user-experience, user interfaces, fast prototyping and generally speaking more user-facing software.In short, lots of food for thought.Want more from the world of functional programming? We’re at Code Mesh 2017 in November!Catch up on the latest and greatest developments in Elixir at ElixirConf.EU, where Claudio will discuss availability >Go back to the blog\n\nTags:ElixirErlang & Elixir FactoryeventsShare  Facebook Twitter Linkedin E-mail", title: "5 Elixir highlights from Erlang & Elixir Factory 2017", url: "https://www.erlang-solutions.com/blog/5-elixir-highlights-from-erlang-elixir-factory-2017.html"}
%{author: "by Ju Liu", text: "Installing Elixir on a Raspberry pi the easy way2017-05-02\n        by Ju Liu\n      Learn more about how Erlang Solutions can support you with Elixir Development or sign up to our mailing list to be notified of our future blog posts.In this tutorial we will go through the easiest way of installing the latest and\ngreatest versions of Erlang and Elixir on your Raspberry Pi. Since the Raspberry\nis still a fairly low-powered device, we will use precompiled packages instead\nof compiling everything from source. This will also help us to keep our system\nupdated in the future.We assume that you are using the latest Raspbian OS, codenamed Jessie, but this\nguide should reasonably work for every future version of Raspbian as well.So first of all let’s add the Erlang Solutions repository:$ wget https://packages.erlang-solutions.com/erlang-solutions_1.0_all.deb &&\n  sudo dpkg -i erlang-solutions_1.0_all.deb &&\n  rm erlang-solutions_1.0_all.deb\nThen we can update our sources and install Erlang and Elixir (we will also\ninstall erlang-dev which includes development libraries useful for many Elixir\npackages):$ sudo apt-get update && sudo apt-get install erlang erlang-dev elixir\nTo check that the installation worked, type this in your console:$ iex\nand you should be greeted by the familiar Elixir shell:$ iex\nErlang/OTP 18 [erts-7.3] [source][smp:4:4] [async-threads:10] [kernel-poll:false]\n\nInteractive Elixir (1.4.0) - press Ctrl+C to exit(type h() ENTER for help)iex(1)> IO.puts \"Hello from Elixir!\"\nHello from Elixir!\n:ok\nHappy hacking!Learn more about how Erlang Solutions can support you with Elixir Development or sign up to our mailing list to be the first to know about our future blog posts.We thought you might also be interested inElixir language consultancyHow to avoid elixir messaging issuesHow to run elixir language apps on dockerGo back to the blog\n\nTags:ElixirRaspberry PitutorialShare  Facebook Twitter Linkedin E-mail", title: "Installing Elixir on a Raspberry pi the easy way", url: "https://www.erlang-solutions.com/blog/installing-elixir-on-a-raspberry-pi-the-easy-way.html"}
%{author: "by Ju Liu", text: "Rebuilding the Mission Impossible Security System in Elixir on Raspberrypi2017-05-02\n        by Ju Liu\n      Learn more about how Erlang Solutions can support you with Elixir Development or sign up to our mailing list to be the first to know about our future blog posts.Yes, you’ve read that right. In this tutorial we are going to rebuild the\namazing security system featured in the 1996 all time classic Mission\nImpossible. We will use a Raspberry Pi, lots of sensors and we’ll write the\ncode in Elixir.Just a quick refresher for those who haven’t seen the movie. Ethan Hunt is a super spy\ntrying to infiltrate the CIA headquarters in order to steal a valuable list of\ndouble-agents. Unfortunately, the list is safely stored in a highly secure\nbunker with the following security mechanisms:- Laser beams- Temperature sensors- Noise sensors- Ground vibration sensors\n\n\nPreparationBefore we start, let me give you the best advice I received when I started\ndeveloping on a Raspberry Pi: get yourself a USB to TTL serial cable! You\ncan find them on adafruit (link,\ntutorial)\nand these little devices will save you the trouble of having to connect an\nexternal monitor, a keyboard and a mouse in order to use your Raspberry. Just\nconnect the cable, fire up screen and boom you’re in.Now we need some sensors to build our security system, and I’ve found a set made\nby Sunfounder that has everything that we need and even more\n(link).\nI’m in no way affiliated with the company, but they posted all the C and Python\ncode to control them on\ngithub so I\nthink they’re pretty cool.The last thing we need is Elixir! We can install it on our Raspberry Pi\nfollowing this tutorial.Let’s get startedWe can now create the project using our beloved mix:$ mix new intrusion_countermeasures\nand add elixir_ale as a dependency in our mix.exs file:defmoduleIntrusionCountermeasures.MixfiledouseMix.Projectdefprojectdo[app::intrusion_countermeasures,version:\"0.1.0\",elixir:\"~> 1.4\",build_embedded:Mix.env==:prod,start_permanent:Mix.env==:prod,deps:deps()]enddefapplicationdo[extra_applications:[:logger],mod:{IntrusionCountermeasures,[]}]enddefpdepsdo[{:elixir_ale,\"~> 0.5.6\"}]endendThis library will provide us the abstractions for controlling the Raspberry\nGPIO pins and I2C bus. You can find out more about the library\nhere. So let’s install and compile:$ mix deps.get && mix compile\nFirst things first: a laser!Grab your laser emitter module and connect it to the breadboard in this way:Now we can start writing the code for our security system:defmoduleIntrusionCountermeasuresdouseApplicationdefstart(_,_)do{:ok,laser}=Gpio.start_link(17,:output)pid=spawn(fn->loop(laser)end){:ok,pid}enddefloop(laser)do:timer.sleep(200)turn_on(laser):timer.sleep(200)turn_off(laser)loop(laser)enddefpturn_on(pid)doGpio.write(pid,0)enddefpturn_off(pid)doGpio.write(pid,1)endendWe connect the GPIO pin 17 using Gpio.start_link, specifying we’re using it as\nan output. Then we spawn a recursive loop function which repeatedly turns the\nlaser on and off. We can run our app with iex -S mix and the laser will start\nblinking. How cool is that?Also note that the default behaviour is to write 0 for turning something on\nand 1 for turning it off. To make the code easier to understand I just added\nthe turn_on and turn_off helpers.Here’s a picture of the setup on my desk:Back to analogNow that we have the laser blinking, we can add a sensor which measures how much\nlight shines through it, also known as a photoresistor. The gotcha is that\nthis is an analog sensor, so we need an analog-to-digital converter to be able\nto read off the digital value in our program. Here’s the diagram:In order to connect to the AD converter in our program, we have to use the I2C\nbus. Unfortunately the I2C bus isn’t enabled by default, so we’ll have to do it\nourselves:$ sudo raspi-config\n# Choose Interfacing Options# Choose I2C# Choose Enable$ sudo reboot\nAs soon as the Raspberry reboots, you can connect the circuitry and check that\nthe bus is visible:$ ls /dev/i2c*\n/dev/i2c-1\n$ sudo i2cdetect -y 1\n     0  1  2  3  4  5  6  7  8  9  a  b  c  d" <> ..., title: "Rebuilding the Mission Impossible Security System in Elixir on Raspberrypi", url: "https://www.erlang-solutions.com/blog/rebuilding-the-mission-impossible-security-system-in-elixir-on-raspberrypi.html"}
%{author: "by Radek Szymczyszyn", text: "Docs in the shell 2: Man-Erlang interface2017-05-23\n        by Radek Szymczyszyn\n      Learn more about how Erlang Solutions’ Erlang and Elixir Solutions or sign up to our mailing list to be the first to know about our future blog posts.Docsh updateIt’s been a while since the last update on docsh and over a year since the\nidea of shell access to Erlang docs originally emerged in my mind.\nBelieve it or not, the project has seen a huge progress,\nthough one might argue that at a pace a tad slower than the speed of light.\nBy the way, if you ask me, it’s “doc-es-age”, not “doc-shhh”.Let’s recap what the original goals were, whether they’ve shifted,\nand how we fared realising them.Require as little fuss as possible to useIf you’re just beginning your Erlang journey, there’s an install script available,\nwhich will take care of the default setup in a few seconds.\nInstall Erlang, clone docsh, run install.sh and there you are!For the veterans: the install script won’t mess up your precious Erlang\ndevelopment environment settings, it’s going to balk at touching your config files,\nbut will provide hints on how you can enable doc access manually.Provide value to the developer no matter whether they use community or OTP librariesOnce docsh is installed, when you run erl it will greet you with a\nreminder that docsh is enabled.\nFrom this point, the shell is equipped with a new set of helper functions\nfor accessing the documentation of modules and functions, function specs,\nand type definitions.\nThese helpers will look familiar to those who had a sip of Elixir,\nbut have been adapted to Erlang’s syntax.\nIf in doubt, refer to h(docsh). in the Erlang shell - that is, use docsh\nto view its own documentation.\nThe README and some examples\nmight also whet your appetite some more if you’re not yet convinced enough to install the tool.There’s one caveat at the moment, though.\nThe so called Erlang/OTP source bundles (i.e. the .tar.gz archives you can get from erlang.org),\nyou use to install from source, aren’t really exactly the thing they’re supposed to be.\nThe C source code included within is compiled on your machine during installation,\nbut the standard Erlang modules come precompiled on the tarball packager’s machine.When docsh inspects a module, in some cases it tries to find its source code.\nGiven the source file path is not valid on your machine,\ndocumentation extraction will fail.\nAll in all, unless you take extra steps when installing Erlang,\ncurrently for the standard OTP modules docsh can only provide function specs,\nnot the inline EDoc documentation one might expect.\nDespite that, the specs can be more than enough to tell what a function does,\nand are an invaluable help when determining its parameters’ meaning and order.\nThis EDoc extraction from OTP modules thing is a known issue\nand will be fixed in the future.Make docsh documentation compatible with Elixir’s format for IEx to useThis goal was twofold: to make the internal format compatible with Elixir\nand to enable IEx (Elixir shell) to access Erlang documentation.\nWhile the internal format compatibility is shelved for now,\nthe access from the Elixir aspect has progressed somewhat.However, there are more languages on the BEAM (the Erlang VM) than just Elixir and Erlang.\nFor instance LFE, Efene and Alpaca come to mind.\nWith Alpaca having an open issue on the doc string system\nthey’re designing, there’s some space for research and maybe even for future collaboration.Back to Elixir, though - there’s a project called\nEhelper,\nwhose goals overlap a bit with those of docsh.\nEhelper aims to extend the Elixir shell with programmable plugins.\nThanks to this architecture, docsh could be an Erlang documentation provider for Ehelper.\nIt might be the way to go, but tinkering directly with Elixir’s .iex.exs\nmight be more straightforward.\nI have to spend more time on finding the most convenient approach for everyday use.\nLet’s see how it unfolds.In the original blog post, I also highlighted some issues which were yet\nto be solved back then.\nThe first one was documentation format diversity:\nat leas" <> ..., title: "Docs in the shell 2: Man-Erlang interface", url: "https://www.erlang-solutions.com/blog/docs-in-the-shell-2-man-erlang-interface.html"}
%{author: "by Ayanda Dube", text: "Advanced RabbitMQ Support Part 1: Leveraging WombatOAM Alarms2017-05-31\n        by Ayanda Dube\n      Erlang Solutions offers world-leading RabbitMQ consultancy, support & tuning solutions. Learn more >IntroductionFrom simple single node deployments to complex and mission critical clustered/federated node architectures, RabbitMQ often finds itself put to use in various MOM (Message-Oriented Middleware) solutions. This is mainly due to its seamless ease of use and adaptability to different use cases, each with distinct requirements on aspects such as high availability, latency stringencies, just to name a few. User testimonials for RabbitMQ back this up; across all its spheres of use, teams have found it to be very impressive. For such a highly esteemed system, playing such an crucial role in the most mission critical solutions in the industry, you’d assume that it is fully equipped with in-built, top-of-the-range operations and maintenance sub-components, utilities, and functions, which enable the most effective and efficient support possible. Unfortunately, that’s often not the case, in particular when we put focus on the all-important aspect of alarming.What RabbitMQ considers as alarms are notifications and error messages which it writes to its logs, coupled with some internal defence mechanisms or recovery strategies, which are put into effect when a subset of some of its common operational problems are encountered. An alarm, in its true OAM sense, can be defined as;a system generated indicator to an external entity, consisting of as much useful information as possible, in order to trigger an aiding action to prevent, resolve and/or alleviate the reported problem’s root cause.With this definition in mind, we come to realise that RabbitMQ has in fact (at the time of publishing this discussion), a limitation in notifying and triggering external entities for carrying out any corrective, or, pre-emptive action(s) for resolving the problem cause. When an alarm is raised within RabbitMQ, an action plan is decided upon, and automatic resolution or recovery attempts are internally executed by the system. See Fig 1 below (NOTE: This is for illustration purposes as the ACTION PLAN step is carried out within RabbitMQ).Fig 1: RabbitMQ Alarming routine illustrationSome of RabbitMQ’s native alarms provide accompanying graphical illustrations on the native Management UI, for example, VM High Memory Watermark alarms will graphically indicate that a node’s permissible memory usage has been exceeded. However, the user is not necessarily notified (unless continually monitoring from the UI) beforehand.An ideal alarming scenario and resolution plan would not only decide on a particular action plan (internally), but go further to warn and/or notify its user(s) of the reported problem, similar to the illustration in Fig 2. This would imply that for any (and many) reported warnings and problems notified to the user, the time taken for recovery would be much much faster, depending on how quickly (and skilled) the user who participates in the recovery procedure is.Fig 2: Expected RabbitMQ Alarming routine illustrationTo handle and cater for common or rare internal RabbitMQ system alarms in a near ideal manner, custom RabbitMQ plugins or external tools which help meet and fulfill these alarming requirements need to be developed, or made use of if already in existence. This is where WombatOAM comes into play, showcasing its significant importance and need for use in operations and maintenance functions of all RabbitMQ installations.i. Metric based alarmsWombatOAM provides RabbitMQ users with a rich set of native and AMQP related metrics to monitor. Coupled with its alarming infrastructure, specific alarms may be defined for each supported RabbitMQ metric provided by WombatOAM. Currently, approximately 50 RabbitMQ-specific metrics are provided by WombatOAM, which equates to a staggering same number of possible distinct alarming scenarios which may be configured and used by support engineers to assist in ensuring optimum end-to-end service provisi" <> ..., title: "Advanced RabbitMQ Support Part 1: Leveraging WombatOAM Alarms", url: "https://www.erlang-solutions.com/blog/advanced-rabbitmq-support-part-1-leveraging-wombatoam-alarms.html"}
%{author: "by Stuart Whitfield", text: "Three reasons to review your online betting tech stack2017-06-06\n        by Stuart Whitfield\n      \nAs CEO at Erlang Solutions, I’ve worked closely with online bookmakers for almost a decade, and have seen the digital marketplace go from SMS bets and WAP sites - remember them! - to sophisticated in-play systems and VR games. We’ve come a long way, but there is still reason to review your online gambling & betting tech stack. First, punters expect perfection of their digital experiences. Second, strong industry competition gives your dissatisfied customers other options. Last, legacy systems can hamper your innovation and competitiveness in the marketplace. 1. Customers expect moreToday’s players increasingly consume games across multiple channels and devices, day or night. They demand ease-of-use and seamless gameplay. Add to this the fact that they expect personalisation, recommendations, and instant access to their favourite products and games, it’s clear that omnichannel, always-on service delivery will only become more prevalent in future. This huge leap in sophistication and digital engagement sees today’s bookmakers working to grow their revenues, whilst maintaining the high standards their customers expect in terms of product quality and service availability. 2. High competitionAll of this needs to happen whilst navigating the perils of what is essentially still a maturing marketing. Just look at the high barriers to entry, and the current environment of M&As which is seeing competition consolidated in online gambling and betting. To stay on top, bookmakers are innovating fast to win the precious few pockets of growth in the sector and it’s hardly a surprise that operators have developed an unblinking, shark-like focus on the end user. Every step of the way, user experience comes first. There is a relentless demand for it to be easier and smoother, regardless of backend challenges. This has left the industry in search of the most efficient and effective ways of directing users to their objective, whether it’s registering, playing a game, placing a bet, cashing out that bet or making a deposit. Systems must be ultra-responsive and able to engage with customers when, where, and how they want. Those who get this ‘right’ in comparison to their competitors enjoy higher customer engagement and retention, and hence profits. And for each operator, this journey to support customer-centricity through the tech stack is slightly different. 3. Legacy systemsMany established operators have legacy systems that are hard to scale or modernise whilst maintaining uptime and quality of customer experience. In our experience, those operators ought to take a step back, review their technology choices and evaluate which of the bewildering range of tech, old and new, can best be deployed in helping them achieve these customer-centric goals. Using the right tools for the job, regardless of legacy systems, has never been more critical for the sector. We work with some of the major players in online betting, helping them create and deploy next generation systems in Erlang, Elixir, and beyond.Interested in finding the right tool for your job? (You should be). Learn how to successfully deploy new technology for the long term from Francesco Cesarini and Mike Williams, two Erlang veterans who have introduced to language into numerous industries, including online gambling and betting.Subscribe to our newsletter for the latest Erlang and Elixir news, or contact us directly for more on how to introduce a new technology to your stack.Go back to the blog\n\nTags:Online Gambling & BettingErlangElixirTech StackShare  Facebook Twitter Linkedin E-mail", title: "Three reasons to review your online betting tech stack", url: "https://www.erlang-solutions.com/blog/three-reasons-to-review-your-online-betting-tech-stack.html"}
%{author: "by Francesco Cesarini", text: "How to build a self-sustaining development team2017-06-20\n        by Francesco Cesarini\n      \nThis is an excerpt from The route to the successful adoption of non-mainstream programming languages by Francesco Cesarini and Mike Williams.So you’ve already built the prototype, failed forwards, and secured approval to move on with engineering the final product. It’s vital that you keep the team that built the prototype and use them to mentor the new recruits. In doing so, you need to make sure your team becomes self-sustainable. It is best if the mentor can sit next to the new recruits, communication needs to be quick and efficient from both sides. As members move to new positions or get assigned new POCs, you need to be able to replace them, be capable of mentoring the new joiners, bringing them up to speed. Our philosophy is to work with internal teams to grow the team’s skills, knowledge and capabilities. Create an environment to grow and foster the mindset for success. If you are a small company, a minimal team should consist of 4-5 people. If you are a large company, 10-12 developers and up. Not everyone needs to be using or developing in Erlang, but they should be passionate about it, be able to jump in and be productive at short notice, and be capable of rotating other team members out.Transferable skillsIt is always a mistake to advertise for programmers with experience in the language you are adopting; you want good and experienced open-minded software developers who understand different programming paradigms and approaches. They do not need to know the programming language, but they should be capable of understanding what is meant by using the right tool for the job. Erlang, you can learn easily. Good software practices, less so.If you acquire a company, you will get a pool of great developers who already have the domain knowledge. Back in 2004, a company in Silicon Valley was advertising for Erlang developers with at least a decade of Erlang experience. They had adopted Erlang as a result of an acquisition at a time when there were maybe 20 developers in the world  who qualified (including the authors of this blog). Ironically, that company used to employ another ten, but had just shut down their Swedish operations, making them redundant. Don’t get too hung up on location. Focus on talent and productivity.   A team that grows with youAs your software project progresses, the focus of your work will change, at the start your focus will be on developers with good architectural and programming skills; later on configuration management, verification and testing; then deployment, operations, maintenance, and documentation. Build a team of developers who can embrace the skills needed across the whole of the development life cycle.You should avoid different people for each category, rather you should have people who themselves can embrace the skills needed for the whole of the development life cycle. Handing over knowledge from person to person is error prone and costly, when a person works across several areas this can be avoided.Cut out the bad habitsLearning Erlang/OTP is easy, as it is a very compact language and framework. The difficult part is unlearning other programming language models and getting rid of the bad habits they bring with them. This is where mentorship and code reviews become an essential part of the process. Review all code, not only code in the application itself but test cases, simulators and tools. Code reviews should be led by experienced developers focusing not only on quality, style, and documentation, but also on educating developers on the system as a whole.New recruits often get up to speed fastest when making changes to existing code. Be cautious and review new code written by new recruits carefully.Ericsson did a study in the late 90s looking at the productivity of graduates and experienced developers in large projects after they had attended Erlang and OTP training. They concluded that a graduate straight out of university became productive after about a month, as they could easily pick u" <> ..., title: "How to build a self-sustaining development team", url: "https://www.erlang-solutions.com/blog/how-to-build-a-self-sustaining-development-team.html"}
%{author: "by Francesco Cesarini", text: "Getting started: Building the core dev team2017-07-05\n        by Francesco Cesarini\n      \nThis is an excerpt from The route to the successful adoption of non-mainstream programming languages by Francesco Cesarini and Mike Williams.On one end of the scale, we often hear complaints about how hard it is to find Erlang developers. Java, C++ and Web developers are everywhere. They are easy to recruit. Not all might be top notch, but at least we can recruit them. Despite that, look at Ericsson who use Erlang in projects with over a hundred developers in each. Members join and leave the team, move to other Erlang or non-Erlang projects and can easily be swapped around. Ericsson had to start somewhere; in the early days, everyone on the internal Erlang mailing list knew each other personally. Today, their Erlang programmer count is in the thousands and those using it daily are in the hundreds. But they are not alone. The reason you might not hear from companies such as Klarna, OpenX, AlertLogic, WhatsApp, Cisco and bet365 (to mention but a few) is that they just get on with it. They are too busy building teams to complain how hard it is to find Erlang developers. We have seen Erlang used by teams of a hundred developers who produced successful products, we have also seen teams of two or three developing, deploying and maintaining a huge code base. Not to mention companies who adopt non mainstream languages through acquisitions, successfully introducing the technology in the wider organisation instead of making the crazy decision to rewrite the product or service in Java. But before you start thinking of hundreds, start small.Start with a few experienced leadersLike all programming technologies, you must have one or two experienced, good software developers who can lead the way. Like everything in life, even a programming language can be used and abused. You need people who will stop you from making the wrong decision and avoid mistakes others have done. Create a small team for the project initiation. Fill it with a few highly experienced experts who will work to shape a plan and get the change sponsors to a common level of understanding.They have to be enthusiastic, but also make sure they understand and embrace the programming model. Those who were around in the very early days at the time when C++ and OO was all the hype might remember that we spent a lot of our time convincing people that doing OO programming with Erlang was not a good idea, and that, if unwilling to make the move to functional and concurrency oriented programming, they were better off sticking to C++ or Java. No technology (or varying levels of enthusiasm) can replace experienced software developers who know what they are doing. While you’re cherry-picking these leaders among men, see if you can seed one of them as a representative on the steering board. Their experience and enthusiasm will be an asset when it comes to changing hearts and minds across the organisation. Developer vs programmerWe use the term “software developer” rather than “programmer”, because software development entails much more than programming. When building your team, you need people who understand and can support the product life cycle, combined with subject matter experts who understand the industry vertical you are active in. In small teams these may well be the same people. Software development entails much more than programming.You need to ensure you have developers who can define, program, build, test, deploy, document, package, write user manuals, and maintain your system.DelegationYou do not want to rely on a lonely hero programmer who does not understand the value of delegation and knowledge sharing, believing that DevOps means being woken up in the middle of the night to address customer complaints about the system not working (and then receiving the employee of the month award for cleaning up the mess they created themselves). Your operations team should be the ones noticing there is a problem through automated alerts, not your customers!While you might need at least one h" <> ..., title: "Getting started: Building the core dev team", url: "https://www.erlang-solutions.com/blog/getting-started-building-the-core-dev-team.html"}
%{author: "by Stuart Whitfield", text: "Riak commercial support now available post Basho2017-08-10\n        by Stuart Whitfield\n      LONDON, 10 August 2017 – Erlang Solutions and TI Tokyo are pleased to announce their partnership to provide enterprise grade support to users of the Riak suite of products; Riak KV, Riak S2 (formerly Riak CS) and Riak TS.Since the much-publicised difficulties encountered by Basho, which culminated in it appointing a receiver in July 2017, Riak users have expressed concern about the uncertainty surrounding the support available for Riak and the future of the product itself.The Erlang Solutions/TI Tokyo partnership means that Riak users now have a range of subscription support options available (including 24/7 enterprise-grade) together with expert Riak and Erlang consulting services.Support services are now live and Erlang Solutions and TI Tokyo will be happy to discuss individual customers’ needs.In the medium term, once the current uncertainty around the ownership of the Riak IPR is resolved (Basho’s receivers are in the process of trying to dispose of its business and assets), Erlang Solutions and TI Tokyo intend to work with the Riak user community to ensure the Riak product set evolves and flourishes and we welcome contact from all those who wish to become active contributors to the ongoing Riak project.Contacts us at general@erlang-solutions.com or download our brochure to learn more about our Riak Support.The key playersTI Tokyo is a privately held Japanese company that has been supplying Basho with support services for APAC (Asia Pacific). TI Tokyo has recently hired additional Basho-trained engineers around the world in order to continue providing 24/7 worldwide support for all Riak products.Erlang Solutions is a member of the Trifork GmbH group of companies. Erlang Solutions has been a Riak reseller since 2012 and has provided Riak support, optimisations and bespoke development work to Basho and its customers since then.Riak KV is a highly performant, distributed key value store. It is in use globally across a range of industry verticals in both open source and enterprise versions.\nNotable users include the NHS, AT&T, The Weather Channel, Best Buy, bet365, IBM, William Hill, Yahoo Japan.Riak S2 (formerly Riak CS) is an open source, large object storage database built on top of Riak KV. It can be used to build public or private clouds or as reliable storage to power applications and services.Riak TS is an open source distributed database built on top of Riak KV optimised for time series data.We thought you might also be interested in:Riak NoSQL Database supportBrief history of RiakOur tailored tech support plansGo back to the blog\n\nTags:riakRiak SupportBashoTi Tokyoriak kvRiak S2Riak CSRiak TSEnterpriseopen sourceShare  Facebook Twitter Linkedin E-mail", title: "Riak commercial support now available post Basho", url: "https://www.erlang-solutions.com/blog/riak-commercial-support-now-available-post-basho.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 2.1.0beta2 - Expanded Platform, first class quality2017-07-06\n        by Piotr Nosek\n      MongooseIM is a platform for businesses to build messaging and social apps, or add messaging and social features to existing apps.\nWhen you need to adapt to growing user demand, we’re here to guarantee that your service scales, grows with new functionalities and remains reliable for all.The fullstack MongooseIM platform offers various components, both for the backend (Erlang, Elixir) and the frontend (iOS, Android, Web) for you to pick up and assemble like pieces of a puzzle.Latest beta release of MongooseIM 2.1.0 is here!This time, we focused on improving the source code and documentation quality.\nEverything to make your MongooseIM deployment easier to maintain and more stable.Our team wants to ensure that the next version will be as mature as possible, with accurate and easy-to-read documentation, and friendly source code for developers; free of known bugs and issues. Beta2 is also time to welcome our new ICE/STUN/TURN component, which has almost reached its stable version by now.And by the way… Hi! I’m Piotr and I’m going to be your guide in the tour of beta2!Read The Fine ManualIt’s easy to forget about documentation when you’re chasing after new features, improvements and world-changing pull requests.\nWhen that does happen, you run the risk of users not appreciating the new shiny module you prepared for them - mainly because they do not know what it is or how to configure it.We understand it is a challenge to maintain up-to-date, high quality documentation of a project of MongooseIM’s size.\nIt is one of our primary tasks for 2.1.0 release to pay off this debt and ensure that no important information piece is missing.\nIt involves revising docs about every module and configuration description correctness.\nWe are verifying the validity of high level concepts and guides.Every GitHub issue, that narrows down to a configuration problem, is a clear indication what we should improve.\nIt’s an ultimate goal to ensure that every MongooseIM user will be able to configure the server without any doubts on which option to use and how!\nIt is our priority to ensure that our users always find the information they seek, no matter if these are abstract concepts, design decisions and development guidelines.In beta2 we continue to work towards a high quality documentation with 50% of docs being reviewed and already improved.\nWe aim at 100% by the 2.1.0 release freeze!MongooseICENowadays it’s not so easy to have each user occupy public IP addresses.\nIn most cases both users are behind NATs, which effectively prevents them from establishing a peer-to-peer connection.\nIt means no file transfers (except for e.g. inefficient In-Band Bytestreams), no video or voice calls.\nWhat can an application provider (or just two users connecting to public XMPP clusters) do under these conditions?\nICE/STUN/TURN enables two clients to establish a peer-to-peer connection and exchange data, in a manner that is cheap and efficient.You can find more information about our new backend service in the MongooseIM family esl/fennec.\nYes, the link is correct.\nFennec is simply the codename until its first stable release.Bloated-stanza-proofBeta2 features an important security update, which moves the stanza size check from Erlang code to the XML parser.\n It means it’s no longer possible to fill the server’s memory with an enormous stanza.\n Before this update, an oversized XML was discarded of course, but only after parsing, so the memory was already allocated and the damage was already done.Because of this vulnerability, a malicious user could trigger out of memory exception and crash the server.\n Beta2 prevents it.Goodbye, deprecation!Erlang/OTP evolves over time, so does its API.\nSome functions become deprecated for good reasons.\nIn beta2 we’ve got rid of erlang:now/0 and crypto:rand_bytes/1 calls.The highlights of this change are:Better performance (less Erlang VM locks)More secure tokens and authentication saltsOK, now it gets technical. :)The former function has be" <> ..., title: "MongooseIM 2.1.0beta2 - Expanded Platform, first class quality", url: "https://www.erlang-solutions.com/blog/mongooseim-2-1-0beta2-expanded-platform-first-class-quality.html"}
%{author: "by Claudio Ortolina", text: "The top 10 Elixir talks of 2017 so far2017-08-16\n        by Claudio Ortolina\n      Want more from the world of functional programming? We’re at Code Mesh 2017 in November!2017 has been a great year for Elixir! It turned 5 years old this January, and the language has just gone from strength to strength. It’s also been a fantastic year for sharing of knowledge within the community. Here’s our pick of the most popular Elixir talks of 2017 so far.GenStage and flow - José ValimEvent: Lambda Days 2017Speaker: José Valim, Elixir CreatorLevel: Intermediate \nJosé explores the rationale and design decisions behind GenStage and Flow, two abstractions that have been researched and now implemented in the Elixir programming with a focus on back-pressure, concurrency and data processing.Lambda days 2018 tickets are now available.Transforming programming - Dave ThomasEvent: Erlang and Elixir Factory San Francisco 2017Speaker: Dave Thomas, Programmer turned publisher (but mostly programmer)Level: Beginner, Intermediate\nWhen it comes to BEAM, the last thing the community wants to do is break something good. At the same time, it’s also a bad idea to stagnate. It is on this basis that Dave Thomas explores what happens if he takes BEAM and starts using it in different ways. In this talk, Dave shares his great thought-provoking way of understanding and teaching programming as a state transition as he experiments with programming by transformation. Does Dave succeed in freeing himself, and the community, from the “tyranny of the program counter”? You’ll have to watch to find out!Leveling up your Phoenix Projects with OTP - Nico MihalichEvent: Lonestar ElixirConf 2017Speaker: Nico Mihalich, DockYardLevel: Beginner, Intermediate \nWant to build a fully functional Elixir project, integrated into a Phoenix application? This talk is for you!With Elixir and Phoenix, the toolkit for building web applications has expanded dramatically. Beyond Phoenix’s routers and controllers is a whole new world of features and ways to build reliable systems. With this talk, Nico demonstrates how. Over the course of the talk Nico takes a practical approach to building a small application in Elixir, walking through all the steps and describing what language features he takes advantage of and why. Along the way he explores GenServer, OTP, backpressure management, synchronous vs asynchronous calls, a testing strategy, and integration into a Phoenix application. Taking Elixir to the Metal with Rust - Sonny ScrogginEvent: NDC London 2017Speaker: Sonny Scroggin, Phoenix Core Team memberLevel: Beginner, Intermediate \nElixir is great, we all love Elixir. However, in this talk Sonny is very upfront about Elixir’s speed; it turns out Elixir isn’t the fastest kid on the block. And while raw CPU speed matters little for most applications, there does exist a couple reasons you might want want to reach for tools that give you access to native power.In this talk Sonny discusses Native Implemented Functions (NIFs) - Erlang’s Foreign Function Interface (FFI).NIFs are normally implemented in C and are considered dangerous. But Sonny explores writing safer NIFs in Rust - a new systems programming language developed by Mozilla, that focuses on memory safety. He also touches on the pitfalls with writing NIFs and how Rust can make this process easier and safer.ElixirConf EU 2017 Keynote - José ValimEvent: ElixirConf EU 2017Speaker: José Valim, creator of ElixirLevel: Beginner, Intermediate, Advanced \nJosé Valim is the creator of the Elixir programming language and the Director of R&D at Plataformatec, a consultancy firm based in Brazil. He is author of Adopting Elixir and Programming Phoenix as well as an active member of the Open Source community.In this talk, Jose talks us through his journey with Elixir so far, and shares his plans for the language in the coming year. Elixir and Money - Tomasz KowalEvent: ElixirConf EU 2017Speaker: Tomasz Kowal, ClubcollectLevel: Beginner, Intermediate\nDealing with money should be easy, because crunching numbers is the most basic thing that every comput" <> ..., title: "The top 10 Elixir talks of 2017 so far", url: "https://www.erlang-solutions.com/blog/the-top-10-elixir-talks-of-2017-so-far.html"}
%{author: "by Areege Al Zubaidi", text: "A brief history of Riak2017-09-05\n        by Areege Al Zubaidi\n      \nIt has been an eventful year for the Riak community so far. For those struggling to keep up with the developments, we’ve put a quick timeline of events together, highlighting the everything any self-respecting member of the community needs to know. Learn more about our Riak Support offering, covering Riak KV, TS, and S2/CS deployments 24/7.\nLearn more about our Riak Support offering, covering Riak KV, TS, and S2/CS deployments 24/7.\nWe thought you might also be interested in:Riak support post Basho announcementOur Riak NoSQL Database supportErlang & Elixir consultancyGo back to the blog\n\nTags:riakRiak SupportBashoShare  Facebook Twitter Linkedin E-mail", title: "A brief history of Riak", url: "https://www.erlang-solutions.com/blog/a-brief-history-of-riak.html"}
%{author: "by Nicolas Vérité", text: "Master your pirate metrics, AARRR2017-10-05\n        by Nicolas Vérité\n      This is an excerpt from Boost your engine of growth with chat and social value by Nicolas Vérité. Instant messaging or chat is a constantly self-reinventing universe. In this article we focus on businesses who are building chat apps and apps with chat. From early stage startups to big corporates, it is always good to remind and always be conscious of some the basics of business, and how the interlinking and mechanics of social and messaging allows you to accelerate growth and consolidate your sustainability.Master your pirate metrics, AARRRPirate metrics are business KPIs for product or service marketing, sales and more generally product management. It is a big funnel of quantitative data telling the story of your customers’ journey. This data describes different stages of your relationship with the client: Acquisition, Activation, Retention, Revenue, Referral. Together these pirate metrics add up to a famous pirate battle cry - “AARRR”.What are the metrics behind AARRR?Acquisition: people who come to your product or serviceActivation: people who actually do something with your product or serviceRetention: people who continue to use your product or service regularlyRevenue: people who payReferral: people who talk (positively, hopefully) about your product or service!More precisely, it is a set of critical engine parts of your growth machine. Each single value of these five metrics is important for your measure, so that you better understand your customer journey, and can optimise it. The ratio of conversions for each step is also very important. But don’t lose sight of the bigger picture; it helps you identify what you are good at, and where to improve.Going deeper, next we will focus on the organic aspects of Instant Messaging: Acquisition, Retention, Referral. We will not cover Activation, because it mostly belongs to your onboarding, neither will we cover Revenue because it mostly belongs to your business model. However, it is clear that Activation and Revenue are not fully disconnected from Acquisition, Retention, and Referral.Here is how to boost the triplet “Acquisition, Retention, Referral”.Features for Acquisition and tractionThere are a number of generic chat features available that appeal to your potential users and thus contribute to Acquisition. One-to-one chat or interpersonal messaging obviously comes to mind first. Then group chat is definitely contributing a lot to your traction, as it is more fun and collaboration for users, the generation Slack/HipChat and their dozens of followers showed that massive enthusiasm and need. And finally, social networking is taking all of that to the super next level.Then you can consider secondary features, such as presence, status, availability, profiles, avatars, and contact management, including blocking. There are even more features, such as typing notifications, last message correction, sent/received/read receipts, pictures/sounds/video/location messaging, archiving, mentions, stickers/emojis, integrations, chatbots, full-text search, the stories craze, and of course end-to-end encryption.Let’s not look too deep into all the features on offer for now, you should focus on creating your own subset, based on your customer demand, and the problems you are trying to solve. Your unique custom features will be your differentiators.Warning: carefully craft and tailor key distinctive features for your audience. Do not use ALL the commodity features. The goal is to avoid feature factories, making your app look like blinking Christmas decorations. “It seems that perfection is attained not when there is nothing more to add, but when there is nothing more to remove.” (Terre des hommes, Antoine de Saint-Exupéry, 1939)Activities for Retention and engagementHere you will use mechanics that will not add friction, nor will you focus on the features that “just add value” for individuals. You will focus on conversation (re)activators, such as chatbots, integrations, group chat and social chat (natural user featu" <> ..., title: "Master your pirate metrics, AARRR", url: "https://www.erlang-solutions.com/blog/master-your-pirate-metrics-aarrr.html"}
%{author: "by Stuart Whitfield", text: "Programming languages for online betting: an investigation of Go, Erlang, and Elixir2017-10-10\n        by Stuart Whitfield\n      “The right tool for the job” is a popular adage in the online betting industry. In my time at Erlang Solutions, I’ve learned that there are three key reasons why Erlang and Elixir are often the right tool for the job in online gambling and betting: superior concurrency, scalability, and reliability.Online betting is a booming industry, both in terms of technology and revenue. Case in point; bet365, the world’s leading bookmaker has more than 22m customers, takes up to three-quarters of its £1.5bn revenues come from international markets. Extreme scalability, concurrency, and reliability is a must to keep bet365’s engines turning. bet365 lives by the mantra the right tool for the job, and runs a mix of Erlang, Elixir, and Go in production. So when and where should you choose Erlang, Elixir or Go in your betting stack?ConcurrencyAt any one time bet365’s systems are serving many 100,000s of users live odds and results, while managing multiple backend data streams. In peak times, like the Super Bowl or the Grand National, the number of users swells by an order of magnitude. This is an awesome feat of concurrent engineering. When it comes to concurrency, Erlang and Elixir, both built on the BEAM virtual machine, excel. They are both concurrency oriented functional languages, built to handle vast numbers of users at the same time. Users of Erlang across verticals as diverse as telecoms, adtech; financial payments; massive multiplayer online role playing gaming; and social media have all exploited its ability to provide impressive concurrency.Go also offers good support for concurrency, especially when comparing it to Ruby, Python, or C++. However, is not an alternative to Erlang or Elixir for backends where availability and low latency for high numbers of concurrent requests is required, as in online betting.ScalabilityModern betting infrastructures demand massive scalability, speed, and fault tolerance to run smoothly. Without built-in scalability, operators can be left to rely on additional hardware to scale vertically, which is not a sustainable nor a cost effective approach. Erlang and Elixir’s concurrency go hand-in-hand with their massive scalability. If Erlang isn’t the best tool for every job your system has, a distributed architecture that can plug into Erlang-based products can make your betting system quick to deploy and scale elastically. Tools built in Erlang, such as Riak KV, scale out, up and down predictably. Say goodbye to the headache of emergency hardware and unpredictable system performance at peak load.When you pit Go’s requests per seconds against the likes of Ruby on Rails or Django, Go returns some impressive benchmarks performing 3x better. Go can scale to hundreds of thousands with relative ease, in much the same way that Erlang and Elixir scale to millions. ReliabilityLike the stock market, downtime for an online betting operator has immediate financial and reputational consequences. For online sports betting the provision of a ultra-reliable, real-time service is now a priority for bookmakers and punters alike. Just look at the booming inplay market for sports events. In this world, pauses of any kind, for system failure, garbage collection, or queuing backlogs, are not acceptable. Online betting stacks must handle their constant torrents of data without impacting the system’s processes, or end users. Erlang and Elixir’s no-shared memory approach allows processes to terminate without corrupting the state of other requests being executed in parallel. This allows a ‘fail and recover’ architecture where failure is isolated and does not affect the system. As a result, Erlang and Elixir achieve “five nines” availability at a fraction of the effort of other programming languages. This makes Erlang and Elixir ideal to build critical gambling and betting systems on.Go is tooled very well, but some of its automated triggers can cause errors, jeopardising server code that is suppose" <> ..., title: "Programming languages for online betting: an investigation of Go, Erlang, and Elixir", url: "https://www.erlang-solutions.com/blog/programming-languages-for-online-betting-an-investigation-of-go-erlang-and-elixir.html"}
%{author: "by Nicolas Vérité", text: "Messaging feature sets and their benefits2017-10-12\n        by Nicolas Vérité\n      This is an excerpt from Boost your engine of growth with chat and social value by Nicolas Vérité. Messaging feature sets and their benefitsA lot of features have come and gone over the few generations of messaging. Some of them stick around much longer than others.Interpersonal assistant chatbots, for a warm welcomeA welcome bot will allow you - among other things - to handhold users through first uses, conducting them through a critical part of the customer journey, avoiding early churn. Also, it will fix a common situation with new apps: the emptiness and solitude. When you install a fresh app it should definitely show anything but the void and blank spaces.A machinegun, marketing-driven push notifications could fit the companionship gap as well, but these are annoying and intrusive, and sometimes they come with disrupting the experience with the app. This may void user value, consequently, synthetically increasing your vanity metrics for an immediate fall once the shots are fired.A chatbot has more empathy and emotional triggers due to its location: inside the one-to-one chat. This gives it an air of interpersonal feeling, as opposed to an external and disconnected notification center. A welcome chatbot is in-app automation (client-side or server-side), as it leverages the conversational experience (the vertical timeline). There is no absolute need for any type of AI - your chatbot can be rule-based with quick replies, as it belongs to a properly mapped user experience. Such a chatbot is an opportunity to be fun and warming, as it can establish the users’ first steps, and thus a general “connection” to the experience.Warning: the experience of a chatbot leads to disappointment sooner or later in the user’s journey. That is especially true if the AI or the decision-tree is not fit for the job. So you have to set the expectations for your users, to prevent or delay that disappointment. “A smile is the universal welcome.” (Max Eastman)Social, open networks, for higher discoverySimply put, the social network sector is quite overcrowded, as the major players over there are really huge. The barrier of entry is high… Unless you are bringing a really disruptive innovation, that is proven to be a game changer, and fit for massive adoption. But then it is often a hard sell.Instead, instant messaging is again booming, mainly thanks to its third generation. There are plenty of players here, and thus it is indeed very hard for a new app to get discovered on the stores, but the market is more accessible to businesses.Social posting, liking and commenting are features all well known on social apps. Building the same features on top of conversational apps is a trend today, a real trend even if still a bit shy and hardly noticeable. Here is why: it allows users/customers to discover communities, places, and people. It enables browsing, searching, and interaction through all available open and public content. In other words, it indirectly gives humans more opportunities to interconnect with more humans and bots. And as a consequence, this increases their network value. It is about growing your users’ network and own branding, and to engage with their audiences.Warning: the content inconsistency that you are used to in various apps, whether you refresh or change the device, is a real pain. Be careful about the expectations when people browse to find something. “The only real voyage of discovery consists not in seeking new landscapes but in having new eyes.” (Marcel Proust)Groupchat, closed networks, for continuous interactionsThe groupchat market is still accessible, although massive adoption is clearly observable. A multiplicity of categories and viable niches exist today, and the exploration is not over. Proof of this resides in some big players (Cisco, Microsoft, Google) jumping on the bandwagon, after the huge successes of Slack, HipChat, Mattermost, Rocket.chat, Zulip, Matrix, Ring. The model has definitely won hearts, with the numbers following sui" <> ..., title: "Messaging feature sets and their benefits", url: "https://www.erlang-solutions.com/blog/messaging-feature-sets-and-their-benefits.html"}
%{author: "by Areege Al Zubaidi", text: "9 unmissable upcoming Erlang + Elixir events2017-10-17\n        by Areege Al Zubaidi\n      This blog post was initially sent as an email exclusively to subscribers to our mailing list. Get exclusive content first, sign up now!A Case Study in LASP and Distribution at Scale - London, UKChris Meiklejohn, lover of distributed systems and programming languages, and Basho alumni, will be at the London Erlang User Group to discuss a case study where Lasp is applied in distributed, large scale systems.\nWhat you need to know\nLocation: Erlang Solutions HQ, E1 8PY, London\nTime & Date: 18:30 BST, Thursday 19 October 2017\nFree event - just RSVP\n\nCode Mesh - The Alternative Programming Conference - London, UKWe’re excited to sponsor Code Mesh 2017, which returns to London this November. Keynotes include Margo Seltzer’s Automatically Scalable Computation, Guy L. Steele’s A Cobbler’s Child, David Turner’s Some History of Functional Programming Languages, and Matt Might’s Winning the War on Error.\nWhat you need to know\n\nLocation: ILEC Conference Centre, SW6 1UD, London\nTime & Date: Tuesday 7 - Thursday 9 November 2017\nTicketed event - Early bird tickets available\n\nGet 10% off Code Mesh tickets with our exclusive code: ESLmeetup10\n\nHow to build distributed applications with Erlang - Milan, ItalyGabriele Santomaggio, developer at Erlang Solutions, returns to CodeMotion to look at how one can use Erlang and/or Elixir to create a distributed application through the OTP libraries. Facebook, Whatsapp, and other large companies utilize these technologies, but we will see how they can be used in real terms through real-life cases.\n\nWhat you need to know\nLocation: BASE, Via Bergognone 34, 20144, Milan\nTime & Date: Wednesday 8 - Saturday 11 November 2017\nTicketed event - Special ticket prices available now\n\nØredev 2017 - Next Gen Developer Conference - Malmö, SwedenFor developers in Sweden, we’ll be at Øredev 2017, the perfect blend of in-depth workshops and conference sessions. Erlang Solutions’ Head of Elixir, Claudio Ortolina, will be there with two talks; GenStage by Example and Practical Elixir Flow.\nWhat you need to know\n\nLocation: Slagthuset Exhibition & Conference Center, Malmö\nTime & Date: Tuesday 7 - Friday 10 November 2017\nTicketed event - 20% group discounts available\n\nErlang, Func You Up! - Stockholm, SwedenThis meetup is for newbies. Come to meet experienced consultants, and ask any question you want about Erlang, Elixir, LFE, Lua. Bring your hobby projects to work on, or ask for a review of your code. If you are willing to display your code on a TV screen, it can be a shared learning experience.\nWhat you need to know\n\nLocation: Erlang Solutions, Saltmätargatan 5, 2tr, Stockholm\nTime & Date: 18:00 CET, Wednesday 15 November 2017\nFree event - just RSVP\n\nIndia Erlang & Elixir Factory Lite - The First Ever! - Bangalore, IndiaIndia - we’re coming for you! \nThe final schedule for India Erlang and Elixir Factory Lite in Bangalore has been published. Don’t miss speakers like Robert Virding, Francesco Cesarini, and Mark Allen in the first event of its kind in India. Many of the speakers will also be running training workshops around the conference.\nWhat you need to know\n\nLocation: Fortune Park JP Celestial Hotel, Race Course Road, Bangalore\nTime & Date: Friday 17 November 2017\nTicketed conference - Tickets still available\n\nParis Open Source Summit 2017 - Paris, FranceErlang Solutions’ MongooseIM team will join the XMPP Standards Foundation (XSF) at this year’s Paris Open Source Summit. Be sure to come and say Hi to the team at the XSF members village! MongooseIM product owner Nicolas Vérité will also be speak, presenting “Open source : non-assistance à UX en danger”.\nWhat you need to know\n\nLocation: Les Docks de Paris\nTime & Date: Wednesday 6 - Thursday 7 December 2017\nFree exhibition passes - Get yours here\n\nLambda Days 2018 - Kraków, PolandMary Sheeran, Philip Wadler, Felienne Hermans, Robert Virding and Kevin Hammond are just a few of the amazing people who dedicate their time to review Lambda Days 2018 talk proposals. Want to pick their b" <> ..., title: "9 unmissable upcoming Erlang + Elixir events", url: "https://www.erlang-solutions.com/blog/9-unmissable-upcoming-erlang-elixir-events.html"}
%{author: "by Lajos Gerecs", text: "From the developer: What’s new in WombatOAM 3.0.0beta?2017-10-19\n        by Lajos Gerecs\n      A lot has changed since the last major release of WombatOAM. There were several minor releases in the past year and below you’ll find a non-comprehensive list of the main features and improvements introduced in this time. Before you go any further, you should know that you can test all of this out today with a 45 day free trial for WombatOAM 3.0.0beta. What is WombatOAM?WombatOAM is an on premises monitoring tool to collect metrics in your Erlang- and Elixir-based applications. It provides historical data and live visibility into your processes’ measurements and logs, continuously checks if these are normal, and raises alarms early to prevent downtime or faulty behaviour. WombatOAM contains an interactive Web Dashboard where you can view metrics and manage the associated nodes, and features several integrations to send the data elsewhere. \n\nA Better DashboardWombatOAM went through a big redesign, where it’s finally reached its current, much improved version. We worked hard on the Web Dashboard making the user interface more intuitive for developers and support engineers as well. The whole look and feel changed giving it a more modern appearance.  \n\nWombatOAM’s Frontpage shows the most important Erlang metrics\nWombatOAM has several Tools which can help diagnose issues with Erlang nodes or clusters directly from the Web Dashboard. The built-in Etop and ETS Table viewer also got a facelift. Now the Node manager tools are moved to the Node Homepage, so tools like Garbage Collector Runner and Node Configurator are accessible right from the Node details. This change was made to make sure you have all the available tools controlling the node and its parameters in one place. Network partitions can and will happen in distributed systems. When a node using Mnesia is separated from the other nodes in the cluster the databases’ contents will diverge. WombatOAM can now detect partitioned Mnesia clusters and raises alarms, we’ve also included a tool to fix the issue by a click of a button. \n\nSome of the Tools are available on the Node homepage to help investigate issues\nTo be able to quickly get up and running after adding a node, we introduced Product Based Frontpages supporting Riak, RabbitMQ, Phoenix, Erlang, and Elixir. This means that WombatOAM will automatically generate a frontpage with graphs of the most important metrics related to the application. Of course you still have the ability to set up custom graphs and customise the frontpage. \n\nImproved Elixir and Phoenix supportElixir’s popularity is continuing to rise so we added numerous features which makes Elixir users’ lives easier. WombatOAM now supports multiple metrics from the Phoenix Web Framework, it collects information related to requests, such as average response time, request count, errors, etc. It also logs query runtimes and other metrics from Ecto and can collect logs from Elixir’s Logger. \n\nWombatOAM displaying Phoenix and Cowboy metrics\nWe’ve added a few other metrics and related alarms as well, like Inode Count, which will notify if a mount is running out of available Inodes. WombatOAM is now better at inspecting RabbitMQ queues and can provide a lot of useful information, including message counts in RAM or on disk, unacknowledged message numbers, etc, for each queue.  We also developed a SumoDB plugin which can log the time taken by the database actions (for example insert, update, delete) and provides a viewer for the data stored in the db as well. \nWe introduced a new graph type, you can now set up gauges to display metrics. \n\nSmarter Alarm HandlingWombatOAM’s alarms can direct your attention towards serious issues in the system thus preventing outages. These problems can range from high CPU load or high memory usage to Erlang VM specific issues, limits imposed by the emulator like atom limits, and application misconfigurations. They can help you investigating scaling issues and application runtime issues as well. Tags were introduced, giving you the options for d" <> ..., title: "From the developer: What’s new in WombatOAM 3.0.0beta?", url: "https://www.erlang-solutions.com/blog/from-the-developer-what-s-new-in-wombatoam-3-0-0beta.html"}
%{author: "by Zsolt Dudas", text: "Getting started with WombatOAM2017-10-24\n        by Zsolt Dudas\n      With the release of WombatOAM 3.0.0beta - our operations, monitoring, maintenance, and performance tool for Erlang OTP based systems, I thought it was time to recap how to install WombatOAM. Get a 45 day free trial. PrerequisitesBefore installing WombatOAM, ensure that the machine meets the prerequisites. The following is required before installing WombatOAM:- A UNIX operating system (WombatOAM has been tested on Linux and Mac OS X)- The Erlang run-time system, ERTS (R15B03 or later)- OpenSSL and libcrypto (already present on Mac OS X) Installing WombatOAMTo install WombatOAM on your computer, retrieve the current WombatOAM package and run the installation script. To do this, execute the following commands:\n0.tar.gz\n\ntar xfz wombat-2.9.0.tar.gz\n\ncd wombat-2.9.0\n\n./upgrade.sh # copy the license key into the directoryThe ./upgrade.sh command returns the following:1) [path to old wombat installation]\n\n2) Other\n\n3) Skip upgradeIf you are installing WombatOAM for the first time, enter 3 at the prompt, skipping the upgrade. The upgrade.sh script will simply build a release and start WombatOAM for you.Upgrading WombatOAMTo upgrade an existing installation of a previous version of WombatOAM, open the package for the new version and execute the following command:1 ./upgrade.shAt the prompt, enter 2 (Other) and follow further prompts to specify the WombatOAM installation to upgrade from and perform the upgrade.\n\nThe upgrade.sh script will preserve your collected data and custom configuration (in your old rel/wombat/files/wombat.config file).The WombatOAM web dashboardTo access the web dashboard, go to http://localhost:8080 in your browser. Log in with the user name admin and password admin.Running WombatOAMYou can start and stop WombatOAM with the following commands, if necessary:./start.sh # start Wombat\n\n./stop.sh # stop WombatKeep in mind that the upgrade.sh script will start Wombat automatically. To check whether Wombat is actually running, check whether you can access the WombatOAM web dashboard on http://localhost:8080.Using WombatOAMTo see how WombatOAM handles nodes, you can install the WombatOAM node itself into WombatOAM:1. Select the Topology tab and click on the + button.WombatOAM’s Topology page, illustrating the + buttons2. Enter the following:- Node name: wombat@127.0.0.1- Cookie: wombat \nAdd a new node pop-up3. Click the Add node button. The WombatOAM node should come up in a few seconds. If it doesn’t, check the following log file: rel/wombat/wombat/log/wombat.logClick Done and you will be redirected to your node’s frontpage. From here, you have an overview of the metrics and active alarms associated with your node.Node frontpage Click the Metrics tab, select the node, and then select a metric. For example, click Memory → Process memory. You should see the measurements made on that node.\nProcess memory metrics for a specific nodeInterested in seeing how WombatOAM can give you full visability of your Erlang or Elixir system? Get a 45 day free trial, on us!\n\nGo back to the blog\n\nTags:wombatoammonitoringmaintenanceErlangElixirShare  Facebook Twitter Linkedin E-mail", title: "Getting started with WombatOAM", url: "https://www.erlang-solutions.com/blog/getting-started-with-wombatoam.html"}
%{author: "by Areege Al Zubaidi", text: "Building the ideal technology stack for online gambling & betting2017-10-26\n        by Areege Al Zubaidi\n      Over the years, we gained great insight into the industry. Erlang is uniquely suited to address the biggest technological challenges of Online Gambling & Betting companies:  InnovationThe Challenge\n\nNew products and features must be released fast and often to keep market advantage and stay relevant. Innovation with Erlang\n\nWith support for millions of lightweight processes, Erlang allows you to build massively concurrent and fault tolerant applications very quickly. Erlang’s functional paradigm makes program outputs much easier to predict, therefore easier to debug and analyse.ScaleThe Challenge\n\nApplications must scale and behave predictably during high traffic or sudden peaks in demand, such as World Cup Finals or the Superbowl.Scale with Erlang\n\nWith its background in telecommunications, Erlang excels in handling message explosion and multiplexing – the generation of a cascade of messages out to individual users starting from a single event. This multiplexing can span hundreds of servers in a coherent way that maintains message delivery order.ReliabilityThe Challenge\n\nIf an online gambling and betting system crashes, it needs to recover so quickly no one will ever notice it failed. Live bets can’t fall through the cracks!Reliability with Erlang\n\nErlang’s concurrency, it’s no-shared memory architecture and built-in ‘fail and recover’ approach make it behave extremely gracefully and predictably under highly variable stochastic load. This makes Erlang ideal to build critical gambling and betting systems on.Real timeThe Challenge\n\nInformation about odds must be delivered with enough speed that it stays actionable during bet placing.Real time with Erlang\n\nBecause of Erlang’s soft real time properties inherited from the telephony world, reactions to external events occur in microseconds, allowing for timely responses.Self-relianceThe Challenge\n\nYou must have complete ‘under the hood’ visibility, to be able to control your systems and make fixes yourself.Self reliance with Erlang\n\nErlang was open sourced in 1998, and it has a mature ecosystem and an active community whom you can ask for knowledge sharing. Erlang also has WombatOAM, a full visibility performance monitoring and maintenance tool. Speed and uptimeThe Challenge\n\nOperators want to release fast and with as little downtime as possible.Speed and uptime with Erlang\n\nErlang is designed for 24/7 applications allowing the dynamic upgrading of running production systems. With its built-in support for distributed code delivery you can upgrade a farm of servers from one host.Building the ideal betting stackChandru Mullaparthi, former Head of Software Architecture at bet365, recently joined the London Erlang User Group to discuss his thoughts on what makes up the ideal technology stack to meet all of the challenges within fast-paced, modern industries like online gambling and betting:Learn more about Erlang for Online Gambling & Betting. \n\n\nGo back to the blog\n\nTags:ErlangvideoOnline Gambling & BettingShare  Facebook Twitter Linkedin E-mail", title: "Building the ideal technology stack for online gambling & betting", url: "https://www.erlang-solutions.com/blog/building-the-ideal-technology-stack-for-online-gambling-betting.html"}
%{author: "by Nicolas Vérité", text: "MongooseIM 2.1.0: stronger platform for better chat experience2017-11-02\n        by Nicolas Vérité\n      A great dilemma for app makers is whether to develop their chat in house, or buy an off-the-shelf solution (“Make-Or-Buy Decision”). Between these extremes the MongooseIM platform provides a flexible set of software components paired with services to fit companies’ specific strategies. It solves the problem of asset building when it comes to chat or instant messaging experiences. What used to be MongooseIM standalone server has pivoted to a platform with MongooseIM 2.0.x series. We started offering new components (backend/server and frontend/client), on top of which you can quickly and efficiently build your solution. The 2.1.0 release is the next chapter of this story, as we deliver a solid iteration with more components that address even more IT challenges, and stronger than ever code base and documentation.Executive summary: one significant leap forwardWith the version 2.1.0, the MongooseIM platform has climbed one step higher in the ladder:Code and documentation efforts have produced a better platform for you to build onThe new Push Notifications and STUN/TURN components are delivering stronger consistency in your ITOur Tide continuous load testing infrastructure guarantees a focus on faster operationsThe following versions on the roadmap will offer geo clustering, IoT and chatbots.A stronger platform, for allMongooseIM code and documentation, for your staffTechie crowds, like craftsmen and operations teams, have to assess and handle ever increasing complexity. We have built means to fluidify your experience on code, and administration fronts, binding them all with documentation!Code attention, for better craft and operations**Code quality, style, and consistency has received a lot of attention: we delivered various improvements, maintenance, refactoring, on top of which we paid technical debt, and obviously added even more tests.For some highlights, we have:Achieved Erlang/OTP 20 compatibility,Added full text search for MAM (Message Archive Management),Implemented XMPP pipelining,Delivered Erlang distribution over TLS,Built accumulators, message metadata for fine-grained inspection and traceability,Accepted a JSON Web Token authentication contribution,Improved MAM, MUC light, and our REST APIs.Benefits: This considerable effort has produced an even more reliable codebase, fit for mature product teams, and for large scale production systems.Documentation love, for better view and understandingOur 2.1.x series has seen vast documentation improvements. We have reviewed,  maintained, and updated the technical content, the structure, and the phrasings, as well as augmented the graphical content. We have applied the art of craftsmanship to the doc!As a result, we have greatly improved the overall configuration literature, added some missing pages on some modules, extended existing ones: everything now leads to comprehensive configuration and architecture reference.Please browse it on: https://mongooseim.readthedocs.io/en/latest/Figure 1: the MongooseIM platform documentationSome examples of the most visible outcomes:Newcomers may follow our three main tutorials (or “HOWTOs”):Building MongooseIM from source codeSet up MongoosePushSet up MongooseICEDevelopers will love our REST API entries:Client/frontend REST APIMetrics backend REST APIAdministration backend REST APISysadmins and devops should like the authentication section revamp:External authenticationHTTP authenticationJWT authenticationLDAP authenticationBenefits: As a consequence, it is now easier to find and use what you are looking for. All features should be covered and properly documented.Future-proofThe code is ready to process intensive traffic and the documentation will help you to configure it to do so. We have a stronger basis for longer term improvements, additions, and customisations.MongoosePush & MongooseICE, for your infrastructureCTOs and architects constantly looking for more efficient alternatives, please welcome two new components in the Mongoose" <> ..., title: "MongooseIM 2.1.0: stronger platform for better chat experience", url: "https://www.erlang-solutions.com/blog/mongooseim-2-1-0-stronger-platform-for-better-chat-experience.html"}
%{author: "by Ayanda Dube", text: "Monitoring RabbitMQ: Native Nodes vs. Independent Agents 2017-11-07\n        by Ayanda Dube\n      \nBefore you go any further, you should know that you can test WombatOAM out today with a 45 day free trial for WombatOAM 3.0.0beta. RabbitMQ users are accustomed to monitoring and keeping track of the status of their RabbitMQ installations using the native RabbitMQ Management plugin, or, alternatively, using third party monitoring tools such as Sensu, which internally make use of the RabbitMQ Management API for metrics acquisition. Regardless of which tool users prefer, a common aspect which cuts across most of these off-the-shelf tools is full dependency on the RabbitMQ Management plugin. In other words, for you to monitor and manage your RabbitMQ installation via a web interface, the RabbitMQ Management plugin has to be enabled at all times on the RabbitMQ nodes. The downside of this approach lies mainly on the overhead the RabbitMQ Management plugin introduces per node on which it is enabled. The following image depicts the accompanying and required applications introduced on a node when the RabbitMQ Management plugin is enabled;Fig. 1: Applications introduced per node when the RabbitMQ Management plugin is enabledA total of 13 additional applications are required by the RabbitMQ Management plugin, which aren’t related to, or required to run any of the AMQP operations. Internally, the RabbitMQ Management plugin creates multiple Erlang ETS tables, which are RAM based, in order to store, aggregate and compute statistics and various RabbitMQ specific node metrics. Unless the hardware has been dimensioned to take this into account, it can place a huge demand on the node’s memory, and could potentially contribute to a number of unknown side effects when traffic load patterns vary from peak to peak.In an ideal world RabbitMQ nodes should be dedicated to delivery of the AMQP protocol i.e. queueing and message interchange logic between connected clients. All potential burdensome operations like UI monitoring and management should ideally be taken care of on a completely independant node; deployable on a separate physical machine from the RabbitMQ nodes, for all OAM functions. This is how the telecoms systems have addressed monitoring and operations for decades.  This inflexibility of the RabbitMQ Management plugin and other monitoring tools dependant on its API, bring to light the main strengths and advantages of using WombatOAM. Illustrated below, is the application overhead WombatOAM introduces on a RabbitMQ node;Fig 2: Application overhead WombatOAM introduces on a RabbitMQ nodeThe WombatOAM approach to monitoring RabbitMQSo what is different about the WombatOAM approach of monitoring RabbitMQ? Firstly, only one additional application is introduced, which is the wombat_plugin, unlike the 13 additional applications which are introduced by the RabbitMQ Management plugin.The reason behind this is the fact that WombatOAM only requires a single lightweight and highly optimised application, the wombat_plugin application, on the node it’s monitoring, to relay all metrics and events to a separate and independent node, responsible for carrying out all heavy computations and UI related operations. This implies a much less, if not negligible, application overhead on the RabbitMQ node in comparison to that introduced by RabbitMQ Management plugin, which carries out all of its computations and operations on the RabbitMQ node itself. These computations compete for the same resource as the traffic which RabbitMQ is processing.WombatOAM thus fully leverages distributed Erlang by carrying out its major operations and maintenance functions in a loosely-coupled manner, on an independent and separate node. This grants much more freedom to the RabbitMQ nodes to predominantly focus on AMQP functions, only, with very little or no chance at all, of experiencing any problems relating to UI operations and maintenance functions.NOTE: For releases prior 3.6.7, the RabbitMQ Management Plugin attempts to reduce the amount of overhead when used in a cluster " <> ..., title: "Monitoring RabbitMQ: Native Nodes vs. Independent Agents ", url: "https://www.erlang-solutions.com/blog/monitoring-rabbitmq-native-nodes-vs-independent-agents.html"}
%{author: "by Rafał Słota", text: "How to set up Push Notifications with MongoosePush2017-11-10\n        by Rafał Słota\n      The new version of our messaging platform, MongooseIM 2.1.0 has been recently released. MongooseIM 2.1.0, as a stronger platform for better chat experience is about quality, accessibility and building trust in the consistency and performance of our solution. It introduces new tools and improvements making access to MongooseIM features easier.In this tutorial, we will dive deep into the details of MongoosePush - help your ops deploy and your devs build push notifications in your chat system. This “How To” will help you keep your infrastructure coherent and perfectly integrated, in order to deliver new features faster and with more confidence over time.How to set up Push Notifications with MongoosePushMongooseIM server supports push notifications using FCM (Firebase Cloud Messaging) and APNS (Apple Push Notification Service) providers. Server side push notification support is fully compliant with XEP-0357 Push Notifications, which defines several components that need to work together in order to provide clients with working push notifications. The following list shows those components as defined in XEP-0357 and MongooseIM components that correspond to those entities:XMPP Server in MongooseIM is enabled by module mod_pushApp Server in MongooseIM is enabled by adding a push node type to mod_pubsub’s configurationXMPP Push Service is implemented as a MongoosePush applicationAll these entities have to be enabled and properly configured in order to use push notifications. So let’s get to it, shall we?Overall component architectureThe components that make push notifications possible in MongooseIM add up to the following architecture: The diagram lists three domains in total - two for MongooseIM and one for MongoosePush. Note that this separation is not required, all three components can be on the same host with the same domain.Configuring MongooseIM componentsFirstly, let’s configure all the required MongooseIM components, step by step.mod_pusha.k.a.‘XMPP Server’The first component that we need to configure in MongooseIM is the mod_push module. This module communicates with XMPP clients directly in order to enable/disable notifications on per-client basis.\nThe mod_push module is very easy to enable - just paste the following to your MongooseIM configuration file:{mod_push, [\n    {wpool, [{workers, 100}]}\n]}.\nAnd that’s basically it. You have just enabled the push notification support with 100 asynchronous workers that will handle all push notification related work.\nYou can also control the format of the “sender” of the push notification (which ultimately becomes the title of push notification) and filter which messages will trigger the notification. In that case you need to create a plugin module that implements the mod_push_plugin behaviour and enable this plugin as specified in the mod_push documentation.mod_pubsubwithmod_push_service_mongoosepusha.k.a.'App Server’The next component to configure consist of two modules:mod_pubsub with a push node type enabled that will act as a sink for push notifications generated by mod_pushmod_push_service_mongoosepush - a connector to MongoosePush applicationmod_pubsub’s push nodeAccording to the XEP-0357 Push Notifications, all notifications generated via the module we have just enabled (i.e. mod_push) have to be send to a push enabled publish-subscribe node. In order to allow clients to allocate such a node, we need to enable it in our mod_pubsub on the MongooseIM server that will communicate with the XMPP Push Service.The minimal mod_pubsub’s configuration looks as follows:{mod_pubsub,[{plugins,[<<\"push\">>]}}]}.Such configuration will enable the mod_pubsub with only one node type available: push. Please note that if you want use mod_pubsub as a 'normal’ publish-subscribe service, you just need to append the <<“push”>> node type to the plugins list. Also, it’s important to note, that the first node type on the plugins list. will be the default one (allocated when the client does not provide a node ty" <> ..., title: "How to set up Push Notifications with MongoosePush", url: "https://www.erlang-solutions.com/blog/how-to-set-up-push-notifications-with-mongoosepush.html"}
%{author: "by Ayanda Dube", text: "Three WombatOAM Agents and a RabbitMQ2017-11-14\n        by Ayanda Dube\n        Before you go any further, you should know that you can test WombatOAM out today with a 45 day free trial for WombatOAM 3.0.0beta.  As of version 2.7.0, WombatOAM has three additional RabbitMQ agents that are shipped as part of the main RabbitMQ plugin. These three agents are more specific to the internal elements of RabbitMQ, namely Queues, Channels, and Connections, with each providing finer and more detailed metrics per individually configured and selected metric attribute.Whereas before, where WombatOAM’s single RabbitMQ plugin would provide an overview of the aggregate metrics, these three additional agents now provide the much desired lower level metric information of the RabbitMQ node being managed. These are illustrated below.RabbitMQ Queues AgentThe RabbitMQ Queues agent provides the capabilities of monitoring queues on an individual basis, with the following attributes being configurable, for each queue.messagesmessages_readymessages_unacknowledgedmessages_ready_rammessages_unacknowledged_rammessages_rammessages_persistentmessage_bytesmessage_bytes_readymessage_bytes_unacknowledgedmessage_bytes_rammessage_bytes_persistentdisk_readsdisk_writesconsumersmemory By default, the RabbitMQ Queues agent is configured to monitor the total number of messages for each queue existing on the node being monitored. More details on how to configure this agent may be found in the WombatOAM documentation. The following image illustrates this agent in use: RabbitMQ Queues Plugin message metric illustrationRabbitMQ Channels AgentThe RabbitMQ Channels agent provides the capabilities of monitoring channels on an individual basis, with the following attributes being configurable, for each captured (alive) channel.numberreductionsconsumer_countmessages_unacknowledgedmessages_unconfirmedmessages_uncommittedacks_uncommittedprefetch_countglobal_prefetch_count The following image illustrates this agent in use, with the consumer_count attribute configured for monitoring, for all channels:RabbitMQ Channels Plugin message metric illustrationRabbitMQ Connections AgentThe RabbitMQ Connections agent provides the capabilities of monitoring connections on an individual basis, with the following attributes being configurable, for each captured (alive) connection.frame_maxchannel_maxrecv_octrecv_cntsend_octsend_cntsend_pendchannels The following image illustrates this agent in use, with the channels attribute configured for monitoring, for all connections:\nRabbitMQ Connections Plugin message metric illustration  This blog post is an excerpt from RabbitMQ Operations & Maintenance using WombatOAM by Ayanda Dube. Download the full guide here.Go back to the blog\n\nTags:RabbitMQqueuesChannelsconnectionswombatoammonitoringAgentsShare  Facebook Twitter Linkedin E-mail", title: "Three WombatOAM Agents and a RabbitMQ", url: "https://www.erlang-solutions.com/blog/three-wombatoam-agents-and-a-rabbitmq.html"}
%{author: "by Rafał Słota", text: "How to set up MongooseICE (ICE/TURN/STUN server)2017-11-21\n        by Rafał Słota\n      The new version of our messaging platform, MongooseIM 2.1.0 has been recently released.\nMongooseIM 2.1.0, as a stronger platform for better chat experience is all about quality and building trust in the consistency and performance of our solution. It introduces tools and improvements making access to MongooseIM features easier.This tutorial will take you through the details of MongooseICE - help your ops deploy and your devs build a STUN and TURN server for NAT traversal and stream relay. This “How To” will help you keep your infrastructure coherent and perfectly integrated, in order to deliver new features faster and with more confidence over time.IntroductionWho is this document for?This tutorial presents our TURN/STUN server in action.\nYou get to see how to set up and configure MongooseICE and examine a system utilising its many talents. Are you in need of an application requiring NAT traversal? Want to see how a TURN and STUN server would handle it? Or maybe you just like to tinker with interesting technologies and experience setting them up first hand?If that’s the case, this tutorial is for you.What is the end result of this tutorial?At the end of the tutorial you will have a working environment with two peers, one sending a live video to another.\nThe peer-to-peer communication will not be obstructed by any NATs that may occur in the background.\nThe live video stream is only an example here - there are many possible use cases for peer-to-peer communication with NAT traversal.\nWe chose to build an example application that shows video streaming, because it’s vivid, catchy and fun.What do I need to begin?Before you begin you have to prepare an environment for setting up the components used in this tutorial.\nHere’s a list of things you’ll need:One Android phone (or at least an Android emulator).\nThe video player in this tutorial is available only as an Android application.RaspberryPi or any other device that is able to run Elixir code. Oh, and also has ffmpeg installed.\nWe are going to use use RaspberryPi 3, to give this tutorial a hint of IoT.At least one machine with a public IPv4 address.\nIt is necessary, because both MongooseIM and MongooseICE servers need to be accessible by all devices that are used in this demo system.\nYou could use a private, local IP address, but then you would need to ensure that your phone and the RaspberryPi are behind some kind of a NAT relative to this IP address.Note: the demo will probably work without the NAT, but then there is no point in setting up a TURN server.We are going to use 2 VPS (Virtual Private Server) that are located somewhere far far away, both having public IPv4 address. Let’s say MongooseICE is bound to 1.1.1.1, and MongooseIM to 2.2.2.2.General architecture of the environment built with this tutorialThis is the architecture of the system we are building:As we know by now, MongooseIM is bound to 2.2.2.2/myxmpp.com and MongooseICE to 1.1.1.1.\nWe also have a RaspberryPi that is connected to a private network (so is behind some NAT) and an Android phone that is connected to an LTE network and also is behind the carrier’s NAT.ICE notesThe end result of this tutorial not only uses MongooseICE and [MongooseIM] servers but also uses custom version of Mangosta-Android and [DemoStreamerICE].\nBoth projects are custom modified and custom made respectively in order to showcase the video streaming using the data relay capabilities provided by MongooseICE.\nThe streaming itself, along with the signalling protocol, were prepared only for the case of this demo and are not a part of the platform.\nThose components exist only to visualize what can be achieved with MongooseICE and what can be built on top of it.Setting up MongooseIM (signalling)The ICE is nothing without signalling. The signalling protocol itself can be designed specifically for the application that is being deployed or can be implemented based on some standards, e.g. Jingle.\nHere, we chose to implement the simplest signalling possible," <> ..., title: "How to set up MongooseICE (ICE/TURN/STUN server)", url: "https://www.erlang-solutions.com/blog/how-to-set-up-mongooseice-ice-turn-stun-server.html"}
%{author: "by Lajos Gerecs", text: "Monitoring Erlang and Elixir just got better - Introducing WombatOAM 3.0.02017-11-28\n        by Lajos Gerecs\n      A lot has changed since the last major release of WombatOAM. There were several minor releases in the past year and below you’ll find a non-comprehensive list of the main features and improvements introduced in this time. Before you go any further, you should know that you can test all of this out today with a 45 day free trial for WombatOAM 3.0.0. What is WombatOAM?WombatOAM is an on premises monitoring tool to collect metrics in your Erlang- and Elixir-based applications. It provides historical data and live visibility into your processes’ measurements and logs, continuously checks if these are normal, and raises alarms early to prevent downtime or faulty behaviour. WombatOAM contains an interactive Web Dashboard where you can view metrics and manage the associated nodes, and features several integrations to send the data elsewhere. \n\nA Better DashboardWombatOAM went through a big redesign, where it’s finally reached its current, much improved version. We worked hard on the Web Dashboard making the user interface more intuitive for developers and support engineers as well. The whole look and feel changed giving it a more modern appearance.  \n\nWombatOAM’s Frontpage shows the most important Erlang metrics\nWombatOAM has several Tools which can help diagnose issues with Erlang nodes or clusters directly from the Web Dashboard. The built-in Etop and ETS Table viewer also got a facelift. Now the Node manager tools are moved to the Node Homepage, so tools like Garbage Collector Runner and Node Configurator are accessible right from the Node details. This change was made to make sure you have all the available tools controlling the node and its parameters in one place. Network partitions can and will happen in distributed systems. When a node using Mnesia is separated from the other nodes in the cluster the databases’ contents will diverge. WombatOAM can now detect partitioned Mnesia clusters and raises alarms, we’ve also included a tool to fix the issue by a click of a button. \n\nSome of the Tools are available on the Node homepage to help investigate issues\nTo be able to quickly get up and running after adding a node, we introduced Product Based Frontpages supporting Riak, RabbitMQ, Phoenix, Erlang, and Elixir. This means that WombatOAM will automatically generate a frontpage with graphs of the most important metrics related to the application. Of course you still have the ability to set up custom graphs and customise the frontpage. \n\nImproved Elixir and Phoenix supportElixir’s popularity is continuing to rise so we added numerous features which makes Elixir users’ lives easier. WombatOAM now supports multiple metrics from the Phoenix Web Framework, it collects information related to requests, such as average response time, request count, errors, etc. It also logs query runtimes and other metrics from Ecto and can collect logs from Elixir’s Logger. \n\nWombatOAM displaying Phoenix and Cowboy metrics\nWe’ve added a few other metrics and related alarms as well, like Inode Count, which will notify if a mount is running out of available Inodes. WombatOAM is now better at inspecting RabbitMQ queues and can provide a lot of useful information, including message counts in RAM or on disk, unacknowledged message numbers, etc, for each queue.  We also developed a SumoDB plugin which can log the time taken by the database actions (for example insert, update, delete) and provides a viewer for the data stored in the db as well. \nWe introduced a new graph type, you can now set up gauges to display metrics. \n\nSmarter Alarm HandlingWombatOAM’s alarms can direct your attention towards serious issues in the system thus preventing outages. These problems can range from high CPU load or high memory usage to Erlang VM specific issues, limits imposed by the emulator like atom limits, and application misconfigurations. They can help you investigating scaling issues and application runtime issues as well. Tags were introduced, giving you t" <> ..., title: "Monitoring Erlang and Elixir just got better - Introducing WombatOAM 3.0.0", url: "https://www.erlang-solutions.com/blog/monitoring-erlang-and-elixir-just-got-better-introducing-wombatoam-3-0-0.html"}
%{author: "by Lukas Larsson", text: "Erlang Garbage Collector2017-11-30\n        by Lukas Larsson\n      This is an update to our previous blog post, Erlang 19.0 Garbage Collector. With Erlang/OTP 20.0, some things have changed, which is the reason for this updated blog post.Erlang Garbage CollectorErlang manages dynamic memory with a tracing garbage collector. More precisely a per process generational semi-space copying collector using Cheney’s copy collection algorithm together with a global large object space.OverviewEach Erlang process has its own stack and heap which are allocated in the same memory block and grow towards each other. When the stack and the heap meet, the garbage collector is triggered and memory is reclaimed. If not enough memory was reclaimed, the heap will grow.Creating DataTerms are created on the heap by evaluating expressions. There are two major types of terms: immediate terms which require no heap space (small integers, atoms, pids, port ids etc) and cons or boxed terms (tuple, big num, binaries etc) that do require heap space. Immediate terms do not need any heap space because they are embedded into the containing structure.Let’s look at an example that returns a tuple with the newly created data.data(Foo)->Cons=[42|Foo],Literal={text,\"hello world!\"},{tag,Cons,Literal}.In this example we first create a new cons cell with an integer and a tuple with some text. Then a tuple of size three wrapping the other values with an atom tag is created and returned.On the heap tuples require a word size for each of its elements as well as for the header. Cons cells always require two words. Adding these things together, we get seven words for the tuples and 26 words for the cons cells. The string \"hello world!\" is a list of cons cells and thus requires 24 words. The atom tag and the integer 42 do not require any additional heap memory since it is an immediate. Adding all the terms together, the heap space required in this example should be 33 words.Compiling this code to beam assembly (erlc -S) shows exactly what is happening....{test_heap,6,1}.{put_list,{integer,42},{x,0},{x,1}}.{put_tuple,3,{x,0}}.{put,{atom,tag}}.{put,{x,1}}.{put,{literal,{text,\"hello world!\"}}}.return.Looking at the assembler code we can see three things; The heap requirement in this function turns out to be only six words, as seen by the {test_heap,6,1} instruction. All the allocations are combined to a single instruction. The bulk of the data {text, \"hello world!\"} is a literal. Literals, sometimes referred to as constants, are not allocated in the function since they are a part of the module and allocated at load time.If there is not enough space available on the heap to satisfy the test_heap instructions request for memory, then a garbage collection is initiated. It may happen immediately in the test_heap instruction, or it can be delayed until a later time depending on what state the process is in. If the garbage collection is delayed, any memory needed will be allocated in heap fragments. Heap fragments are extra memory blocks that are a part of the young heap, but are not allocated in the contigious area where terms normally reside. See The young heap for more details.The collectorErlang has a copying semi-space garbage collector. This means that when doing a garbage collection, the terms are copied from one distinct area, called the from space, to a new clean area, called the to space. The collector starts by scanning the root-set (stack, registers, etc).It follows all the pointers from the root-set to the heap and copies each term word by word to the to space.After the header word has been copied a move marker is destructively placed in it pointing to the term in the to space. Any other term that points to the already moved term will see this move marker and copy the referring pointer instead. For example, if the have the following Erlang code:foo(Arg)->T={test,Arg},{wrapper,T,T,T}.Only one copy of T exists on the heap and during the garbage collection only the first time T is encountered will it be copied.After all terms referenced by the root-set have been copie" <> ..., title: "Erlang Garbage Collector", url: "https://www.erlang-solutions.com/blog/erlang-garbage-collector.html"}
%{author: "by Ayanda Dube", text: "Advanced RabbitMQ Support Part II: Deeper Insight into Queues2017-12-06\n        by Ayanda Dube\n      Before you go any further, you should know that you can test WombatOAM out today with a 45 day free trial for WombatOAM 3.0.0IntroductionThe most important and critical elements of any RabbitMQ installation are the Queues. Queues retain messages specific to different use cases across various industrial sectors such as telecommunications, financial systems, automotive, and so forth. Queues, and their adherence to AMQP are essentially “why” RabbitMQ exists. Not only do they retain messages till consumption, but internally, they are also an implementation of some of the most complex mechanisms for guaranteeing efficient message propagation through the fabric, while catering for additional requirements such as high availability, message persistence, regulated memory utilisation, and so forth.So queues are general, the main focal point of any RabbitMQ installation. Which is why all RabbitMQ users and support engineers often find themselves having to do regular checks around queues, as well ensuring their host Rabbit nodes have been precisely configured to guarantee efficient message queueing operations. Typical questions that tend to arise from RabbitMQ users and support engineers are;… how many messages are in Queue “A”?… how many messages are pending acknowledgement in Queue “K”?… how many consuming clients are subscribed to Queue “R”?… how much memory is Queue “D” using?… how many messages in Queue “F” are persisted on disk?… is Queue “E” alive?Within RabbitMQ, the implementation of a queue is a combination of multiple aspects such as the behaviour specification governing its operation (e.g. internally, what is known as the backing queue behaviour), the transient/persistent message store components, and most importantly, the queue process dictating all the logic and mechanics involved in the queueing logic. From these, a number of attributes exist, which give an indication of the current state of the queue. Some of these queue attributes are illustrated below:Fig 1: RabbitMQ Queue AttributesWombatOAMAs of WombatOAM 2.7.0, the WombatOAM-RabbitMQ plugin now ships with an additional agent, the RabbitMQ Queues agent. This RabbitMQ Queues agent has been precisely designed and developed to allow monitoring and acquisition of metrics specific to Queues, as well as presenting them in a user friendly manner to RabbitMQ users. Two modes of operation are supported:Dynamic operation: Queues existing on the monitored node, with names matching to a user defined regex are dynamically loaded by WombatOAM for monitoring.\nStatic operation: Specific queues are configured and monitored as defined in the WombatOAM RabbitMQConfigurationThe manner in which this agent operates and presents metrics is solely dependant on the way in which it has been configured.1. Dynamic operationDynamic mode of monitoring Queues may be configured by defining a match specification, from which queue names are matched against as follows, and the particular, desired attribute/metric from each matched queue. For example, to monitor memory usage of all queues, the following configuration may be defined in the wombat.config file:{set, wo_plugins, plugins, rabbitmq_queues, dynamic_queues, [{match_spec, \".*\"},\n{metric, memory}]\n}.\nThis will capture all queues on the node being monitored and present memory metrics from queues.Fig 2: RabbitMQ Dynamic Queue Metrics2. Static operationIn static mode of operation, users explicitly specify Queues and corresponding attribute/metric they would like to monitor in the wombat.config . A complete static configuration entry would consist of the Queue Name, Virtual Host, and the Attribute being measured. For example, to monitor the number of messages , consumers and amount of memory utilisation from the SERVICES.QUEUE , and number of messages only, from the EVENTS.QUEUE, a user may specify the following configuration from the wombat.config file:{set, wo_plugins, plugins, rabbitmq_queues, static_queues,\n[{<<\"SERVICES.QUEUE\">>, <<\"/\">>, me" <> ..., title: "Advanced RabbitMQ Support Part II: Deeper Insight into Queues", url: "https://www.erlang-solutions.com/blog/advanced-rabbitmq-support-part-ii-deeper-insight-into-queues.html"}
%{author: "by Francesco Cesarini", text: "World, meet Code Sync Conferences2017-12-06\n        by Francesco Cesarini\n      I attended my first Erlang User Conference in 1995. It was my first conference ever. I was an intern at the Computer Science Lab, working on my Master’s thesis with Joe Armstrong. The conference was opened by Erlang System’s manager Roy Bengtson, my future boss. In his opening talk, he announced two new libraries, the Erlang Term Storage,  and the Generic Server Module, as well as the tools which were eventually merged to give us the Observer. When attendees complained over the lack of documentation for these tools, Klacke at the CS Lab suggested they write it themselves. The two day conference had doubled in numbers from its first installation the previous year, with presentations from the Computer Science Laboratory, Erlang Systems, Ericsson and Universities around the world. It was the beginning of something you do not get to experience often. \nOpening slide from the proceedings of the Second Erlang User Conference 1995The journey to launching Code SyncBy 2009, the conference had outgrown the Ericsson conference center in Älvsjö, the conference chair Bjarne Däcker (the former head of the Computer Science Lab) had retired and the OTP team did not have the infrastructure and flexibility needed to expand the event. We at Erlang Solutions had gained experience in events by running the Erlang eXchange in 2008 followed by the first Erlang Factory in Palo Alto in early 2009. Ericsson asked us to help, so we took over the logistics and worked with them to put together the program. \nCan you spot me at Erlang User Conference 2006?From these humble beginnings, a conference focused on Erlang expanded to include OTP. Use cases of trade-offs in distributed systems. Talks on cloud infrastructure, orchestration and micro services before the terms were invented. And attempts to make Erlang OO (Not the way Alan Kay intended it) were described and forgotten. The discussions in the hallway track were on the unsuitability of C++ for certain types of problems and around an emerging language called Java. Fast forward to 2017, the focus from Java has moved to the JVM and its ecosystem. It is Scala, Akka, Groovy, Grails, Clojure and Spring. The same happened with .NET, giving it an ecosystem for C#, F# and Visual Basic to thrive. Erlang’s natural progression was no different. As time progressed, the BEAM came along, and new languages were created to run on it. Reia, by Tony Arcieri was the first (who ever said that a Ruby Flavoured Erlang was a bad idea?) and Efene, a C-flavoured language by Mariano Guerra first presented at the Erlang Exchange in 2008 is still used in production today! The conferences evolved from a languages conference to a conference on the Erlang Ecosystem, where the BEAM and OTP were used to build scalable and resilient systems. Conferences where communities were exchanging experiences, inspiring and learning from one another. And as we started looking outside of the Erlang ecosystem, our events expanded to include talks on functional programming, concurrency, multi-core and distributed systems. As a result, the Erlang User Conference, Erlang Factory, and Code Mesh have grown to a roster of global Erlang, Elixir and Alternative Tech conferences which have gone from strength to strength. Who can forget Mike, Joe and Robert on stage bickering together, Martin Odersky joking on how Scala influenced Erlang, Simon Peyton Jones talking about Erlang and Haskell, two childhood friends grew up together or Joe Armstrong interviewing Alan Kay! As of today, we organise five tentpole conferences every year, as well as numerous satellite conferences and a thriving partnership with ElixirConf and Lambda Days.\nJoe Armstrong and Alan Kay in conversation at Code Mesh 2016Last month we took Erlang Factory Lite to the Indian Subcontinent for the first time! This was on the back of a successful event in Buenos Aires this March and a sold out Factory Lite in Rome. This happened alongside some of the best conferences we’ve ever put on, from Erlang and Elixir Factor" <> ..., title: "World, meet Code Sync Conferences", url: "https://www.erlang-solutions.com/blog/world-meet-code-sync-conferences.html"}
%{author: "by Ricardo Goncalves", text: "Code Mesh 2017: Day 1 review2017-12-19\n        by Ricardo Goncalves\n      Before you go any further, you should know that Code Mesh is now a part of Code Sync, our new family of global tech conferences. Learn more ->This year’s Code Mesh saw the conference go from strength to strength. So much so, I couldn’t fit the highlights from the entire conference in a single blog post. So here’s my take on the talks I attended on day one of Code Mesh 2017:Keynote: Automatically Scalable Computation - Margo SeltzerSpeaker: Margo Seltzer, (at the time) Herchel Smith Professor of Computer Science and the Faculty Director for the Center for Research on Computation and Society in Harvard’s John A. Paulson School of Engineering and Applied Sciences\nThis was the first keynote of CodeMesh and what a way to start. The main question was basically: “Can programs get better at running programs with practice?”The idea seems far-fetched and even Margo herself said that initially she thought the idea (coming from a young student) was a bit “naive”, in the sense that it was not possible and/or practical.Also keep in mind that she was talking about feeding the same program to the computer and it ran faster with time, and not some higher-level “neural network/deep learning” middleware that was being used.This idea works on the lowest level possible, the bits and bytes running inside your CPU, and it’s like branch prediction on steroids, where the program execution is divided in smaller parts and pre-computed (possibly in different cores). Over multiple runs, heuristics are built for that program that make these pre-computation somewhat accurate, depending on the program itself.Some of the benchmarks were pretty amazing, but to truly that this to the next step, it seems like hardware-support will be needed from the CPU.There is a lot more to it than this, but suffices to say that it was a great beginning to CodeMesh.A Practical Functional Relational Architecture: Building Systems with Datomic - David NolanSpeaker: David Nolan, Software Engineer at Cognitect\nDavid Nolan gave us a pretty good talk on immutability on the database with Datomic.Most of the talk was motivation for why we should care for an immutable database, which makes sense, since actually using one (like Datomic) seems pretty straightforward, given that you can’t screw up your data :)He argued that immutability, a characteristic of functional programming, was already an option on the front-end with technologies like React or ClojureScript (which Nolan is the creator) and on the back-end with functional languages (Erlang, Clojure, Haskell, etc.). This leaves the database as the odd one out.Datomic was born from that sentiment of bring the benefits of immutability for the entire stack. The live demo where Nolan trivially queried data from the past was also nice (and seems really useful for auditing, etc.).As an interesting side note, Datomic can actually delete data due to legal reasons.Beyond Eventual Consistency (FaunaDB, Calvin) - Jamie AllenSpeaker: Jamie Allen, Director of Engineering for the Unified Commerce Project at Starbucks\nJamie is the head of engineering at Starbucks, a company with a global presence, so you can imagine the scale at which they deal in their systems / databases.When he arrived at Starbucks, Cassandra was the DB of choice. But it turns out that eventual consistency is not ideal for every use case, and in particular for some the uses that Starbucks has (which I believe is the reward program that customers can sign-up for).So the engineering team lead by Jamie started their journey on finding a replacement for Cassandra that provided stronger guarantees than eventually consistency.He also argued that the CAP theorem is still misunderstood and maybe not the best way to frame the problem of data consistency, availability, etc.He suggests to use the PACELC theorem instead. The rest of the talk was a small review of the options that they looked at for their next DB: Amazon Aurora, Microsoft Cosmos, Google Spanner, CockroachDB and finally FaunaDB, which seems like t" <> ..., title: "Code Mesh 2017: Day 1 review", url: "https://www.erlang-solutions.com/blog/code-mesh-2017-day-1-review.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 2.1.1 - More than a patch!2018-01-25\n        by Piotr Nosek\n      About 3 months have passed since the final MongooseIM 2.1.0 release.Over that time we’ve gathered feedback from community and picked out improvements we really wanted to include in 2.1.0 (but the schedule is merciless!). The outcome is a release that closes the 2.x series.This is the last stop before the leap into 3.0.0, when you may expect significant changes and features.You might ask, “why do they call it >>More than a patch<<?“ as there are many catchier titles we could have used.The reason for that title is honesty, and us admitting our miscalculation. What started as a small revision, sort of closure after 2.1.0, turned into quite an impressive set on changes.What are these? Keep reading! Oh, and by the way: welcome to MongooseIM 2.1.1!Secure connections to databasesSecurity and connection encryption have always been important topics, not only in chat applications.To always stay ahead of the game, we’ve ensured that you can integrate MongooseIM with external (i.e.: not Mnesia) databases with TLS enabled.We’ve updated our dependencies where it was necessary and made sure everything is well-documented. With 2.1.1 you may add extra hardening to your platform, no matter if your MySQL/Postgres/etc. is running in the same local network, or in a separate location. For example, you could have a MongooseIM cluster running on bare metal in your data center, while calling MySQL deployed in a cloud (for extra flexibility).Obviously, it does not apply to Mnesia, which runs alongside MongooseIM and uses Erlang distribution for data exchange.If you’d like to add a similar level of security to it, you may enable TLS for Erlang distribution protocol. This improvement also does not apply to Redis, as there is no official support for connection encryption in this database yet. We may add some recommendations on enabling it in an unofficial way in the future.DeumbrellificationA word of explanation: Deumbrellification is a process of transforming an umbrella structure (an application that contains more applications) into a flat one. It makes developers’ life easier, as it means more intuitive code hierarchy and better integration with certain build systems.How does it apply to MongooseIM?For a large part of its lifetime, MongooseIM has been bundled with MySQL and PostgreSQL client libraries. It required a nested structure - the main application was placed in apps/ directory alongside these drivers. In the meantime, two events took place: we’ve begun fetching these drivers as dependencies and we’ve switched from Rebar 2 to Rebar 3.The former change has left us with more up-to-date libraries downloaded by Rebar, and with a somewhat awkward project structure with only one application remaining in apps/ directory. While we were certain that we want to improve it at some point, it had a low priority because it simply kept working. In order to make MongooseIM usable as a dependency, there was a separate src/ folder with a mongooseim.app.src file inside. It means that, while we had MongooseIM’s application file in src/, the rest of the code was in apps/ejabberd/. Again - not the prettiest solution, but it did its job.The latter improvement required us to temporarily disable MongooseIM’s application file, because Rebar 3 no longer accepted such a structure. With the release of 2.1.0, community feedback strengthened our resolve to keep going and complete the journey. The full transition to OTP-compliance had to be done sooner rather than later; 2.1.1 is what we aimed for. All of the code is in src/ now, and all dependencies are fetched from other repositories. And, what is important, MongooseIM can be used as a dependency in other Rebar projects again!For those who forked MongooseIM and modified it for their projects, we’ve prepared a comprehensive guide to what has been changed and how you should migrate your repository in order to sync with the current master.Event PusherAt some point a requirement arose for MongooseIM to be able to “publish” data to external endpoin" <> ..., title: "MongooseIM 2.1.1 - More than a patch!", url: "https://www.erlang-solutions.com/blog/mongooseim-2-1-1-more-than-a-patch.html"}
%{author: "by Areege Al Zubaidi", text: "Top 10 Erlang & Elixir events of 20182018-01-30\n        by Areege Al Zubaidi\n      This blog post was initially sent as an email exclusively to subscribers to our mailing list. Get exclusive content first, sign up now!\n\nCode BEAM SF - San Francisco, CAThe BEAM lands in San Francisco this March with Code BEAM SF. Remember Erlang & Elixir Factory? In 2018 we re-thought a few things and re-launched it as the Code BEAM SF. Learn more about the transition here. First two keynotes Kostis Sagonas and Richard Cook are already confirmed!\nWhat you need to know\n\nLocation: Marines’ Memorial Club & Hotel, San Francisco\nDates: Thursday 15 - Friday 16 March 2018\nTicketed event:Early bird tickets available\n\n target=“_blank”>Lonestar ElixirConf 2018 - Austin, TXElixir comes to Texas this February with Lonestar ElixirConf. Back for its second year, Lonestar features keynotes from Phoenix Framework alchemist Chris McCord, Nerves core team member Tim Mecklem, and Aaron Patterson, Ruby core team member.\n\nWhat you need to know\nLocation: Norris Conference Center, Austin, TX\nDates: Thursday 22 - Friday 23 February 2018\nTicketed event: Standard tickets available until 3 February\n\nEMPEX LA 2018 - Los Angeles, CAEMPEX is a sophisticated conference series for the Elixir programming language and ecosystem held in LA. This year, EMPEX will present a single track of technical talks, including keynotes from Emma Cunningham and Sarah Gray in a fun space in downtown LA.\n\nWhat you need to know\n\nLocation: 1827 South Hope Street, Los Angeles, CA 90015\nTime & Date: 09:00 PST, Saturday 10 February 2018\nTicketed event:  get tickets here\n\nLambda Days - Kraków, PolandLambda Days is a one of a kind experience in the functional programming world. Keynotes Mary Sheeran and Philip Wadler will be joined by Heather Miller and José Valim at Lambda Days this February over two days divided into six tracks.\n\n\nWhat you need to know\nLocation: Auditorium Maximum UJ, Kraków\nDates: Thursday 22 February - Friday 23 February 2018\nTicketed event:Regular tickets still available\n\nElixirDaze 2018 - Denver, COElixirDaze is a conference for building the Elixir community with top talks and helpful hacking. Hot off the press, this year’s keynotes will be Rob Conery and Fred Hebert\nWhat you need to know\n\nLocation: Ophelia’s Electric Soapbox, 1215 20th St, Denver\nDates: Thursday 1 - Friday 2 March 2018\nTicketed event: Only Standard tickets left!\n\nCode BEAM Lite - Milan, ItalyCode Sync meets Coders51 at Code BEAM Lite in Milan this April. Call for Talks is still open! This event will be bursting with great talk ideas around the themes of tools, BEAM, frameworks, distribution, concurrency and multi-core, curated by the stellar programme committee of Francesco Cesarini, Gabriele Santomaggio, Gianluca Randazzo, and Paolo Laurenti. Already confirmed are Mike Williams, Erlang co-inventor, and Georgina McFadyen, software consultant.\nWhat you need to know\n\nLocation: VENINI42, Via Giulio e Corrado Venini, Milan\nDate: Friday 6 April 2018\nTicketed event:Early bird tickets available\n\nElixirConf EU - Warsaw, PolandFollowing a hugely successful ElixirConf EU 2017 in Barcelona last year, ElixirConf EU is back on the continent this year, this time in Warsaw! One of the leading European conferences for Elixir, ElixirConf EU’s keynotes include José Valim, Chris McCord, and Evadne Wu. Training is also available.\nWhat you need to know\n\nLocation: Hilton Warsaw Hotel & Convention Centre, Warsaw\nDates: Monday 16 - Wednesday 18 April 2018\nTicketed conference:Early bird tickets still available\n\nEMPEX NYC 2018 - New York City, NYEmpire City Elixir Conference 2018, the NYC-based one-day conference for curious programmers is back this May! Brooklyn Zelenka has already been announced as a keynote speaker. Want to get involved? Call for Papers is still open!\nWhat you need to know\n\nLocation: Subculture, 45 Bleecker St, New York City\nDate: Saturday 19 May 2018\nTicketed conference: Keep your eyes peeled for ticket release\n\nCode BEAM STO - Stockholm, SwedenThis May marks the inaugural edition of Code BEAM STO conference (" <> ..., title: "Top 10 Erlang & Elixir events of 2018", url: "https://www.erlang-solutions.com/blog/top-10-erlang-elixir-events-of-2018.html"}
%{author: "by Ayanda Dube", text: "FIPS for Erlang & Elixir Systems2018-02-20\n        by Ayanda Dube\n      FIPS (Federal Information Processing Standards)[1] are a set of standards defined by the NIST (National Institute of Standards and Technology) to provide a means to govern and control how computer systems inter-operate in industry approved, credible and acceptable methods. FIPS-140 isn’t a necessity across the board, but if you’re operating in uncompromising sectors such as those found in governmental systems, I highly recommend you work to become FIPS-140 compliant. The FIPS-140 publication defines the standard requirements pertaining to cryptographic modules and functions employed in a computer systems, in all phases inclusive of, but not limited to, the design, implementation, installation, and usage.The requirement for Erlang based systems such as RabbitMQ, MongooseIM, Riak, WombatOAM to meet FIPS-140 compliancy are on a rapid surge, due to their dense usage in mission critical environments, such as those found in governmental sectors where the security requirements are uncompromising, and of uttermost importance. These Erlang systems are comprised of multiple applications that operate as part and parcel of a stack of other underlying applications and subsystems, such as the Erlang Virtual Machine and Operating System. Thus, in order to fulfill FIPS-140 compliance, considerations must cut across these underlying, enabling, layers as well, with an emphasis on the operation and interaction with the validated FIPS security module(s). The following is a graphic illustration and discussion of the components and aspects considered in an Erlang/Elixir system in order to conform to the FIPS-140 standard.Fig 1: Components and aspects to be considered for FIPS-140 compliance1. HardwareFIPS-140 defines platform security requirements, from the hardware to the operating system along with its security libraries. The requirements on hardware span from classifying the types of hardware security modules, such as single-chip and multi-chip embedded cryptographic modules, in which aspects such as the physical covering and coating for protection against tempering are defined, along with other internal aspects such as zeroization of sensitive “on-chip” information, and more. In the scope of Erlang, embedded systems being developed and shipped with, for example Erlang-ALE (and Elixir-ALE or Nerves, for embedded Elixir systems) would need to take such factors into consideration on both firmware implementation, and hardware fabrication.2. Operating Systems and VirtualisationThe requirements on operating systems govern the types (is it a trusted OS or not) and the manner in which the cryptographic software modules employed will function with regards to the provision of data protection as defined in FIPS-140 standard. These requirements are vast, and to the pleasure of developers and the community, libraries such as OpenSSL implement these feature sets, which, with good understanding, need be configured and enabled for FIPS-140 compliance upon execution. FIPS-140 recommends a modular approach to software design and implementation, and OpenSSL follows suit, realising FIPS-140 through a validated OpenSSL FIPS Object Module. Other libraries such as GnuTLS also incorporate FIPS-140 compliance as preferred by the user.Also within the scope of aspects to be considered, encompassing operating systems fulfilling FIPS-140, are the spawnable virtual machines and instances, which encapsulate and act as containers for efficient provisioning of various applications. These could be in the form of fully-fleshed operating systems such as those provisioned by automation tools such as Docker, Kubernetes, CoreOS to application runtime virtual machines such as the Erlang Virtual Machine, JVM, .NET, etc.Fig 2: Erlang3. ApplicationApplications executing on the aforementioned hardware and operating system platforms also need to be compliant with FIPS-140 regulations. At this layer of a computer system, for the Erlang and Elixir ecosystem, we find systems and applications such as RabbitMQ, Mongo" <> ..., title: "FIPS for Erlang & Elixir Systems", url: "https://www.erlang-solutions.com/blog/fips-for-erlang-elixir-systems.html"}
%{author: "by Bartłomiej Górny, Michał Piotrowski, Wioletta Dec", text: "Real-time Experience at FOSDEM 20182018-03-26\n        by Bartłomiej Górny, Michał Piotrowski, Wioletta Dec\n      This year we took our chance to engage with one of the largest open source software families - by attending FOSDEM. This is a Free Open Source European Developer’s Meeting taking place at the Université Libre de Bruxelles Solbosch campus in Brussels on 3-4 February. FOSDEM is among the world’s largest events focusing on free and open-source software development and its atmosphere is pretty unique. \nFig. 1: Elasticsearch [R]Evolution by Philipp Krenn, Fosdem 2018 FOSDEM 2018 was incredible as always - huge, noisy, crowded, crazy, brimming with energy, joy and never ending excitement. With nearly 14,000 attendees, 653 speakers and almost 700 talks supporting open source innovations, spread across 57 thematic sessions, the event was a hit. Most of the conference rooms were full to bursting, the exhibitors and networking areas were busy from early morning until evening and filled with enormous number of free open source projects and their communities. Github-sponsored free coffee, stalls featuring everything from hardcore Perl hackers to the VLC squad dressed as roadwork cones and LizardFS’ Polish-Irish team treating visitors to their stand with vodka shot!\nFig. 2: Exhibitors Area, FOSDEM 2018Alessio Fattorini described FOSDEM as “Woodstock for Geeks”. Taking the level of enthusiasm, creative energy combined with tech, innovation and knowledge, we’d say he was right!As always, organisers did a great job increasing networking and knowledge sharing opportunities through multiple accompanying social events. 2018 is the 20th anniversary of Open Source and it was celebrated at Fosdem.We were there too, representing our own open source based messaging platform MongooseIM, while hanging out in the Real-Time Lounge.REAL-TIME LOUNGEThe ‘Real-Time Lounge’ is where various open source, XMPP powered software solutions are presented by their communities, under the umbrella XSF (XMPP Standards Foundation) who are the main hosts of the ‘Real Time Lounge’. Squeezed between vending machines and a wheel of fortune was our cosy corner, where we brought together the best of open-source instant messaging and real-time communication. XSF, first and foremost, and XMPP-based software - Tigase, Prosody, MongooseIM, OpenFire and more. Fig. 3: Real Time Lounge, FOSDEM 2018In addition, our MongooseIM representatives, Michał Piotrowski and Bartłomiej Górny presented their work within the Real Time Communications Devroom. While Michał explored different ways of scaling an open source XMPP server - MongooseIM, Bartłomiej shared his vision of XMPP as the road to innovation.Michał Piotrowski, “Scaling messaging systems”“In my talk I described the most frequent scalability limitations when it comes to MongooseIM, showing that, thanks to the Erlang VM, scaling a single node MongooseIM installation or multiple nodes in the same datacenter is easy. The real fun begins when we need to spread the installation between continents. In this case there are two options. XMPP federation where users are bound to a specific datacenter. There is also the new MongooseIM feature called Geo Distribution - in this cases all MongooseIM clusters across the globe serve the same XMPP domain, so users can connect to any datacenter, usually the closest one.”Scalability depends on many variables for MongooseIM’s or indeed any other XMPP server. It’s hard to say that a particular option will work for every one, as every MongooseIM installation we have had the pleasure to build is unique. When planning how to scale MongooseIM we need to consider things like:Machine power (CPU and memory)Type of connected users. Using an XMPP server from a web browser or a desktop is different from a mobile device.  A mobile device will (re-)connect more often than a desktop client.Used and enabled XMPP features. Using only basic one-to-one messages without archiving will place much lighter demands on the server than for instance large group chats with many active users.When the service popul" <> ..., title: "Real-time Experience at FOSDEM 2018", url: "https://www.erlang-solutions.com/blog/real-time-experience-at-fosdem-2018.html"}
%{author: "by Oleg Tarasenko", text: "Running distributed Erlang & Elixir applications on Docker2018-03-28\n        by Oleg Tarasenko\n      The docker platform has been around for a couple of years already, so let’s briefly review which benefits it provides, and why you should consider using it:An easy means to boot your production services on the desktopI still remember how complex it was to bring up MySql on OS X in the past. But it would be even worse if you consider a scenario where your production environment is running some specific version of MySQL, especially built on non OS X.How would you bring that up? Luckily this problem just goes away when you’re using docker, as you can bring up any version of program as easily as executing the command  docker run mysql:5.3.The ability to work against a realistic  testing environment, without having to implement service mocksIt was always an issue. If you wanted to test your software properly, you had to bring up (or mock) a lot of related services. And it always created issues, as a mock never really matches the characteristics of a complete running service.And with docker you can just plug any software that your application relies upon, and have it right there as a part of your testing environment.Creating realistic cloud infrastructure, using containersFinally, docker containers can be spun up by tools like Apache Mesos forming full featured clouds, deployable in the effortless and clear manner, and incredibly stable!Interested? Lets see which benefits the technology can give you when it comes to the Erlang and Elixir worlds.Testing distributed erlang applications with dockerLet’s consider a case when we need to create and test a distributed erlang application, running on the same machine, and let’s say we want to have it running, but it relies upon some extra services.This kind of setup can be described in the following docker-compose file:\nversion: \"3\"\nservices:\n  c1:\n    image: erlang:latest\n    # We're using the following command to bring up erlang shell\n    # for the example purposes, but in the other case the command\n    # will describe a running container\n    command: erl -noshell -name app@host1.com -setcookie cookie\n    container_name: host1.com\n    networks:\n      - net1\n\n  c2:\n    image: erlang:17.5\n    command: erl -noshell -name app@host2.com -setcookie cookie\n    container_name: host2.com\n    networks:\n     - net1\n\n  ejabberd:\n    image: rroemhild/ejabberd\n    ports:\n      - 5222:5222\n      - 5269:5269\n      - 5280:5280\n    container_name: host3.com\n    environment:\n      - ERLANG_NODE=ejabberd@host3.com\n      - XMPP_DOMAIN=test.io\n      - ERLANG_COOKIE=cookie\n      - EJABBERD_ADMINS=admin@test.io\n      - EJABBERD_USERS=admin@test.io:admin\n      - EJABBERD_SKIP_MODULES_UPDATE=true\n    networks:\n     - net1\n\n# We're using custom network setup, as it ships with a DNS\n# system which allows containers to communicate by hostnames.\nnetworks:\n  net1:\n    driver: bridge\nNow let’s boot this setup and take a look at how we can facilitate communication between these containers:Bring up every container described in the file: docker-compose up -dConnect to one of the hosts: docker exec -it host2.com erl -name test@host2.com -setcookie cookie -remsh app@host2.comVerify that host connectivity is functioning correctly:(app@host2.com)1> net_adm:ping('app@host2.com').\npong\n(app@host2.com)2> net_adm:ping('app@host1.com').\npong\n(app@host2.com)4> net_adm:ping('ejabberd@host3.com').\npong\n(app@host2.com)5> nodes().\n['test@host2.com','app@host1.com','ejabberd@host3.com']\nIn this simple example we’ve brought up several containers and connected them using the standard erlang distribution. This is possible because all of the containers are running in the same docker network, and can access one anothers epmd daemons…But how can we connect docker containers running on different hosts?Connecting beams running on separate machinesFinally if you want to go to production, and to create a real cloud, running multiple hosting machines, the setup above will not work, as containers will not know how to connect to each other.Indeed" <> ..., title: "Running distributed Erlang & Elixir applications on Docker", url: "https://www.erlang-solutions.com/blog/running-distributed-erlang-elixir-applications-on-docker.html"}
%{author: "by Brujo Benavides", text: "Erlang Serpents2018-04-24\n        by Brujo Benavides \n      DisclaimerBrace yourselves… a long post is coming.It took me too long to write this blog post and the main reason is that it encompasses many many different topics. This will be a blog post about- Hackathons- TDD- Game development- Data Type abstraction in functional languages- Erlang\n\n   - bitstring syntax   - RESTful APIs   - multiple tools like cowboy, mixer, trails, swagger, lasse, etc.\nHistoryA long time ago, when I was a little kid, I started programming in QBasic and, as many of you might know, QBasic came with two little games in it. One of them was NibblesFast-forward 25 years… and you’ll find me at Erlang Solutions trying to come up with the subject for our next Hackathon with the help of Roberto Romero and Hernán Rivas Acosta.\nWe wanted a multiplayer game that could be watched on a single screen. Of course we came up with serpents!HackathonsEvery year at Erlang Solutions we all take one day off from our projects and we spend it all together celebrating what we love the most: programming. In 2014 we ran a “build your app in just one day” competition with awesome results. For 2015’s edition, we decided to come up with a multi-player game where the organisers set up the server and the teams developed the clients.\nThe code that I will be showing through the rest of this blog post, it all comes from the game server that Hernán, Roberto and myself developed.GoalsThe main goal of serpents was of course to be used for the Hackathon. But I had a hidden agenda for it as well: Since this project was going to be open-sourced on github, I wanted to use it as a case to show how we work. I wanted to be able to get people on IRC, erlang-questions, reddit, stackoverflow, etc. that asks questions like “hey! how do you build a web-server in Erlang?” and tell them “look here. This is how you do it!”.\nWith that in mind, we faced this project as if it was a client project and, turns out, our clients (our fellow devs) were in fact one of the toughest clients we have ever faced.ArchitectureSo, how did we build a multiplayer server for a serpent’s game?\nWe started by dividing it into 3 main components:- a web page that displayed the progress of the games.- a web server that served the webpage and provided a RESTful API for it to be updated in real-time.- a game server that provided the means for clients to connect to it.\nFor the web page we used plain HTML and some Javascript (you can tell how that is not really interesting to me at least :P). What is interesting is the real-time part. We implemented that one (as we usually do) over SSE. During a game, the website looked like this:From the server perspective, we implemented the RESTful API using cowboy on trails and we documented it with swagger. It ended up looking like this:On the other side, we decided to give client devs 2 options. They could just use the same RESTful API and SSE connection to communicate with the server, or they could use our HDP protocol.HDP is a blazingly fast protocol that runs on UDP. It was developed by Hernán and documented in kafka style for all to use. It’s specialised for serpents, but it can be replicated in other projects with ease.Internal ArchitectureInternally, as you can see on github, the code is divided in multiple folders and multiple modules that we could test individually.One one side, we had the basic building blocks of the game: the rules (in spts_core) implemented as a gen_fsm per game and its entities (represented as Data Types or Models, each one with its own module and opaque type). You can see our approach in spts_serpents:%%% @doc Serpent model-module(spts_serpents).-author('elbrujohalcon@inaka.net').-typestatus()::alive|dead.-typename()::binary().-opaqueserpent()::\#{name=>name(),numeric_id=>pos_integer(),token=>binary(),body=>[spts_games:position()],direction=>spts_games:direction(),food=>pos_integer(),status=>status()}.-export_type([serpent/0,status/0,name/0]).-export([new/6]).-export([name/1,numeric_id/1,direction/1,direction/2,to_json/1,to_json/2,to_binary/2% ...]).-specnam" <> ..., title: "Erlang Serpents", url: "https://www.erlang-solutions.com/blog/erlang-serpents.html"}
%{author: "by Szymon Mentel & Joseph Yiasemides", text: "ElixirConf EU 2018 Highlights2018-04-25\n        by Szymon Mentel & Joseph Yiasemides\n      ElixirConf EU 2018 was a great place for our colleagues, clients, and the community to forge new relationships and strengthen existing ones. The other aspect of conferences we appreciate is how talks prompt questions, their answers, and subsequent discussions. Here are our highlights for this years ElixirConf EU.Robust data processing pipeline with Elixir and FlowLászló Bácsi talked about processing pipelines in general but also about mental model behind them. The talk contains an Elixir Flow crash course as well as some examples of using the library. It covers topics like composing, branching, supervising Flows. You would also find error handling strategies there.Going low level with TCP sockets and :gen_tcpOrestis Markou presented a nice overview of the :gen_tcp API and compared it to the BSD one. From the talk you can learn how to write simple TCP server and client in Elixir as well as some caveats you can come across.SOLID ElixirGeorgina McFadyen spoke about design principles. This is a great talk. She began with a case study which she used throughout the talk easing the audience into the SOLID principles which are commonly attributed to the OOP paradigm. The surprising twist is that she transformed them into a set of principles more in-line with functional programming (SORTID). The content was excellent, the slide deck was great, and her delivery was fantastic.State and the distributed data structuresArkadiusz Gil gave an excellent introduction to Conflict-Free Replicated Data Types (CRDTs). They were presented in contrast to Mnesia which was designed to provide strong consistency guarantees. In this journey you will learn the basics principles behind State-Based CRDTs and how they can be expressed in Elixir code.Knee deep into P2PFernando Mendes presented a battle-story from implementing a distributed spanning across a bunch of RaspberryPis and few sensors. This was nicely concluded by a Distributed Systems Checklist.Rewriting a legacy application in Elixir: the good, the bad and the uglyRaphael Costa shared a story of migrating their product to Elixir and how the new technology stack made them more efficient. The system his team develops helps people sort out taxes in Brazil which is interesting use case to apply Elixir to. His practical advice on how to migrate, and what to migrate when, is valuable for those of us moving bigger code-bases to Elixir.Property-based testing is a mindsetAndrea Leopardi gave an introductory talk to property-based testing presenting the basics of the concepts along with the examples. He contrasted the PBT approach to unit test (“testing by example”) as well as covered the performance aspects of it. Andrea also listed a few ways to conceive of properties.Closing KeynoteThe closing keynote by Chris McCord was an overview of what’s new in Phoenix 1.4. To mention a few additions we can expect: support for HTTP/2, faster development compilation and explicit Router helper aliases. The second part of the presentation was devoted to data persistence: when to use the database and what alternatives we have.See more Erlang and Elixir events here. Go back to the blog\n\nTags:ElixirConf EUElixirPhoenixElixir FlowTCP socketsSOLID ElixirConferencesShare  Facebook Twitter Linkedin E-mail", title: "ElixirConf EU 2018 Highlights", url: "https://www.erlang-solutions.com/blog/elixirconf-eu-2018-highlights.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 2.2 - The Global Server2018-04-25\n        by Piotr Nosek\n      While every MongooseIM release comes with important improvements, sometimes they are more relevant for certain groups of users. In MongooseIM 2.2 we present 3 major features: SASL EXTERNAL authentication mechanism, stable Global Distribution, and Jingle/SIP proxy.All of them are especially beneficial to larger deployments or big companies.They often already provide certificate-based authentication to their users, so with SASL EXTERNAL it is no longer required to introduce new passwords or tokens to your existing system.Also, when they hit a certain cluster scaling limit, they need to distribute a service to several data centers. In order to retain user experience, Global Distribution comes into play.The third element, Jingle/SIP proxy, will be appreciated by VoIP app owners who would like to incorporate MongooseIM and integrate it with existing clients and components.If you’d like to learn more, please keep reading.One more thing: I think we owe a word of explanation for the community members who were tracking our repository and our responses to issues on GitHub. We were on track to release MongooseIM 3.0, but it turned out that certain important Pull Requests required further work. We didn’t want to keep you waiting, so the new version is here anyway. Only with different version number increase.Welcome to MongooseIM 2.2!Authentication with certificatesTypical XMPP authentication involves a password or a token that is sent to the server. There are several SASL (Simple Authentication and Security Layer) mechanisms with SCRAM-SHA-1 being the recommended one.In 2006, a set of recommendations was published as XEP-0178. They describe best practices for SASL EXTERNAL mechanism usage. It is actually a pretty mature extension, but it gained extra attention recently when more and more companies wished to use certificate-based authentication.SASL EXTERNAL implementation in MongooseIM 2.2 follows the aforementioned XEP and tightly integrates with TLS encryption used for connection. It means that client certificate used for securing the stream may be reused to log the client in. It is not only a very secure method, but also avoids introducing concepts of passwords and tokens in systems where they are not actually needed.Stable Global DistributionAll of you know what mobile network and landline are. The former allows you to call everyone in the world, as long as they carry their device with them, always with the same number. The latter requires the recipient to be present at a specific location in order to receive a call. What is more, you actually have to know where they are, as landline phone numbers (at least usually) include prefixes assigned to certain districts or cities.I’ve included a reminder of all these attributes to explain a difference between Global Distribution and classic XMPP Federation. The former is an XMPP cellular network and the latter is an XMPP landline. GD is a custom extension developed by the MongooseIM team, exclusive to our server. With GD enabled, your clients no longer need to be aware of the recipient’s exact location. They may be connected to any cluster.As you may guess, message routing in this case is more expensive than the old model. Actually, it requires a distributed routing table. The current solution may be used with a Netflix Dynomite layer on top of Redis.The teams behind smaller apps may rest assured - when your solution grows, it will be possible to enable Global Distribution later, for existing cluster(s). You don’t need to worry about the Dynomite and Redis overhead already. :)Global Distribution module was already present and mentioned in the 2.1.1 release. It was considered highly experimental back then but we’ve received many reports about bugs and possible improvements. We’ve resolved all of them, so in MongooseIM 2.2 we consider it stable. It is still not fully compatible with some extensions, as e.g. users migrating between clusters could lead to fragmented message archive. Nevertheless, it’s core purpose - r" <> ..., title: "MongooseIM 2.2 - The Global Server", url: "https://www.erlang-solutions.com/blog/mongooseim-2-2-the-global-server.html"}
%{author: "by Konrad Zemek", text: "Escalus 4.0.0: faster and more extensive XMPP testing2018-05-22\n        by Konrad Zemek\n      Escalus 4.0.0 is the newest version of our XMPP client library for Erlang, a component of our MongooseIM platform of tools and services.\nCreated as a tool for convenient testing of XMPP servers, it can also be used as a standalone Erlang application.\nIn contrast to other XMPP clients, Escalus provides a rich testing API (assertions, stanza building…) and a high degree of flexibility that allows to completely redefine its behaviour.It is used by Erlang Solutions for integration, load and stress testing of MongooseIM XMPP server.\n\nThe newest version, Escalus 4.0.0, now supports Erlang 20 and offers the following features and improvements:New, RapidXML-based XML parserEscalus 4.0.0 includes a new version of our exml Erlang XML parser!\nThe parser’s processing layer was rewritten from scratch, extensively profiled and optimised; as a result, the new parser is on average 5 times faster than before when encoding and decoding XML elements.Included XML viewerFiles containing traced XMPP stanzas now include a powerful XML viewer by Sergey Chikuyonok.\nThe viewer shows elements in a readable manner and supports collapsing, searching by name, XPath support, and more.\nInspecting your XMPP traffic has never been easier!Message pipeliningThe new XML parser also supports message pipelining, which means that multiple stanzas can be safely sent and received at once by the client.\nThis can greatly improve efficiency of many use cases and in the future will be used to speed up Escalus’ XMPP connection times by an order of magnitude.Transport-level metadata for stanzasThe transport process used to receive and deliver XMPP stanzas can now pass on metadata that will be included with elements delivered to the Escalus’ client.\nCurrently the metadata set by existing transport implementations is limited to a receive timestamp, but can be easily overridden and extended by a custom solution.Other improvementsTCP connections are now set up with a nodelay option which decreases communication latency between Escalus and XMPP server.\nIf you don’t like the change, Escalus 4.0.0 also supports easy overriding of TCP options that allows you to disable it, and more - including the nitty-gritty settings of buffer sizes or ToS flag.A host of refactoring changes, subtle API improvements, bug fixes, performance enhancements, and an increased number of useful functions to inspect and construct your stanzas all lead to a smoother experience while testing all of your most important features.Test our work on Escalus 4.0.0 and share your feedbackCheck out our full release notes for Escalus 4.0.0 & 3.1.0 on GitHub. Play around and let us know what you think!Help us improve the MongooseIM platform:Star our repo: esl/escalusReport issues: esl/MongooseIM/issuesShare your thoughts via Twitter: twitter.com/MongooseIMDownload Docker image with new releaseSign up to our dedicated mailing list to stay up to date about MongooseIM, messaging innovations and industry news.Check out our MongooseIM product page for more information on the MongooseIM platform.We thought you might also be interested in:Our RabbitMQ solutionsRabbitMQ monitoring with wombatOAMMongooseIM - XMPP ProtocolGo back to the blog\n\nTags:MongooseIMEscalusEscalus 4.0.0XML parserXML viewerconcurrencyErlangAPI improvementsErlang 20TCP connectionsMessage pipeliningShare  Facebook Twitter Linkedin E-mail", title: "Escalus 4.0.0: faster and more extensive XMPP testing", url: "https://www.erlang-solutions.com/blog/escalus-4-0-0-faster-and-more-extensive-xmpp-testing.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 3.0.0 - Application turbocharger2018-06-05\n        by Piotr Nosek\n      MongooseIM 3.0.0 is out and with it come many improvements to our global messaging solution!\nOver the years we have proven that MongooseIM is the way to go when building a scalable, secure messaging system that never fails. With new features and fixes, our battle tested, highly customisable platform provides an enterprise friendly toolbox everyone can use. Whether you’re an XMPP expert or an entrepreneur looking to bring to life your idea for a community building app, MongooseIM platform helps you build a product tailored to your needs, that will easily grow to match your ambition.\nFind out what goodies we’ve managed to pack up for you this time and see how we can aid your users’ experience with our truly instant messaging platform.What is so great about 3.0.0?!As a team we’ve switched into a faster gear and our latest release is a reflection of that.\nMongooseIM 3.0.0 is an enterprise ready, stable solution that now works faster then ever; delivering a smooth messaging experience to your users. It features important upgrades that will allow your servers to process even more messages per minute and save memory space for additional user sessions. Everything thanks to a couple of improvements, the new XML parser being the prominent highlight.Efficiency is not the only reason why we’re so proud of this release. It also features prototype Inbox implementation. It’s an essential extension for virtually every chat application. Our rich experience in this topic allowed us to design a solution that should match most use cases already and will be expended even further!As usual, there are also other improvements we’d like to share with you. You may find the full list in our changelog but we’ve picked five of them to describe, as we feel you should learn more about them.Achieve more with the same hardwareThanks to several important changes and improvements, MongooseIM is now able to process information faster and consume less resources. It means your servers may handle more users and traffic with the MongooseIM upgrade alone.Depending on your specific application, 25-400% better performance may be expected. Actually, the richer and more complex trafic, the better results you’ll get, compared to previous MongooseIM versions!Three aspects of MongooseIM have been modified in order to achieve this:All messages from users are interpreted in a completely new wayMore users can connect to a single server per secondAll user sessions store as little information as possible when they are idleHello inboxWe’ve implemented Inbox features in the past for various projects and the time has come to pour the best ideas and experiences into an extension open for everyone!A few words of explanation for those not familiar with the Inbox feature. It is the view in a chat application that you see every time you open it. It is a list of all conversations, with excerpts of last messages and unread messages count. Simple as that!Unfortunately, as there is no official Inbox specification in XMPP yet, we’ve come up with custom protocol (thank you XMPP for your extensiveness!) for this purpose. We’re going to submit it as a XEP (XMPP Extension Protocol) for a review by community but in the meantime you can enjoy its simplicity and intuitiveness. All you need to do is to enable mod_inbox and implement a few simple IQ stanzas in your client application.Please keep in mind though, this extension is still in experimental stage and will be marked as stable in one of our future releases.Under the hoodWe’ve also added some lower level changes that are going to be useful to developers, CTOs and devops.Performance bundle: Acceptor pool, session hibernation, new XML parserWe’ve been using expat parser since the very beginning. Recently, our brave C++ warrior in the MongooseIM team thought of replacing it with an alternative - RapidXML. Everything indicated that it might consume less resources if properly used.And he did use it in an excellent way. The whole C code was rewritten into C++ wit" <> ..., title: "MongooseIM 3.0.0 - Application turbocharger", url: "https://www.erlang-solutions.com/blog/mongooseim-3-0-0-application-turbocharger.html"}
%{author: "by Magnus Henoch", text: "Erlang trace files in Wireshark2018-06-07\n        by Magnus Henoch\n      If you’ve tried to debug a running Erlang system, you probably tried tracing.  The Erlang VM lets you trace many different things, most notably messages and function calls, but also processes getting spawned and killed, and garbage collections.Perhaps the most common way to use tracing is calling the dbg module from an Erlang shell, tracing calls for a few functions:%% Start a tracer process\ndbg:tracer().\n%% Trace function calls for all processes\ndbg:p(all, [call, timestamp]).\n%% Add a function to trace calls for\ndbg:tp(my_module, my_function, cx).\nThat prints any function calls for that specific function in the shell.But what if you have a lot of trace events?  Digging through shell output isn’t the most pleasant way to find a needle in the haystack.The dbg module includes support for writing trace events to files and reading them back.  To write trace events to a file, use the following command:dbg:tracer(port, dbg:trace_port(file, \"foo.trace\")).\nThen you can read back the data with dbg:trace_client.But since the trace file is just a data file, with a fairly simple format, we could just use a tool that specialises in inspecting files full of timestamped events: Wireshark!Wireshark? Really?Yes!  Wireshark is mostly known for reading files in the PCAP and pcapng formats, but you can add support for other file formats through Lua plugins.It so happens that I have a plugin that does just that, called cautious-rotary-phone. (Github’s repository name generator sometimes helps imagination-deficient programmers.)It consists of two modules, erlang-trace.lua and erlterm.lua.erlang-trace.lua reads the files in the Erlang trace file format. It’s a simple format, with each entry consisting of three elements:one byte, always 0, meaning the start of a binary entrya 32-bit big-endian integer, denoting the size in bytes of the entrythe entry itself, in Erlang external term format\nThe module registers itself as a file handler, and when called, reads the file, chops it up into entries, and extracts the timestamp for each entry.  That gives Wireshark enough data to display all the trace entries in its packet list.Then erlterm.lua gets invoked.  It is a protocol dissector, similar to ones you might write for any network protocol, except it dissects Erlang terms instead of network packets.  It identifies different types of terms, makes the data available to Wireshark for display and filtering, and dives into recursive data types such as tuples and lists.So what does it look like?Let’s try this out on MongooseIM, the instant messaging server!  I installed it on my machine, and set out to find something interesting to trace.  It so happens that client-to-server (“c2s”) connections are handled by child processes of a supervisor called ejabberd_c2s_sup.  We can trace all messages sent and received by any newly spawned child processes using the set_on_spawn trace flag:dbg:tracer(port, dbg:trace_port(file, \"mim.trace\")).\ndbg:p(ejabberd_c2s_sup, [timestamp, send, 'receive', set_on_spawn]).\nThen I started two XMPP clients, registered two accounts, sent messages between them, and then opened the trace file in Wireshark.I sent a message with the text hello, so I can find the trace events containing that text with this Wireshark filter:frame contains \"hello\"\nThat shows me this event:Erlang binary term format: {trace_ts, <mongooseim@localhost.869.0>, receive, 2 more elements}\n    Version number: 131\n    Term type: Small tuple (104)\n    Arity: 5\n    Tuple element: trace_ts\n    Tuple element: <mongooseim@localhost.869.0>\n    Tuple element: receive\n    Tuple element: {$gen_event, {xmlstreamelement, {xmlel, <<\"message\">>, [ 4 elements ], [ 2 elements ]}}}\n    Tuple element: {1526, 395003, 982214}\nSo the process 869.0 on the node called mongooseim@localhost has received an XML element called message.  The XML element itself exceeds the display threshold, but I can open up the tree element and see more details:Tuple element: {xmlel, <<\"message\">>, [ 4 elements ], [ 2 elements ]}\n    Ter" <> ..., title: "Erlang trace files in Wireshark", url: "https://www.erlang-solutions.com/blog/erlang-trace-files-in-wireshark.html"}
%{author: "by Oleg Tarasenko", text: "Railway oriented development with Erlang2018-06-13\n        by Oleg Tarasenko\n      This blog suggests an alternative means by which you can structure your programs, inspired by the Elixir pipe macro ‘|>’ but without making use of the dreaded parse transforms using my tiny epipe library, which I have recently written. Epipe itself is inspired  by this article published by Scott Wlaschin.Getting startedLet’s perform a small practical task which will demonstrate this railway approach to functional programming. Consider the case where we’re building a POP3 email client using Erlang. Our goal is to implement a control flow for establishing connections with a POP server. This diagram illustrates the steps needed to accomplish this action:\nFirst, let’s build a function implementing the connection functionality:connect(Addr, Port, ConnOptions, User, Password) ->\n    {ok, Socket} = ssl:connect(Addr, Port, ConnOptions),\n    ok = receive_greetings(Socket),\n    ok = send_user(Socket, User),\n    ok = send_password(Socket, Password).\nThe code above is very beautiful, only four lines of code and we’re done! But wait… the implementation above is very much a best case scenario. Obviously we need to add some error handling in order to to deal with edge cases :(. I mean, “what could possibly go wrong”?Adding error handlingLet’s summarise all possible edge cases on the diagram below:\nLet’s add the error handling code, and see how it looks now! Spoiler: The example below is trivial and can be beautified by splitting the operations into separate functions but the nested case statements are unavoidable.connect(Addr, Port, ConnOptions, User, Password) ->\n    case ssl:connect(Addr, Port, ConnOptions) of\n        {ok, Socket} ->\n            case receive_greetings(Socket) of\n                ok ->\n                    case send_user(Socket, User) of\n                        ok ->\n                            case send_password(Socket, Password) of\n                                ok -> ok;\n                                _Err -> error_logger:error_msg(\"Auth error\")\n                            end;\n                        _Err ->\n                            error_logger:error_msg(\"Unknown user\")\n                    end;\n                Err -> error_logger:error_msg(\"Could not receive_greetings\")\n            end;\n        _Error -> error_logger:error_msg(\"Could not connect\")\n    end.\nWow. Now we have added all of the error code. And wow, the size of the code has increased by 400%… with a commensurate decrease in readability. Ouch!Perhaps there is a cleaner way to implement this?Designing for better errors handling with “the railway” approach (theory)The idea behind the railway approach is to decompose “step” functional blocks, using railway switches as an analogue:\n* Image source: Scott Wlaschin\nWhich could be translated into the following Erlang code:switch_component(Input) ->\n    case some_action() of\n        {ok, Response} -> {ok, Response}; % Green track\n        Error          -> {error, Error}  % Red track\n    end.\nOnce you have created two way (ok/error) switches for all required operations, you can combine them as elegant as it’s done on the railroad:\n* Image source: Scott Wlaschin\nSo, to recap, what exactly happens is:In the case of the success scenario, all functions (“railway switches”) are executed sequentially, and we travel along the “Success track”. Otherwise, our train switches to the “Error track” and travels along that route that way, bypassing all other steps:\n* Image source: Scott Wlaschin\nDesigning for better error handling with “the railway” approachWe have released a tiny erlang library, which simplifies railway decomposition for Erlang. So, given the above example, let’s take a look at how to implement our use case using Epipe:-record(connection, {\n    socket,\n    user,           \n    addr,\n    port,\n    passwd\n}).\n\nconnect(Addr, Port, User, Password) ->\n    Connection = #connection{\n        user = User,\n        passwd = Password,\n        add = Addr,\n        port = Port\n    },\n    % Defining list of railway switches to follow\n    Con" <> ..., title: "Railway oriented development with Erlang", url: "https://www.erlang-solutions.com/blog/railway-oriented-development-with-erlang.html"}
%{author: "by Erlang Solutions", text: "Scaling reliably during the World’s biggest sports events2018-06-21\n        by Erlang Solutions\n      Erlang Solutions works with some of the world’s leading online gambling & betting operators. See what we do.“A busy day for an online betting shop is like Black Friday at Amazon, only prices change every second,” Martin Davies, Head of Technology at bet365 told us a year ago. During big sporting events, like football tournaments, that can go on for weeks with global interest and audience numbers, Amazon’s Black Friday pales in comparison. Operators need to scale and innovate while serving massive numbers of punters on a daily and hourly basis. Here’s our tips on how to do that:The innovation-scale dilemma:the biggest challenge facing online bookmakersBookmakers must not only meet the demands of high frequency requests and traffic bursts, but also keep the tech-savvy, multi-channel customers engaged. This is where they come across their biggest challenge; the “innovation-scale dilemma.”To meet user demand, the industry continuously creates and improves on new types of games and bets. This is when tech departments hit upon the dilemma. Over a certain number of users, the ability to innovate quickly is lost. Precious time is spent rewriting software so that it runs to scale, slowing release time.To break this vicious cycle, the most innovative industry players – such as bet365 and William Hill – have chosen Erlang (or Elixir, a language based on the same underpinnings as Erlang) as their core technology. Erlang Solutions also supports global payment companies, like Klarna, messaging companies like ooVoo, and IoT companies such as Intel – all of whom face similar technical challenges to online bookmakers.Read more on SBC NewsInnovation at scale“Innovate or die” is a reality of life for most consumer facing industries these days. As the pace of progress in the computing industry shows no signs of slowing down, disruption by innovative startups is an existential threat to established players in any market.Online businesses are especially ripe for disruption as the tools and technologies required to start an online business are pretty much available for free with no strings attached. The online gambling and betting industry is no different. Given the recent surge in popularity of online gambling, especially during the World Cup, established players have to innovate just to stay where they are in the marketplace.Every step of the way, user experience comes first. There is a relentless demand for it to be easier and smoother, regardless of backend challenges. This has left the gambling industry in search of the most efficient and effective ways of directing users to their objective, whether it’s registering, playing a game, placing a bet, cashing out that bet or making a deposit. Systems must be ultra-responsive and able to engage with customers when, where, and how they want.Those who get this ‘right’ in comparison to their competitors enjoy higher customer engagement and retention, and hence profits. And for each operator, this journey to support customer-centricity through the tech stack is slightly different.Some established operators have legacy systems that are hard to scale or modernise whilst maintaining uptime and quality of customer experience. Those operators would be wise to take a step back, review their technology choices and evaluate which of the bewildering range of tech, old and new, can best be deployed in helping them achieve these customer-centric goals. It can help to spend some time imagining what an ideal sportsbook architecture would look like, without the burden of legacy, and then mapping out an evolutionary roadmap to get there.Read more on SBC NewsConcurrency, scalability, and reliabilityAt any one time bet365’s systems are serving many hundreds of thousands of users live odds and results, while managing multiple data streams on the backend. In peak times, like the Super Bowl or the Grand National, the number of users swells by an order of magnitude. This is an awesome feat of concurrent engineering.Wh" <> ..., title: "Scaling reliably during the World’s biggest sports events", url: "https://www.erlang-solutions.com/blog/scaling-reliably-during-the-world-s-biggest-sports-events.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 3.1 - Inbox got better, testing got easier2018-07-25\n        by Piotr Nosek\n      This summer the MongooseIM team have not had a second to be lazy - the development of MongooseIM 3.1 release took over what was supposed to be our downtime, when all major activities driven throughout the year slow down. We’re happy to say that in this time of leisure, the new release is packed with important features, improvements and excitement. Take a look at the version highlights and be part of this major step in creating a world-class communication server. This time, a large part of the changes are focused on development efficiency, but rest assured, we’ve added new items you are going to appreciate.In the “Test Runner” section, you get to learn all about a little tool we provided so that you can easily set the development environment up and run tests locally without Travis CI.Our Inbox extension has got three big updates that push the boundaries of what’s currently offered in XMPP world. As a rule, we want to lead by example; less talk and more action. That is why working in cooperation with Forward, we decided to put forward an implementation of a popular use case as a unique feature in this software sector.This release is also an important lesson for us. A lesson about edge cases and concurrency in integration testing. You don’t necessarily have to be an Erlang developer to benefit from the third section, but reading it allows you to learn with us.The “Honorable Mentions” section may seem minor, but for some projects the items listed there can indeed make a difference! It’s a candy mix of different changes, so read carefully not to miss your favourite flavours!Obviously, a single blog post is too small a space to tell a profound story about every new item in the changelog, so we encourage you to check it out. You can find a link at the bottom of this blog post. Test RunnerThe Travis CI is our main verification tool for the Pull Requests we create and merge. Whilst being convenient and critical for our process, it is not very handy for day-to-day development. It is very common to frequently execute limited subset of tests to ensure that a new piece of code we wrote works perfectly. However, waiting for Travis results every time would extend implementation time excessively as it executes multiple presets, while being a shared resource at the same time.The test runner is a script that helps to set the development environment up, and run tests on a developer machine locally. The test runner shares a lot of code with our Travis CI build scripts, which ensures that test results are consistent between local and CI runs.The test runner allows to choose which tests to run. It can be useful, when one of the tests is failing and we want to rerun it.Since MongooseIM supports different database backends, the test runner is able to set a selected database up for you and configure MongooseIM. Simply put, it prepares the local environment before executing actual test suites.The test runner supports a lot of options to customise your build and test execution scenario. It also supports shell autocompletion for option names and values.We’ve prepared a recording for you that presents a basic usage of the script.. Please note that Asciinema allows you to pause and copy any text fragment you like, so it would be very easy for you to repeat the same steps.New Inbox FeaturesOriginally sponsored by and created for Forward, Inbox has been available as an open source extension for the last two months already. In MongooseIM 3.1, it returns with a bundle of fresh goodies. The first feature is MSSQL support. Despite being less frequently used with MongooseIM compared to MySQL or PostgreSQL, it’s still an important piece of the architecture for many projects, especially those running in Azure cloud. We don’t want you to feel excluded, dear Microsoft users!The second one is the support for classic MUC group chats. MUC Light was never intended as a complete replacement for original XEP-0045 solution. It means that numerous projects exists where mod_muc " <> ..., title: "MongooseIM 3.1 - Inbox got better, testing got easier", url: "https://www.erlang-solutions.com/blog/mongooseim-3-1-inbox-got-better-testing-got-easier.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interviews with co Creators Robert Virding Joe Armstrong2018-08-28\n        by Erlang Solutions\n      Erlang has been open sourced since 1998 and this year marks the 20th anniversary. We’ve been celebrating with parties, conferences, webinars, meetups and other delicious content so far. To celebrate this milestone we kicked off with launching a new family of tech conferences called Code Sync - do you remember Erlang Factory San Francisco and Erlang User Conference in Stockholm? As from 2018, Code Sync consolidates all the conferences that we’ve been organising since 2008 retaining their individual personalities and focuses. So if you are on a look out for Erlang Factory or EUC - check Code BEAM conferences aimed at ‘Discovering the Future of the Erlang Ecosystem’.Shortly after we kicked off with a party in March held in San Francisco in partnership with TigerConnect, and then we continued with our Stockholm party in May where we’ve partnered with WhatsApp, Ericsson and aeternity. Taking the Erlang Party around the world!These two epic #OpenErlang parties invited local communities for an evening of 1998 flashback. It was great seeing old friends, and welcoming a large number of new faces too. So yes, the Erlang and Elixir community continues to grow, getting more followers and vibrancy year by year… Next party will be held in London on 8th November and we will share more info in the upcoming weeks. We also partnered with a great number of Erlang and Elixir enthusiasts on a series of #OpenErlang webinars that we are rolling out throughout this year. The next one is coming up in September with Ben Marx from Bleacher Report. And next up is our exclusive #OpenErlang Interview Series with some of the biggest names within the Erlang, Elixir and Open Source community. We’ve been all working hard behind the scenes and we are finally ready to share some great personalities, stories and uses of Erlang that even Robert, Joe and Mike never dreamed of when creating the language!So what better individuals to kick of the interview series with than the co-creators of Erlang? Two-thirds of the Erlang Creator Dream Team Robert Virding and Joe Armstrong talk their favourite topic…Erlang!From how Erlang developed into a programming heavyweight to the benefits of the language becoming open sourced, Robert and Joe share their highlights over the past 20 years including the community it has created and how important it is to a number of huge global companies. \nWe have the transcript listed at the bottom of this blog post.#OpenErlang; 20 Years of Open-Sourced ErlangErlang was originally built for Ericsson and Ericsson only, as a proprietary language, to improve telephony applications. It can also be referred to as “Erlang/OTP” and was designed to be a fault-tolerant, distributed, real-time system that offered pattern matching and functional programming in one handy package. Robert, Joe and Mike were using this programming language at Ericsson for approximately 12 years before it went open sourced to the public in 1998. Since then, it has been responsible for a huge number of business big and small, offering massively reliable systems and ease of use. About RobertRobert Virding is one-third of why Erlang exists; along with Joe Armstrong and Mike Williams, Robert developed Erlang in 1986 and continued to use it solely at Ericsson before the language was released as open sourced in 1998.Robert originally worked extensively on improving garbage collection and functional languages but has since developed his entrepreneurial spirit having began the first Erlang startup - Bluetail.The co-creator was an early member of the Ericsson Computer Science Lab and currently works as the Principal Language Expert at Erlang Solutions, as well as a keen speaker and educator. About JoeRobert’s partner in crime over the last 3-4 decades is Joe Armstrong. He too has an eye for business, having debugged programs in exchange for beer whilst studying at University College London. Along with Robert Virding and Mike WIlliam, he de" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interviews with co Creators Robert Virding Joe Armstrong", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interviews-with-co-creators-robert-virding-joe-armstrong.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Ericsson's Christopher Price2018-09-05\n        by Erlang Solutions\n      What happened in 1998? There was the introduction of a brand new currency in Europe, Google was founded and the iconic Britney Spears came crashing into our worlds. Of course we’re forgetting one vital development.The significance of Britney is undoubtedly important, however more so was the decision to make Erlang open source, making this year its 20th anniversary. To celebrate, we have been hosting parties, conferences, webinars and meetups including the #OpenErlang interviews.The #OpenErlang InterviewsWe have been interviewing a few contributors, makers and shakers from the Erlang community as part of our #OpenErlang celebrations! From those who have had a key involvement in the process of creating the language to the individuals contributing to its further development and ultimately the companies adopting Erlang. Keep your eyes peeled each week as our key influencers of Erlang give exclusive interviews regarding the programming language and its development over the last few decades. Next up is our exclusive #OpenErlang Interview with Christopher Price, President at Ericsson Software Technology.Christopher has been championing a shift in the technology industry from standardization to open source software development for many years and across many companies. Here, he talks about the legacy of Erlang, and what Ericsson plans to do to develop and promote open source technologies around their exciting 5G transformation.We have the transcript listed at the bottom of this blog post.About ChristopherChristopher has always had a passion for open source technologies throughout his career, collaboration ideas and community building in the technology and ICT sector. Initially beginning his journey as a developer for global and carrier networks, over the past few years, Chris has really focused his efforts on the open source community and advancements in technology. Christopher Price is now the President at Ericsson Software Technology based in Stockholm, Sweden. He is responsible for developing and promoting software across open source communities. As well as actively participating within the open source community, Chris is an active member of the Linux Foundation, the OpenStack Foundation and the OpenDaylight Project. At Ericsson, Chris previously was the head of the network architecture and standardization team for the IP and Broadband division. His other key skill sets include technology development and architecture, policy control, user session control plane solutions and DPI technologies. The Legacy of EricssonA huge number of mobile traffic is carried through Ericsson. Can you take a guess? That is 40% of all mobile traffic (thank you Erlang OTP team out there!)Not only is Ericsson a dominant force in the mobile industry, but communications in general, having been founded around 140 years ago with that very goal. The aim of Ericsson was to make communicating easier, and that has certainly been the case for well over a century. Founded by Lars Magnus Ericsson, Ericsson successfully broke into the 21st-century technology where many other businesses failed to adapt, and it did so with ease. Now, in 2018, Ericsson offers an abundance of services all aimed around this initial goal of “communication as a human need”. This spans into digital services, managed services and many innovations. What is Ericsson doing nowadays?Real-time connectivity is Ericsson’s key focus. As technology excels and we - the consumers - become more demanding, Ericsson has wholeheartedly accepted the challenge of offering A+ communication at lightning speed. This is seen through 5G standardization, in which this process is highly complex and extraordinarily innovative. The stages of 5G standardization include radio access, 5G core, security and sustainability. The race to release 5G is underway. This means data speeds and capacities will be increasing, and countries must provide the correct bandwidths under the correct condit" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Ericsson's Christopher Price", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-ericsson-s-christopher-price.html"}
%{author: "by Oleg Tarasenko", text: "Receiving messages in Elixir or a few things you need to know in order to avoid performance issues2018-09-06\n        by Oleg Tarasenko\n      We’re kicking off #ElixirOverload with Oleg Tarasenko’s post on receiving messages in Elixir! What can you do to avoid common mistakes that plague developers? Here, Oleg makes a performance comparison of message processing depending on the process mailbox size, amongst other fantastic insights. This is just the beginning. We are dedicating one week to the brilliant Elixir community with themed content all about Elixir. We have four fresh blog posts with Oleg’s here whetting the appetite. Why have we gone all Elixir? As if there needs to be an excuse to talk Erlang OR Elixir, but in this case, we are offering new Elixir Architecture Sessions at Erlang Solutions. In addition, we are present and counting at ElixirConf US this week with one of our senior developers Claudio Ortolina there in the thick of it listening to fantastic talks over the four days. You can also request Empirical Monkeys training with friend of Erlang Solutions, Rafal Studnicki.If you have any questions for Oleg…and later on for Joe and Bart, you can contact us at general@erlang-solutions.com. Keep up-to-date with all things #ElixirOverload and beyond through our Erlang Solutions Twitter, including Claudio’s #TwitterTakeover at ElixirConf 2018.As you know Elixir programs use processes to run pretty much everything, and in order to communicate between processes, Elixir uses message passing. In this blog post we cover scenarios that could result in degraded messaging performance, which in turn can ruin your overall application performance. Sounds interesting? Of course it does! Find out more below…Sending and receiving messagesMessages are sent using the send/2 function and received using the receive do construct.In practice, the simplest way to observe the behaviour of sending and receiving messages is to open up an Elixir shell and execute the following:iex(1)> send(self(), :test_message)\n:test_message\nThe example code shown above will send a :test_message atom to the mailbox of the current shell process.Let’s send several other atoms to ourselves and see what happens when we start reading them back from our process mailbox:iex(2)> send(self(), :test_message1)\n:test_message1\niex(3)> send(self(), :test_message2)\n:test_message2\niex(4)> send(self(), :test_message3)\n:test_message3\niex(5)> :erlang.process_info(self(), :message_queue_len)\n{:message_queue_len, 4}\nAs we can see from the snippet above, every time we send a message to a particular process, it’s stored in that process’ mailbox. We now have 4 messages; lets fetch them from the mailbox using the receive construct!iex(8)> receive do msg -> IO.puts(\"Received message: \#{inspect(msg)}\") end\nReceived message: :test_message\n:ok\niex(9)> receive do msg -> IO.puts(\"Received message: \#{inspect(msg)}\") end\nReceived message: :test_message1\n:ok\niex(10)> receive do msg -> IO.puts(\"Received message: \#{inspect(msg)}\") end\nReceived message: :test_message2\n:ok\niex(11)> receive do msg -> IO.puts(\"Received message: \#{inspect(msg)}\") end\nReceived message: :test_message3\n:ok\niex(12)> receive do msg -> IO.puts(\"Received message: \#{inspect(msg)}\") end\nAs you can see, messages are received in the same order they were transmitted. You can also see that the last receive blocks the shell, which is left waiting to fetch the next message from the process mailbox.A closer look at the receive blockElixir’s receive macro is used in the following way:receive do\n  pattern1 -> :process_message_pattern1\n  pattern2 -> :process_message_pattern2\n  _  -> :process_catch_all_case\nafter\n 1000 -> :ok\nend\nThis code takes the first message from the mailbox and will then try to match it against all the patterns defined in the receive block. If the first message can’t match both pattern1 and pattern2, it will be matched by the catch all () case, and :process_catch_all_case will be returned in this case.Finally, if the process’ mailbox is empty, the code will block new messages to arrive and continue the execution " <> ..., title: "Receiving messages in Elixir or a few things you need to know in order to avoid performance issues", url: "https://www.erlang-solutions.com/blog/receiving-messages-in-elixir-or-a-few-things-you-need-to-know-in-order-to-avoid-performance-issues.html"}
%{author: "by Joseph Yiasemides", text: "To Pipe or Not to Pipe2018-09-07\n        by Joseph Yiasemides \n      The material in this post is based on one of our recent talks at Code BEAM Stockholm. It elaborates on what we covered there on this topic. Though this is a very small part of what it means to program in Elixir, it is something that we stumble across often, so it warrants a post. Here’s our second instalment in the #ElixirOverload series.There is a time and place for one of Elixir’s most loved pieces of notation: the pipe. It is not always best. There are cases where it can really hinder readability while there are other cases where it can very much aid it. What do these look like?We all know a variant introduction to the pipe. Perhaps an expression on a collection with successive work performed by the various Enum functions like the map/2, filter/2, and reduce/3.Take a look at the Elixir script below:require Integer\n\n0..8\n|> Enum.filter(&Integer.is_even/1)\n|> Enum.map(&Integer.to_string/1)\n|> IO.inspect()\nThis has some important aspects to it that are too easy to miss. The first being that there are clear subjects to the expression, the initial Range 0..8, and the intermediate collections we are working through. The other being that there are many successive transformations we perform. Together, a clear subject and successive transformations, are one recipe for a good pipe use-case.The pipe also brings home referential transparency in a way that traditional notation simply cannot. In the below, the values in the comments can be substituted for the the pipeline in the source code up to that point, without changing the behaviour of the program:require Integer\n\n0..8                               ## [0, 1, 2, 3, 4, 5, 6, 7, 8]\n|> Enum.filter(&Integer.is_even/1) ## [0, 2, 4, 6, 8]\n|> Enum.map(&Integer.to_string/1)  ## [\"0\", \"2\", \"4\", \"6\", \"8\"]\n|> IO.inspect()\nThe other case where we see the pipe in its full utility is with a structure. This is where we might liken it to method chaining in so-called OO languages. It might be most familiar to us through the Plug.Conn structure. This time the expression involves an abstract data-type (the Plug.Conn) with functions that transform and return an updated %Plug.Conn{} rather than the Enum higher-order functions. We still perform successive transformation on the structure.conn\n|> Plug.Conn.put_resp_content_type(\"text/plain\")\n|> Plug.Conn.send_resp(200, \"Hello!\")\nThat leaves us with the question of when a traditional notation is best. The answer is when there is no clear subject to an expression, few transformations we want to perform, or the transformations in question juggle intermediate data. Expressions that lend themselves to a traditional notation in some cases include mathematical formulae, reading/writing files, and socket I/O. The formula √|x| + 5·x^3 is one example::math.sqrt(Kernel.abs(x)) + 5 * :math.pow(x, 3)\nIn arithmetic the rules of precedence are well known and expected. Thus, that is all we need to read and understand whatever it is that we are calculating. This is true for all sorts of operator expressions including the common arithmetic, boolean, and list operators. A pipe in these cases would only be awkward and hinder readability. The same goes for the following example:   alias :gen_tcp, as: TCP\n\n    {:ok, socket} = TCP.connect(host, port, [:binary, packet: 0] ++ passive())\n    :ok = TCP.send(socket, data)\n    {:ok, response} = TCP.recv(socket, 0)\n    TCP.close(socket)\nOf course there is a middle ground where the choice between a pipe and traditional notation makes little difference if at all. It is common in this case that we are piping values of different types through successive transformations. If we want to write a program vertically, as opposed to horizontally, then a pipe is the only good choice to avoid superfluous variables if we do not want to nest function application.Compare and contrast the following two definitions:def total(x) do\n  x\n  |> Keyword.values()\n  |> Enum.sum()\nend\n\ndef total(x) do\n  Enum.sum(Keyword.values(x))\nend\n\n96 = total(type: 16, length: 16, value: 64)\nTo conclud" <> ..., title: "To Pipe or Not to Pipe", url: "https://www.erlang-solutions.com/blog/to-pipe-or-not-to-pipe.html"}
%{author: "by Bartosz Szafran", text: "Building an Elixir Stream2018-09-10\n        by Bartosz Szafran\n      With the ElixirConf US last week, we’re celebrating all things Elixir. We have also launched our new Elixir Architecture Sessions - get in touch for more details. Building an Elixir Stream is the third blog of our #ElixirOverload Takeover. You can also read the other Elixir-based content in this series including  Receiving Messages in Elixir by Oleg Tarasenko, and To Pipe or Not To Pipe by Joe Yiasemides. Building an Elixir StreamMongooseIM is one of the products we develop at ESL. It is a real-time messaging platform with a focus on performance and scalability. Therefore it is essential to perform load tests on such software. Here we look at building and developing an Elixir Stream including building a library and testing data. Not so long ago the load testing process was quite complicated and consumed too much developer time. We took the effort to develop an automation tool, called Tide, to test MongooseIM both regularly and easily.It starts load tests with almost no effort from the developer in general. Tests are started in a sandbox environment. During such test, our load-generator Amoc and MongooseIM itself report metrics, describing the state of the test from a client and server perspective. Simulated clients exchange messages through the server, so the most important client metric is end-to-end message delivery time. We use InfluxDB for metrics storage. It is time series database, which efficiently stores metrics, and provides an API for performing analysis on data.The ProblemDuring a test, we set up a temporary instance of InfluxDB, where metrics are reported. It is a fresh instance of the database for each test, started on load infrastructure. After each test, we want to:Retrieve all metrics.Perform some transformations.store it in another instance of InfluxDB, let’s call it persistent.One technical problem, with this approach, is that InfluxDB yields data in a different format than it accepts as input. The output form of queries via the HTTP API has a JSON representation, however InfluxDB expects data in the Influx Line Protocol on writes.So in our product we also had to transform the format of data.So summing up, we query for all data with the following:SELECT * FROM /.*/\nwhich gives us JSON like:{\n    \"results\": [\n    {\n        \"statement_id\": 0,\n        \"series\": [\n        {\n            \"name\": \"metric_name\",\n            \"columns\": [\"time\", \"value\"],\n            \"values\": [\n                [\"2018-02-02T15:46:52Z\", 1],\n                [\"2018-02-02T15:47:02Z\", 2]\n            ]\n        }\n        ]\n    }\n    ]\n}\nWe need to transform it into:metric_name value=1 \"2018-02-02T15:46:52Z\" \nmetric_name value=2 \"2018-02-02T15:47:02Z\"\nand do a POST request to another instance of the database.Naive SolutionLooks pretty simple, just a few Enum.map(). Indeed it worked when we created first prototype. More or less it looked like:def dump_metrics() do\n  query = \"SELECT * FROM /.*/\"\n  params = URI.encode_query(%{q: query, db: \"test_db\"})\n  url = \"http://localhost:8086/query?\#{params}\"\n  %{body: body} = HTTPoison.get!(url)\n  data_to_write =\n    Poison.decode!(body)\n    |> map_metrics()\n    |> convert_to_influx_line_protocol()\n  HTTPoison.post(\"http://another_influx:8086/write\", data_to_write) \nend\nThis naive implementation has a few problems. First of all, it queries for all metrics in one request. This is okay when the expected amount of data is less than a few hundred data points. In our case, we were querying for tens of thousand of data points. Waiting for a response takes more than a minute and is likely to time-out.Using Chunked Transfer EncodingA first attempt to fix this problem was taking advantage of InfluxDB’s ability to chunk responses. It uses HTTP chunked transfer encoding. InfluxDB streams partial results, instead of sending all results at once. To use it, we need to simply add chunked=true to the GET parameters. Let’s look at our dumping function, after introducing these changes:def dump_metrics() do\n  query = \"SELECT * FROM /.*/\"\n  params = URI" <> ..., title: "Building an Elixir Stream", url: "https://www.erlang-solutions.com/blog/building-an-elixir-stream.html"}
%{author: "by Erlang Solutions", text: "Top 5 Elixir \"Gotchas\"2018-09-11\n        by Erlang Solutions\n      Concluding our #ElixirOverload week is a case study from our Elixir Team at Erlang Solutions listing mistakes or oversights that can commonly occur, whether you’re a global company or a new startup.Categories in this case study entitled Top 5 Elixir Mistakes are clearly defined. Each section will look at the symptoms, what to look for, root cause and how to move forward from this:Too much configToo many agentsToo many macrosSimplicity slipping awayDo I need a process?Our Elixir experts run code reviews and they can spot an issue a mile away. Many Elixir code reviews have similar errors, incorrect patterns, regardless of the system size. Here is what they have to say…Too much configAbusing config files, leading to code that’s not flexible at runtime.\nThis is particularly relevant for library authors. It’s preferable to provide public APIs which accept config options, so that we maintain flexibility.Too many agentsClaudio Ortolina: “If a process is named, it means that \nit’s a singleton in the whole system and needs to be designed with \ncare to not become a bottleneck.”It’s easy to reach out for an Agent to store some data. This comes at a cost though, which is the introduction of a bottleneck. It’s always important to think about how the introduction of a new process may affect the overall system performance.Too many macrosMost macro usages can be replaced by function calls. Use macros sparingly, only when you absolutely need to modify the code at compile time.Simplicity slipping awayA code base that is hard to get to grips with. What’s it like when\na new team member comes along to a project? How long do they have to riffle around in a code base before they get to grips with it enough to deliver value? If the answer is too long, given the project size, then this can indicate that simplicity is slipping away.Do I need a process?Szymon Mentel: “The thing is to have the processes in balance. The Erlang VM is known for being able to run hundreds of thousands processes concurrently, but before getting there make sure there’s appropriate rationale behind that.”The full version of Top 5 Elixir Mistakes can be downloaded in a PDF format from our case studies section. It is the first case study you will see. There, you will also find other case studies such as Elixir vs Erlang vs Go; an infographic detailing the important similarities and differences between the BEAM languages.  We have hundreds of BEAM specialists across the world with a passion for open source technologies. They can help with consultancy to development of your fault-tolerant Elixir system. These systems can scale to BILLIONS of users. If you’re interested in consultancy or development, or would like a review of your system, contact us. We’ve also introduced our new Elixir Architectural Sessions. Special thanks to our Elixir Team; Claudio Ortolina, Szymon Mentel, Joseph Yiasemides and Arkadiusz Gil for preparing the case study and additional quotes. Go back to the blog\n\nTags:ElixirelixiroverloadShare  Facebook Twitter Linkedin E-mail", title: "Top 5 Elixir \"Gotchas\"", url: "https://www.erlang-solutions.com/blog/top-5-elixir-gotchas.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Jane Walerud2018-09-11\n        by Erlang Solutions\n      The #OpenErlang InterviewsErlang wouldn’t be what it is today without the community surrounding it! On the 20th anniversary year of the language being open sourced, we have been holding the #OpenErlang celebrations, highlighting the enthusiasts surrounding Erlang as well as the language itself. From the developers who built Erlang from the very beginning, to individuals like Jane who helped spread Erlang across the world, we have been interviewing many contributors and asking “What does Erlang mean to you?”.  Of course, we know of the creators (Robert, Joe and Mike) but there is a whole host of other generations adopting Erlang, and we’ll be speaking to them and the companies that use Erlang in the coming weeks. Continuing our #OpenErlang Interview series is entrepreneur, Bluetail founder and tech investor Jane Walerud who used Erlang to start Bluetail in 1999, soon after the language was open source. Jane talks about how Erlang has developed and contributed to  other languages such as Elixir to appeal to a whole new generation, how influential the decision to make Erlang open source by Ericsson was, and how precious the growing Erlang and Elixir community is. We have the transcript listed at the bottom of this blog post.About JaneJane Walerud describes herself as a “serial entrepreneur”, which is a pretty accurate description! She has helped multiple tech startups since the early noughties as not only an investor but also as an active team member of every startup she worked with. She was instrumental in promoting and open sourcing Erlang back in the 90s. Her work has spanned across many influential companies who use the language including Klarna, Tobil Technology, Teclo Networks and Bluetail, which she founded herself.Jane has always been impressed with the language, hence starting Bluetail and continuing the legacy of Erlang until she sold the company for a whopping $152 million to Alteon Networks. Since then, she has continued her entrepreneurial activities, helping launch countless startups within the technology sector from 1999 to present day. Other roles have included Member of the Board at Racefox, Creades AB and Royal Swedish Academy of Engineering Sciences, and a key role in the Swedish Government Innovation Council. Her current role is Walerud Ventures, a family-run business based in Stockholm, Sweden.You can follow Jane on Twitter. About Walerud VenturesIt seems Jane and her husband have passed on this spirit to her daughter and they currently own their family business Walerud Ventures helping further tech startups reach their full potential. This is founded in 2002.Walerud Ventures devote their time, money and energy to tech companies in the early stages. The main four startups that have done extremely well are Bluetail, Klarna and Tobil as mentioned, and also Lensway. Interview TranscriptAt work with the boss breathing down your neck? Or don’t want to be one of those playing videos out loud on public transport? Here’s the transcript, although not as exciting as the real thing..Jane Walerud: I’m an entrepreneur and met the Erlang gang early on. The first company I started with Erlang was called Bluetail, which basically was clustering technology on the Internet. That was a great success. We sold the company about a year after we founded it for $150 million. Back when I was selling Erlang, I said that one, you could split work over many different computers smoothly. Two, that it didn’t really matter if one of the computers is broke. There would be immediate recovery without the customer or the end user noticing that anything actually happened. And three, it’s very efficient programming. One person doing Erlang can do the work of 10 to 100 other people. When we released open source, it was sort of a secret weapon. Ericsson could have kept it themselves and had a secret weapon where they could finish huge distributed software projects and nobody else could.They decided instead, just to let it out as" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Jane Walerud", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-jane-walerud.html"}
%{author: "by Claudio Ortolina", text: "ElixirConf 2018 Wrap Up2018-09-14\n        by Claudio Ortolina\n      The recent ElixirConf® US 2018 in Bellevue was a whirlwind of announcements, ambitious ideas and solid production stories. I attended with my colleague Adam and had the opportunity to spend significant time chatting with developers and CTOs from companies and organisation of all kinds and size.The community is evolving: recurring topics for this year highlight that plenty of people started tackling challenges growing existing Elixir systems, particularly when introducing stateful, distributed patterns.Testing at largeBoth in terms of talks and hallway conversations, it’s clear that the community is experimenting with property based testing techniques and tools (and in some cases they’ve already adopted this as part of their work stack).In this respect, it’s worth watching the talk by our own Rafał Studnicki and Simon Zelazny from Wallaroo Labs, where they show how they managed to replicate specific issues in Phoenix Presence using a property-based testing approach with Elixir, Docker and Propcheck (based upon PropEr). The source code for that test suite, available at GitHub - distributed-owls/breaking-pp: Breaking pp, is a very approachable code read and shows in practice how to tackle stateful modelling of a real system.Another common thread for those who are looking into property-based testing is the book Property-Based Testing with PropEr, Erlang, and Elixir by Fred Hebert (which I’m reading myself and recommend). Introduction to the topic is gentle, and while the ramp up is steep, the author always carefully tries not to lose people along the way.Telemetry (measure all the things)During his final keynote (and more on that in another paragraph) Chris McCord gave a shoutout to the Telemetry project, a joint effort between the Phoenix team and Erlang Solutions to provide a stable core to introduce instrumentation in any Elixir project.We believe it’s just not possible to run software in production without metrics, alarms and good monitoring (we went as far as building a product for this very reason) and it only makes to contribute community-wise to increase this practice.Other companies, like AppSignal and New Relic are making efforts in terms of supporting the Elixir language and ecosystem, together with open-source initiatives to provide integration with tools like OpenCensus.In the end, it’s just reassuring seeing that no matter what teams choose to use, the concern about running software in production with an eye on monitoring sits front and centre in people’s minds.Nerves, Scenic and IOTJustin Schneck’s keynote showcased NervesHub, a way to securely manage firmware updates for Nerves devices. Technically impressive and full of potential, I also enjoyed the fact that Nerves Hub is the result of the collaboration of different individuals from different companies that ultimately leads to a greater good for the community and therefore can be part of an organisation’s strategy.Boyd Multerer) demoed and talked about Scenic, an OpenGL based Elixir library to build rich user interfaces on a wide variety of OSes, eventually aiming for integration with Nerves. Apart from the impressive performance, it’s the programming paradigm behind it that can potentially be eye-opening for people who are at the beginning of their Elixir/Erlang journey: every element on the screen is a separate process, while groups of elements end up being managed by supervisors. This correspondence between visual layouts and processes architecture seems ideal to teach the language and programming model.PhoenixThe other announcement Chris McCord gave relates to a new experimental package called Phoenix LiveView (which will remain optional and not included in Phoenix core) which can be used to build reactive web interfaces which are completely driven and rendered by the server.This technique can potentially be used to increase a web page interactivity in a progressive fashion and without necessarily opting into a full fledged JavaScript client side framework.ConclusionIt’s interesting to " <> ..., title: "ElixirConf 2018 Wrap Up", url: "https://www.erlang-solutions.com/blog/elixirconf-2018-wrap-up.html"}
%{author: "by Dominic Perini", text: "Blockchain 2018: Myths vs Reality2018-10-17\n        by Dominic Perini\n      After a successful year of involvement in a variety of blockchain projects, I felt it healthy to take a step back and observe the emerging trends in this nascent (but still multi billion dollar) industry and question whether some of the directions taken so far are sensible or whether any corrections are necessary.\nI will provide a ‘snapshot’ of the state of advancement of the blockchain technology, describing the strengths and weaknesses of the solutions that have emerged so far, without proposing innovations at this stage (those ideas will form the subject of future blog posts). If you are interested to hear what I and Erlang Solutions, where I work as Scalability Architect and Technical Lead have to say about blockchain, let me take you through it:The contextI do not propose in this blogpost to get into the details of the blockchain data structure itself, nor will I discuss what is the best Merkle tree solution to adopt. I will also avoid hot topics such as ‘Transactions Per Second’ (TPS) and the mechanisms for achieving substantial transaction volumes, which is de facto the ultimate benchmark widely adopted as a measurement of how competitive a solution is against the major players in the market; Bitcoin and Ethereum.What I would like to examine instead is the state of maturity of the technology, and its alignment with the core principles that underpin the distributed ledger ecosystem. I hope that presenting a clear picture of these principles and how they are evolving may be helpful.The principlesAs the primary drive for innovation emerges from public, open source blockchains, this will be the one on which we will focus our attention.The blockchain technology mainly aims at embracing the following high level principles:Immutability of the historyDecentralisation of the control‘Workable’ consensus mechanismDistribution and resilienceTransactional automation (including ‘smart contracts’)Transparency and TrustLink to the external worldLet us look at them one by one:1. Immutability of the historyIn an ideal world it would be desirable to preserve an accurate historical trace of events, and make sure this trace does not deteriorate over time, whether through natural events, or by human error or by the intervention of fraudulent actors. The artefacts produced in the analogue world face alterations over time, although there is often the intent to make sure they can withstand forces that threaten to alter and eventually destroy them. In the digital world the quantized / binary nature of the stored information provides the possibility of continuous corrections to prevent any deterioration that might occur over time.Writing an immutable blockchain aims to retain a digital history that cannot be altered over time and on top of which one can verify that a trace of an event, known as a transaction, is recorded in it. This is particularly attractive when it comes to assessing the ownership or the authenticity of an asset or to validate one or more transactions.We should note that, on top of the inherent immutability of a well-designed and implemented blockchain, hashing algorithms also provide a means to encode the information that gets written in the history so that the capacity to verify a trace/transaction can only be performed by actors possessing sufficient data to compute the one-way1 cascaded encoding/encryption. This is typically implemented on top of Merkle trees where hashes of concatenated hashes are computed.Legitimate questions can be raised about the guarantees for indefinitely storing an immutable data structure:If this is an indefinitely growing history, where can it be stored once it grows beyond capacity of the ledgers?As the history size grows (and/or the computing power needed to validate further transactions increases) this reduces the number of potential participants in the ecosystem, leading to a de facto loss of decentralisation. At what point does this concentration of ‘power’ create concerns?How does the verification performance d" <> ..., title: "Blockchain 2018: Myths vs Reality", url: "https://www.erlang-solutions.com/blog/blockchain-2018-myths-vs-reality.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Simon Phipps2018-10-19\n        by Erlang Solutions\n      2018 also marks another huge anniversary! The “open source” label was created at a strategy session held on February 3rd, 1998 in Palo Alto, California. That same month, the Open Source Incentive (OSI) was founded. So this year we’ve partnered with OSI to celebrate our anniversaries together. Viva open source, viva #OpenErlang! This is now our fourth #OpenErlang Interview having already unleashed videos featuring Robert Virding and Joe Armstrong, Chris Price, and Jane Walerud; each have their own views and stories to share when it comes to Erlang and open source. 2018 also marks another huge anniversary! The “open source” label was created at a strategy session held on February 3rd, 1998 in Palo Alto, California. That same month, the Open Source Initiative (OSI) was founded. So this year we’ve partnered with OSI to celebrate our anniversaries together. Viva open source, viva #OpenErlang!Without further ado, we are very happy to introduce our next #OpenErlang friend - President of the Open Source Initiative, Simon Phipps. We have the transcript listed at the bottom of this blog post.About SimonSimon Phipps has his fingers in a lot of puddings, and is a passionate open source advocate. He is a programmer and computer scientist extraordinaire with a wealth of experience  and we didn’t have to ask him twice to work with us. In a true open source spirit, Simon is always very excited to support any project or campaign promoting the open source!   Simon has had experience at some of the world’s leading tech companies. He was a key figure at IBM in relation to Java, having founded their IBM Java Technology Center. He then joined Sun Microsystems in 2000 - most of Sun’s core software then became open source under Simon’s leadership (Solaris, XML and Java being the main ones). As mentioned, Simon is the President of the Open Source Initiative, which he also created, and he has been President twice; firstly until 2015 before stepping down at the end of his term in 2016. He was then re-elected in 2017. Simon is also part of the Open Rights Group, The Document Foundation and on the board of Open Source of America. Pass roles have included OpenSolaris, OpenJDK, OpenSPARC and MariaDB Foundation. He is the creator of LibreOffice and founder of Open Mobile Alliance. About The Open Source InitiativeDo any of us remember a life without Internet? If so, those were bleak times indeed. Using paper maps and needing to entertain ourselves…For starters, none of us would be in our position now if the decision by Ericsson to open source Erlang hadn’t been made 20 years ago. In the same year, the coinage of the term “open source” came about in Palo Alto, California and the Open Source Initiative (OSI) was created. Like Erlang, the Open Source Initiative had no idea just how popular it would become. OSI is a global non-profit organisation that promotes open source software and the communities that love them. This includes education and infrastructure, as well as building communities surrounding the various language. Along with broadcasting the popularity of open source technologies and projects, including BEAM languages, the OSI aims at preserving the communities and continuing legacies that are now 20 years old. Interview TranscriptAt work with the boss breathing down your neck? Or don’t want to be one of those playing videos out loud on public transport? Here’s the transcript, although not as exciting as the real thing.Simon Phipps: I’ve been with the Open Source Initiative now since 2008. For the last few years, I’ve been the President of the Open Source Initiative. The Open Source Initiative is at its heart a marketing program for free software. It takes the practical aspects of software freedom, the development methodology, the community openness, and makes them accessible to businesses and to those who don’t want to become activists for the ethics of free software. In the early years, it was very much an upstart movement. It focus" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Simon Phipps", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-simon-phipps.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Anton Lavrik from WhatsApp2018-10-24\n        by Erlang Solutions\n      May the 20th anniversary celebrations of open sourced Erlang never end! And we don’t intend to slow down. In fact, we are speeding things up as the #OpenErlang party in London fast approaches (you still have time to register and join us on 8th Nov). Our upcoming #OpenErlang interviews will share more insights on how global companies such as WhatsApp and AdRoll achieved the unachievable, with Erlang being their secret weapon. Erlang - WhatsApp secret weapon to conquer the globe! WhatsApp runs on Erlang, and happening to be sponsoring our #OpenErlang London Party in early November. Currently there is 1 billion daily active WhatsApp users, sending 6 billion messages and 4.5 billion photos every day! And there is over 55 billion WhatsApp calls made every day. The ability to process this amount is astonishing and we want to know more about WhatsApp ability to manage their system and provide a smooth experience to their users. Next in our #OpenErlang interviews we host WhatsApp Server Engineer Anton Lavrik who shares with us why he loves Erlang and how it is used at WhatsApp with tremendous success. We have the transcript listed at the bottom of this blog post.About AntonAnton came across Joe Armstrong’s PhD thesis on Erlang 15 years ago as part of his own PhD, and he’s been a supporter of the language ever since, having actively used Erlang for over a decade now. Whilst he has been using Erlang for a while now, Anton has worked over numerous domains including embedded and real-time systems, domain-specific languages and programming tools, large-scale data collection and processing systems, custom analytic databases, and analytic stacks. Anton began his programming career in 2001 and has since worked as a Technical Lead for Alert Logic amongst other roles before moving to WhatsApp. About WhatsAppWhatsApp was founded in 2009 by ex-Yahoo! Employees Brian Acton and Jan Koum. After buying an iPhone, Koum quickly realised the gaping hole that WhatsApp would eventually fill and the pair found a developer on RentACoder.com named Igor Solomennikov to turn their idea into reality. The early versions of the app would often crash to the point where Koum was considering packing it in to pursue other ventures. His business partner Acton convinced him to stay and just a few months later in June 2009, Apple launched push notifications which would be vital in the evolution of WhatsApp. Users quickly increased to 250,000. The growth was so sudden that the team decided to change WhatsApp to a paid service (just $1 yearly subscription) as the verification texts were costing the small company too much. By December 2009, you could now send photos via the application as well. Fast-forward to December 2013 - WhatsApp has 400 million active users every month. Fast-forward again to February 2017 - WhatsApp has over 1.2 billion users globally. And of course, it is a free service. Today, we have over 1 billion daily active users - just wow! Some other stats to tantalise the tastebuds courtesy of expandedramblings.com:450 million daily active users100 million daily voice calls70% of users that use WhatsApp on a daily basis65 billion WhatsApp messages are sent dailyThere are 1 billion WhatsApp groups4.5 billion photos are shared through on the app daily3 million companies use WhatsApp for business purposes.Why WhatsApp uses ErlangEveryone knows WhatsApp - it’s the most popular messaging application that has ever been created - but in terms of the backend? This is often something we don’t think about. WhatsApp will successfully send your message and we all carry on with the rest of our day. WhatsApp uses a surprisingly small amount of engineers for the billions of users it caters to on a daily basis. How do they manage this? Like many applications Erlang is involved in, it becomes the one essential cog that all the smaller cogs revolve around. One of Erlang’s best attributes is concurrency - it is the best multi-tasker out there " <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Anton Lavrik from WhatsApp", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-anton-lavrik-from-whatsapp.html"}
%{author: "by Felipe Ripoll", text: "Building the NetStats System Dashboard for Ethereum-based platform 2018-10-25\n        by Felipe Ripoll\n      During the last year, we have been working closely with POA Network improving one of the systems they run. Erlang Solutions Elixir/Erlang Developer and Architect Felipe Ripoll will look to explore the ins and outs of the NetStats System Dashboard in this latest post. At Erlang Solutions we provide Erlang and Elixir Consultancy but what does POA Network do? Simply put, they are running an Ethereum-based network but with a new Consensus Mechanism type called Proof of Authority, and they have this to say:“POA Network is an Ethereum-based platform that offers an open-source framework for smart contracts. POA Network is a sidechain to Ethereum utilizing Proof of Authority as its consensus mechanism. POA provides developers with the flexibility to code in Ethereum standards with the added benefits of POA Network’s solutions to scalability and interoperability in blockchain networks.”In this blog post, we will focus primarily on the dashboard we have created, however, if you want more information on the POA Network you can check their website where they concisely explain what they are doing, and you can also check the code! You’ll find info for this at the bottom of this post. Netstats SystemFor this kind of system, it is critical to have a tool capable of checking the status of each Ethereum node in the network. That is why it has been already created. It is called the ‘Netstats’.The first version of this tool was originally split into two different projects by POA Network: the Agent and the Dashboard. Both were written in Node JS.• The Agent is a simple process running in each Ethereum node. Its task was to retrieve Ethereum metrics periodically and send them through a WebSocket connection to the Dashboard server.• The Dashboard was in charge of receiving the Ethereum metrics from each Agent and serving an HTML webpage with those metrics displayed in real time.The solution based on a NodeJS approach, although responding successfully to a number of critical requirements, exposed the following weaknesses:• It wasn’t extensible. That means it was only working on Ethereum metrics. Instead, we were asked to make the system capable of handling more types of metrics. For example System metrics (disk space, memory usage…) or maybe others that might become relevant at a later stage.• Persistence; POA Networks wanted a way to store the metrics in a database.• It wasn’t scalable. Node JS is great for prototyping basic systems but it is not very good to sustain a growth from a few agents to thousands.Our aim was to provide a solution which offers a response to the described weaknesses. Simple as that!In order to fix the extensibility issue, we decided to provide the system with plugins so that one can easily create own plugins in order to get the specifically wanted metrics.That plugins mechanism helps with the Persistence issue too. In fact, one can create a plugin which, instead of sending the data to the Dashboard, stores it into a database. One can then create another plugin for the Dashboard communication so the same metric would go through the two plugins in a pipeline.For the Scalable issue, we decided to go with Elixir…Our SolutionWe chose to continue with the system split into two parts; the Agent and a Backend Server. This server is called now the Warehouse. Agents collect data in the nodes and send them to the Warehouse periodically.The Plugins mechanism are present in both the Agents and the Warehouse. With the agents, one can create plugins for different kinds of metrics. In the event that metrics need to be routed to different destinations, data can be sent directly to a warehouse server using one plugin and to a database through another plugin. With the warehouse, the plugins will be used to select the type of protocol to use while communicating with the Agents. In addition, we can use plugins to determine what to do with the data. For instance, send it to the Dashboard UI or store it into a database.The AgentThe ma" <> ..., title: "Building the NetStats System Dashboard for Ethereum-based platform ", url: "https://www.erlang-solutions.com/blog/building-the-netstats-system-dashboard-for-ethereum-based-platform.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: The OpenErlang Parties2018-10-30\n        by Erlang Solutions\n      It’s party time! To celebrate the 20th anniversary of open sourced Erlang, we have already held two great parties in San Francisco and Stockholm - now it’s London’s turn!This year we’ve been also holding meetups, webinars, producing blogs and interviews to mark the occasion, but like any celebration, a party should be on the cards!The London Erlang Party is coming and we invite you all to join the Erlang, Elixir and Open Source community on the evening of 8th November.  Put your name on the list and we will send you a free ticket!The choice to make Erlang available to everyone has created a powerful community, and its achievements have been exceptional. We’ve partnered with WhatsApp and æternity to say a MASSIVE thank you and treat you to a good old-fashioned night out in London, on us! This is a free event full of drinks, food and a few surprises, and we can’t wait for you to join us in celebrating open source languages and in particular ERLANG! Please RSVP on our Eventbrite page to register your attendance.When: Thursday 08 November 2018 - 18:30 - late\nWhere: ILEC Conference Centre, 47 Lillie Road, London. SW6 1UDOpenErlang InterviewsAlong with our London shindig, we have a selection of #OpenErlang Interviews online. We’ve been asking key influencers in the Erlang community to chat to us about their experiences and Erlang milestones over the last 20 years.  If you’ve signed up, check out a sneak peek of what’s to come! And if you haven’t - what are you waiting for? It’s free after all…We have the transcript listed at the bottom of this blog post.About #OpenErlangYou can find out more about our activities - past, present and future - at our #OpenErlang page. Catch up with past webinars, sign up for current ones, and watch our complete #OpenErlang Interview series. About ErlangErlang was created in the Ericsson labs in the mid-80s by Robert Virding, Joe Armstrong and Mike Williams where Ericsson continued to use it until it was made open source in 1998. Jane Walerud was a key figure in helping the language become open source as well. The name “Erlang” came from an abbreviation of “Ericsson Language” along with reference to the Danish mathematician and engineer Agner Krarup Erlang who invented fields of traffic engineering and queueing theory. The language was designed with the aim of improving the development of telephony applications, and a garbage-collected runtime system. The key positive of Erlang is the “write once, run forever” motto coined by Joe Armstrong in an interview with Rackspace in 2013. The successes of the language can often be down to “robustness” - the ability to run multiple processes whilst still maintaining the amazing speed and efficiency. Error handling is non-local so if one process breaks or encounters a bug, it continues running! And then of course Erlang is famous to be scalable, distributed, highly concurrent, highly available and fault-tolerant functional programming language.Erlang can be used interchangeably with Erlang/OTP. Interview TranscriptAt work with the boss breathing down your neck? Or don’t want to be one of those playing videos out loud on public transport? Here’s the transcript, although not as exciting as the real thing.[background instrumental music]Stuart Whitfield: This year is the 20th anniversary of the open sourcing of Erlang. The BEAM Community wouldn’t exist if that fateful decision hadn’t been taken two decades ago.Anna Neyzberg: Open Source really did change the way they built software and seeing that people are still committed to continuing that and passing that on is really critical so we can continue doing what we do.Francesco Cesarini: It’s really, really exciting to see how they are all getting along, sharing ideas and learning from each other.Osa Gaius: Different countries of all races, backgrounds. We hope that in the next 20 years, the diversity of people in the community will still be large.Stuart: Erlang success as a technology would not have happened without " <> ..., title: "20 Years of Open Source Erlang: The OpenErlang Parties", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-the-openerlang-parties.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Miriam Pena2018-11-06\n        by Erlang Solutions\n      We’ve been holding a year-long celebration in the honour of Erlang’s 20th anniversary as an open source language. This week, we’re excited to introduce Miriam Pena as our next #OpenErlang enthusiast. Previously, we looked into WhatsApp with one of their talented Server Engineer’s Anton Lavrik. WhatsApp has used Erlang since its humble beginnings back in 2009, but what other giants use the language? Miriam Pena is one equally talented Staff Engineer at AdRoll, a company that uses both Erlang and Elixir!Adroll uses both languages “to respond to each bid request in less than 80 milliseconds” and Miriam wouldn’t have it any other way. Here, she discusses when she saw the real potential of Erlang and how its concurrency methods are used to full advantage at AdRoll. We have the transcript listed at the bottom of this blog post.About MiriamMiriam has been an engineer at AdRoll for nearly 5 years. During that time, she has worked with Erlang, Elixir, AWS, Python, Dynamodb, Kinesys and Memcached. Currently, AdRoll’s real time bidding system handles a peak volume of 1.5 Million req every SECOND.  Previously, Miriam has worked as an Erlang specialist software engineer, including with us at Erlang Solutions back in 2008-2011! With over a decade of experience working with scalable systems, at AdRoll, Miriam designs critical parts of their Real-Time Bidding and Ad Server infrastructure, organizes the Erlang and Elixir meetup in San Francisco and has previously been voted one of the “women to watch” by Women 2.0. Miriam loves working with distributed, scalable, high performance, high concurrency, and high availability systems. Bonus points if they are written in Erlang and Elixir! She has also open sourced a lightweight Memcached Erlang library called Mero that is used at a massive scale in their RTB infrastructure. About AdRollAdRoll was founded in 2007 with the purpose of advertising online without the need for massive budgets only rewarded to major corporate companies, and the needless complexity that came with this. It works by retargeting - those ads that follow you around the internet encouraging you to buy whatever it was that your willpower denied you the first time around! Retargeting is an extremely successful advertising tool, and AdRoll has allowed businesses of nearly any size to benefit from it. The benefit for us? Much more variety! It keeps a particular brand at the front of the consumer’s mind, so when they decide to commit to a purchase, they commit to your business. To retarget most effectively, you must segment your users so the ad they’re receiving is 100% relevant. You must also consider the type of product. For example, if a user wants to buy flights or hotels, it’s best practice to target near immediately, whilst bigger/luxury purchases require further thought and therefore you shouldn’t bombard the consumer. Why AdRoll uses ErlangAdRoll has said that they have generated over $7 billion in revenue for their customers, and as previously mentioned, AdRoll must deal with approximately 1.5 million actions per second and answer them in less than 80 milliseconds. This huge amount of requests requires a highly reliable system such as Erlang to process actions very quickly and even more efficiently. Erlang is an extremely concurrent system that can handle this real-time bidding with a very minimal possibility of the systems crashing. AdRoll’s two main issues are:Real-time bidding - there will be multiple businesses battling it out for the same ad space. Real-time bidding, like an online auction for the best spots. AdRoll participates in over 1 million programmatic auctions per second. Erlang also allows buyers to respond just as quickly.\nAd targeting - AdRoll has a thorough system in place to funnel users to the correct advertisement on the correct website. The main benefits of Erlang for AdRoll:• Erlang/OTP offers AdRoll scalability - robust building blocks can be easily replicated.\n• Erlang/OTP offers robu" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Miriam Pena", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-miriam-pena.html"}
%{author: "by Erlang Solutions", text: "Vitamin E - FinTech Special 2018-11-02\n        by Erlang Solutions\n      To sign up to our newsletter at the bottom of this post!\nVitamin E FinTech Special - Blockchain myths and reality, exciting new projects and webinar announced…Vitamin E\n\n                        FinTech SpecialYour monthly dose of all things Erlang & Elixir from Erlang Solutions✨ It’s a FinTech Special ✨ Blockchain - Is it the future or will the bubble burst?\n\n\n                                                Behind the scenes, our teams have been blowing the lid off of the Blockchain scene! Last year’s involvement in a number of successful Blockchain and FinTech projects made us achieve the unachievable. \n\n\n                                                Now that we are catching our breaths, we wanted to look through the myths vs reality of Blockchain to sift through the noise and give you a clear idea of what on earth is going on.\n\nBlockchain 2018: Myths and Reality is an unmissable summary of the state of the art by Dominic Perini, our Scalability Architect and Tech Lead at Erlang Solutions.\n\n\n                                                Get involved in the discussion and be ready for more insights on how to disrupt FinTech and Blockchain with hyper-reliable, concurrent and scalable solutions.\n\n\n                                                Keep your eyes peeled and ears open for MORE FinTech and Blockchain reviews, webinars, and blogs.  Read Blockchain 2018: Myths vs Reality → COMPANY FOCUS - POA NetworkOne of our substantial FinTech collabs has been with Ethereum-based platform POA Network. During the last year, we have been working closely to improve one of their systems, with great success! \n\n\n                                                Elixir/Erlang Developer and Lead Architect of this project Felipe Ripoll explored the ins and outs of the NetStats System Dashboard in his latest blog post.\n\n\n                                                What’s more! We have a very special webinar approaching with POA Network’s Project Lead Andrew Cravenho entitled: \n\n‘BlockScout - Open Source EVM Blockchain Explorer’.\n\n\n                                                This is on Wednesday 14th November - sign up now! Even if you can’t make it, we’ll send this to all registrants personally, so it’s worth signing up!Sign up to BlockScout Webinar →COMPANY FOCUS - æternity\n                                                We teamed up with æternity to disrupt the Blockchain space! Together we are building a highly scalable system that caters for billions of users.\n\n\n                                                Kudos to the founder Yanislav Malahov and his æternity team and for their amazing work - long live scalability.\n\n\n                                                Have a look at Yani’s high praise on our new and improved FinTech and Blockchain page at Erlang Solutions!\n\n\n                                                We also partnered with æternity and WhatsApp to organise a free #OpenErlang party in London on Thursday 8th November. Make sure you sign up and celebrate 20 years of Erlang being open sourced. Explore FinTech Page  →#OpenErlang London Party Friends of the BEAM - please join us for an evening celebrating 20 years of open source Erlang!\n\nDetails\n\n                                                📆 Thursday 8th November \n\n                                                📍ILEC Conference Centre, 47 Lillie Road, SW6 1UD\n\n                                                ✅ Free event\n\n                                                🖊 RSVP\n\n\n                                                The choice to make Erlang available to everyone has created a powerful community, and its achievements have been exceptional. We’ve partnered with æternity and WhatsApp to say a BIG thank you and treat you to a good old-fashioned night out in London, entirely on us. This week we also published highlights from our Stockholm party to whet the appetite so don’t miss out! \n\n\n                                                Along with our London shindig, we have a sel" <> ..., title: "Vitamin E - FinTech Special ", url: "https://www.erlang-solutions.com/blog/vitamin-e-fintech-special.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: OpenErlang Interview with Robert Virding2018-11-14\n        by Erlang Solutions\n      This is our last OpenErlang Interview of the series! We’ve spoken to some serious Erlang players over the last couple of months including massive companies such as WhatsApp and AdRoll who use Erlang, and enthusiasts and champions of tech and open source languages. We started off our celebrations with an interview with Robert Virding and Joe Armstrong - the creators of Erlang! How Erlang and its community has grown over the last 20 years is a testament to its creators, who developed the language in the Ericsson labs during the 1980s. Robert Virding needs no introduction, so let’s go straight into our interview as he speaks about WHY Erlang was made including its scalability and robustness, and where he sees the language going from here. We have the transcript listed at the bottom of this blog post.About RobertRobert Virding is one-third of why Erlang exists; along with Joe Armstrong and Mike Williams, Robert developed Erlang in 1986 and continued to use it solely at Ericsson before the language was released as open sourced in 1998.Robert originally worked extensively on improving garbage collection and functional languages but has since developed his entrepreneurial spirit having begun the first Erlang startup - Bluetail.The co-creator was an early member of the Ericsson Computer Science Lab and currently works as the Principal Language Expert at Erlang Solutions, as well as a keen speaker and educator.About ErlangErlang was created in the Ericsson labs in the mid-80s by Robert Virding, Joe Armstrong and Mike Williams where Ericsson continued to use it until it was made open source in 1998. Jane Walerud was a key figure in helping the language become open source as well. The name “Erlang” came from an abbreviation of “Ericsson Language” along with reference to the Danish mathematician and engineer Agner Krarup Erlang who invented fields of traffic engineering and queueing theory. The language was designed with the aim of improving the development of telephony applications, and a garbage-collected runtime system. The key positive of Erlang is the “write once, run forever” motto coined by Joe Armstrong in an interview with Rackspace in 2013. Other characteristics of Erlang include:• Fault-tolerant\n• Soft real-time\n• Immutable data\n• Pattern matching\n• Functional programming \n• Distributed \n• Highly concurrent\n• Highly available\n• Hot swapping The successes of the language can be often due to “robustness” - the ability to run multiple processes whilst still maintaining the amazing speed and efficiency. Error handling is non-local so if one process breaks or encounters a bug, it continues running! Erlang can be used interchangeably with Erlang/OTP. Interview TranscriptAt work with the boss breathing down your neck? Or don’t want to be one of those playing videos out loud on public transport? Here’s the transcript, although not as exciting as the real thing.Robert Virding: Erlang is a programming language, and the system around that, for building systems which are highly concurrent and fault-tolerant. Systems where a lot of things are going on at the same time and you don’t want the system to crash when things go wrong…because they always go wrong! We originally worked for telephone switches but now it’s being used for a lot of different things, for example, web servers. If you have a big web server, of course, you want a lot of things going on at the same time.It’s quite fascinating because it’s being used for things we had never dreamed of when we originally created the language, that would come along later. 2018 was interesting, the fact this was 20 years ago Erlang became open source and available to users outside Ericsson. Since then it’s been spreading. It is still spreading and being used in more things with different type of users, and the other languages written on top of it. So in that sense it’s an interesting year because it’s just getting bigger and bigger and spreading more and more.Erlang has been" <> ..., title: "20 Years of Open Source Erlang: OpenErlang Interview with Robert Virding", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-openerlang-interview-with-robert-virding.html"}
%{author: "by Piotr Nosek", text: "MongooseIM 3.2 - Meet our Inbox2018-11-21\n        by Piotr Nosek\n      Since the last release of our enterprise-ready, highly scalable IM platform: MongooseIM 3.1, the team has been working at full speed on the expanded set of features and improvements aimed to bring MongooseIM to the next level. What comes as a result is MongooseIM 3.2. With its highlights such as full-featured Inbox, worker pool unification,  PKI for BOSH and Websockets and multi-aspect TLS integration, this release becomes a big step in the evolution of our server!What we love about MongooseIM 3.2 ?!The latest iteration of MongooseIM not only introduces exclusive and uncommon solutions, such as the advanced inbox or multi-aspect TLS integration, it also becomes more and more open to new angles in providing a full-fledged messaging solution, that responds to global market demands.Among the highlights of the 3.2 release, there is another bundle of Inbox improvements. The most significant one is the possibility to attach unread messages count to push notifications so application badge may be updated appropriately. Our full-featured Inbox now gets more and more mature, becoming a complete extension for virtually every chat application! We also added PKI for BOSH and Websockets, allowing web XMPP clients to authenticate with TLS certificate.This version certainly makes devops’ life easier. Unified worker pools, provided in 3.2, enable much more convenient and consistent configuration of outgoing connections (e.g. to databases). They also grant better stability, predictability, and inspection of their behavior.Meet our InboxInbox in MongooseIM 3.2 received a couple of nice improvements but one of them is particularly important: integration with the Event Pusher. Among other things, this component is responsible for delivering push notifications data to MongoosePush and other services, and using it with inbox opens up some new possibilities. One example would be simplifying incrementing the unread count (the “badge”) which up until now was hardcoded to “1” and required extra effort from the frontend team when trying to display the real number of notifications. Push notifications implementation was unable to access this information at the moment of event delivery and the client application had to work around this and risk being inaccurate.With the new update, a valid number is always attached to push notifications so the applications may display it in a simple, natural and precise manner.\nMongooseIM 3.2 introduces a number of updates that should make your client development team much happier. All inbox query results include total unread messages count and the number of “active” (with at least one unread message) conversations. A client may also filter explicitly for active conversations only.We would like to present our new Inbox demo, showcasing three of the newly added features:Unread messages counter implemented for push notificationsNew filtering option - a user may choose to query for conversations with unread messages onlyExtended error description - error messages readability is improved.Examples in the demo are prepared with the Forward application.Worker pools - unite!When you take a look at MongooseIM 3.1 - Inbox got better, testing got easier\nyou may notice an inconspicuous paragraph “Worker pool unification”. This small internal improvement expanded into one of the most satisfying cleanups in MongooseIM in recent history. It affects not only the server’s inner workings but also changes the way pools are configured.Until 3.1.x (included) the config schema varied between multiple connection types:For RDBMS there was an odbc_server key (misleading, right?) with several unlabeled elements (you had to remember their order or use docs). Pool size was defined under separate key. Oh, right, there was yet another key to define the pool names alone. And you couldn’t define common pool for all XMPP domains.For HTTP, we had an http_connections key. Pool size was provided as one of key-value pairs.For Cassandra you could specify the pool size as well. As one o" <> ..., title: "MongooseIM 3.2 - Meet our Inbox", url: "https://www.erlang-solutions.com/blog/mongooseim-3-2-meet-our-inbox.html"}
%{author: "by Francesco Cesarini", text: "Twenty Years of Open Source Erlang2018-12-08\n        by Francesco Cesarini\n      Erlang was released as Open Source Tuesday December 8th, 1998. Do you remember where you were that week? I was in Dallas (Texas); one of my many visits helping the Ericsson US branch set up an Erlang team working with the AXD301 switch. Waking up on Tuesday morning, I got the news. The release was uneventful. There was no PR around the release, no build up or media coverage. Just a sparce erlang.org website (handcrafted using vi). An email was sent to the Erlang mailing list, a post made the front page on slasdot, alongside a mention on comp.lang.functional (which Joe dutifully followed up on). There were no other marketing activities promoting the fact that Ericsson had released a huge open source project. My highlight that week was not the release of Erlang, but going to a Marky Ramone and the Intruders gig in a dive in downtown Dallas. Little did I know how Open Source Erlang would affect the tech industry, my career, and that of many others around me. Getting it out of EricssonWhat made it all happen? Many of us wanted Erlang to be released as open source, for a variety of reasons. Some of my Ericsson colleagues wanted to leave their current positions, but continue building products with what they believed was a silver bullet. Others wanted to make the world a better place by making superior tools for fault tolerant and scalable systems available to the masses. For Ericsson management, a wider adoption of Erlang would mean a larger pool of talent to recruit from. Jane Walerud was amongst us trying to sell Erlang outside of Ericsson and one of the few who at the time knew how to speak to management; she understood that the time of selling programming languages was over. Håkan Millroth, head of the Ericsson Software Architecture Lab suggested trying this new thing called “Open Source”. Jane, armed with an early version of The Cathedral and the Bazaar paper, convinced Ericsson management to release the source code for the Erlang VM, the standard libraries and parts of OTP. Until Erlang was out, many did not believe it would happen. There was a fear that, at the last minute, Ericsson was going to pull the plug on the whole idea. Open Source, a term which had been coined a few months earlier, was a strange, scary new beast large corporations did not know how to handle. The concerns Ericsson had of sailing in uncharted territory, rightfully so, were many. To mitigate the risk of Erlang not being released, urban legend has it that our friend Richard O’Keefe, at the time working for the University of Otago in New Zealand, came to the rescue. Midnight comes earlier in the East, so as soon as the clocks struck midnight in New Zealand, the erlang.org website went online for a few minutes. Just long enough for an anonymous user to download the very first Erlang release, ensuring its escape. When the download was confirmed, the website went offline again, only to reappear twelve hours later, at midnight Swedish time. I was in Dallas, fast asleep, so I can neither confirm nor deny if any of this actually happened. But as with every legend, I am sure there is a little bit of truth behind it.The Dot Com Bubble EraAdoption in first few years was sluggish. Despite that, the OTP team, lead by Kenneth Lundin was hard at work. In May 1999, Björn Gustavsson’s refactoring of the BEAM VM (Bogdan’s Erlang Abstract Machine) becomes the official replacement of the JAM (Joe’s Abstract Machine). Joe had left Ericsson a year earlier and the BEAM, whilst faster, needed that time to make it production ready.I recall the excitement every time we found a new company using Erlang/OTP. Telia, the Swedish phone company, was working on a call center solution. And One2One - the UK mobile operator - had been initially using it for value added services, expanding its use to the core network. IdealX in Paris, did the first foray into messaging and XMPP. Vail System in Chicago and Motivity in Toronto were using it for auto dialler software. And Bluetail, of course, had many produ" <> ..., title: "Twenty Years of Open Source Erlang", url: "https://www.erlang-solutions.com/blog/twenty-years-of-open-source-erlang.html"}
%{author: "by Erlang Solutions", text: "20 Years of Open Source Erlang: The OpenErlang Interviews2018-12-19\n        by Erlang Solutions\n      In our latest blog post ‘Twenty Years of Open Source Erlang’, Francesco Cesarini spoke of a conversation he had with Joe Armstrong back in 1995, three years prior to Erlang becoming open source; “Erlang will not be around forever.” Joe said, “Someday, something better will come along”. Here we are, careering into 2019, and Erlang still remains as strong as ever. What’s the secret?All year we’ve been celebrating #OpenErlang and you have surely come across our amazing video series. We’ve spoken to some of the key enthusiasts that have been championing Erlang/OTP! This includes Anton Lavrik from WhatsApp, probably one of the most prolific companies to use Erlang to date with 1 BILLION active daily users. And how about AdRoll? Staff Engineer Miriam Pena spoke of Erlang participating in over one million actions per second. You can check out the other companies that use Erlang as well. Erlang has the ability to scale tremendously, but it has also understandably made waves in the open source community - the social side of programming. The President of the Open Source Initiative, Simon Phipps, spoke of Erlang’s strong following, and how Microsoft had made a “delicious” U-Turn from the Linux operating system to Erlang. Lastly, we spoke to past and present employees of Ericsson! Jane Walerud was a hugely integral part in making Erlang open source in 1998, whilst current President of Ericsson Software Technology Christopher Price gave us further insight into Ericsson’s 5G development using Erlang. Here we have a look back at all of the #OpenErlang videos that began back in August with Robert Virding and Joe Armstrong and ended with Francesco’s retrospective from 1998 to 2018. \nThe Erlang Creators; Robert Virding and Joe ArmstrongWe interviewed Robert and Joe during the #OpenErlang Stockholm party, and it felt only right to begin our Erlang journey with those who know it best; the co-creators of Erlang! Mike Williams was absent during our Stockholm Party, but of course there in spirit, and as always Robert and Joe were as enthusiastic about Erlang now as they were in 1998. You can read the full article including the interview, facts about Robert and Joe, and the Erlang journey.The President of Ericsson Software Technology; Christopher PriceChris spends his time developing and promoting open source communities, not only at Ericsson but at OpenStack where he’s on the Board of Directors and the OpenDaylight Project as an Ambassador. These are just his current roles! What was interesting, speaking to Chris, is the development in 5G technology. Ericsson anticipates that by 2023, 20% of the world’s population will be covered by 5G and it intends to get the ball rolling. You can read more about Chris, the legacy of the Ericsson Labs, and what Ericsson is doing including its 5G standardisation. The Serial Tech Entrepreneur; Jane WalerudA “serial tech entrepreneur” is the best way to describe Jane. She has invested in a number of tech startups since the 90s and was instrumental in promoting the fine qualities of Erlang back in 1998 when she campaigned to make it open source. In fact, she used Erlang when founding Bluetail back in 1999 with Robert Virding. Erlang can lend itself to other languages, such as Elixir, which she describes in her #OpenErlang interview. Jane has always been impressed with the robust nature of Erlang. The fact you can run it on multiple devices, and if one breaks? Doesn’t matter. Read more about Jane’s inspiring Erlang journey, and how Erlang went from Ericsson’s “secret weapon” to open source.  The Open Source Freedom Fighter; Simon PhippsSimon’s passion is open source. He created the Open Source Initiative back in 1998, in the same month that the term “open source” was coined! Since then, Simon has been involved in so many organisations that champion open source languages, including being the President of the Open Source Initiative. “Software freedom is the essential ingredient for the profitability of companies us" <> ..., title: "20 Years of Open Source Erlang: The OpenErlang Interviews", url: "https://www.erlang-solutions.com/blog/20-years-of-open-source-erlang-the-openerlang-interviews.html"}
%{author: "by Erlang Solutions", text: "Q&A with Programmer and #OpenErlang Illustrator Daniel Stori2019-01-15\n        by Erlang Solutions\n      We were delighted to have Daniel Stori onboard with our #OpenErlang celebrations. As an open source advocate, Daniel put his two fine talents - open source programming and illustrating - to good use when creating the #OpenErlang comics. About DanielSoftware specialist, Daniel Stori has been in the industry for the past 20 years. He has been working in C, C++, Java, JavaScript, Golang, Python, Ruby, etc. Nowadays, he is working with cloud computing related technologies, specially with Kubernetes.Intrigued about where his inspiration has come from, we decided to grill Daniel on getting young people into coding, the appeal of programmer humour, and why programming and creativity aren’t so far apart after all…Q: How did you get involved with the #OpenErlang campaign?A: I received a message from Erlang Solutions Team to be part of #OpenErlang party in the last year. Initially, the idea was to do some live drawing at the party, but I had some health issues at that time, so we decided to do a kind of remote live drawing instead. From there, we continued collaborating. Q: Why did you agree to get onboard with #OpenErlang?A: Because of the 3G: Great people, Great community and Great technology.  Q: Why do you like Erlang?A: I never had a chance to work in an Erlang project but I have studied it a lot in the last years. I think that Erlang is wonderful because you need to think in distributed systems from the very beginning. Q: What is your programming language of choice and why?A: I’ve worked as a software developer for 20 years, my primary language in the last few years was Java. Today I am more involved with devops tools, primary with Kubernetes. So golang and Javascript (nodejs) are my favourite languages nowadays. Q: Many would think the programming/developer industry is very mathematical, and it is, but how is it also creative?A: I think the industry has always demanded creativity over time, but with different approaches. In the past, the problem was less complex but the resources were very limited. Today we face more complex problems, but we have tons of ways to solve them.Q: How would you describe the creativity in programming? It’s like a blank canvas, right?A: I think it’s hard to describe creativity. Maybe this subject deserves a comic ;) I think there is not a rational path to creativity, it’s more about inspiration.Q: What came first for you, the illustrations or the programming?A: When I was a little kid, I used to do cartoons with my family, so I think drawing comes first. I started to play with code when I was 12, 13 yo.Q: Where do you get your ideas from?A: I’ve worked in the industry in the last 23 years. The day-to-day running of the enterprise world is an endless source of ideas. Also the community itself, the online forums. We have a very controversial community.Q: In what way controversial?You know, we have a very passionate community, I think. People are used to defending their os, language, framework or technology like their family. In this scenario, it’s kind of easy to create jokes, because jokes always target a group. Q: Has any idea gone awry?A: Not a specific idea. Sometimes people think I am a kind of misogynistic person because I don’t put girls on my comics. The reality is that I really find it difficult to draw women! I also have difficulties to draw people looking to the left, so I use to draw them looking to the right and I swap it using the software.Q: How do you deal with accommodating all programming languages? What sort of issues have you come across in the past?A: I know that is cliché, but I really believe that different programming languages solve different problems. Erlang/Elixir is the first thing that came in mind for high scalable/resilient software. For classic enterprise software, maybe Java / c#. If you need to build easy to deploy tools for DevOps world, maybe Golang or Python. For web apps, Ruby, Node, etc. I know that these languages can solve other problems, but they work bet" <> ..., title: "Q&A with Programmer and #OpenErlang Illustrator Daniel Stori", url: "https://www.erlang-solutions.com/blog/q-a-with-programmer-and-openerlang-illustrator-daniel-stori.html"}
%{author: "by Erlang Solutions", text: "Let's #TalkConcurrency with Sir Tony Hoare2019-01-24\n        by Erlang Solutions\n      Back in November, we took a trip to Cambridge University with Francesco Cesarini to arrange a panel discussion revolving around concurrency. For the panel, we enlisted the help from the best; Sir Tony Hoare, Joe Armstrong, and Carl Hewitt! All pioneers in the concurrency field.What followed was a fantastic discussion about how concurrency models have developed, and where they will be heading in the future. We also interviewed Sir Tony Hoare personally about his work with concurrency that has spanned across 50+ years. Take a look for yourself!About Sir Tony HoareComputer scientist Sir Tony Hoare FRS FREng is well-known for developing the sorting algorithm Quicksort in 1959/1960, which is a systematic method for placing the elements of an array in order. It is the most commonly used algorithm for sorting due to its speed, especially when compared with its related competitors. Quicksort is a comparison sort and sometimes referred to as “partition-exchange sort”.  In addition to Quicksort, Sir Tony has a list of other achievements under his belt; Quickselect, Hoare logic, Communicating Sequential Processes and Structured programming to name a few. In addition, he has won numerous awards and honours based on his brilliant work within the Computer Science field! This includes SIX Honourary Doctorates over the years and his Knighthood back in 2000. He is now the principal researcher at Microsoft Research in Cambridge and Emeritus Professor in the Department of Computer Science at Oxford University. [Transcript]Tony Hoare: Hi, I’m Tony Hoare. I’m an honorary member of the Cambridge University Computing Laboratory, where this interview is being recorded.I’d like to tell you something about how I got interested in concurrency as a subject from our research, and what the influences were in the development of my thinking about this subject.In 1960, I got my first job as a programmer in a small computer manufacturer and led a small team towards the implementation of a programming language - a new programming language at that time called ALGOL 60.\nThe project was successfully delivered. After that, the company decided that it would need an operating system for its new computer, and I was put in charge of its design and its development.Unfortunately, the operating system, two years later, turned out to be undeliverable. It was just terribly slow. I put the cause of my failure down to the fact that I didn’t understand concurrency. This was one of the motives which led me, in 1968, to change my profession and join a university as professor of computation at the Queen’s University in Belfast.One of the objectives of my research I made was the exploration of what concurrency really meant and how to tame it. In 1965, I had met Ole-Johan Dahl and Kristen Nygaard, who were the designers of a language called Simula 67, which had an enormous influence on the propagation of ideas of object-oriented programming, and it impressed me greatly.\nThey had a concept of timing which was implemented as a simulated time train in the way that is completely standard nowadays. That gives a framework within which one could explore the meaning of real concurrency.After I had joined the Queen’s University Belfast, I teamed up with a colleague, Jim Welsh, to design a new version of Pascal; a language which is then current for implementation of compilers and other software, to design a new version which would import some part of the class structure of Simula 67. It was called Pascal Plus. Jim Welsh wrote its compiler and tested it and delivered it. It’s rather a splendid exercise because he only ever found one fault. He found one fault in the compiler that he’d written. It was a no-reference fault. Otherwise, he had implemented the language completely from its specification without testing it, any part of the implementation, before putting it all together and compiling it.The only other Pascal compiler that was in existence at that time produced a running compiler, which we used" <> ..., title: "Let's #TalkConcurrency with Sir Tony Hoare", url: "https://www.erlang-solutions.com/blog/let-s-talkconcurrency-with-sir-tony-hoare.html"}
%{author: "by Erlang Solutions", text: "Let's #TalkConcurrency with Joe Armstrong 2019-01-30\n        by Erlang Solutions\n      We launched our #TalkConcurrency campaign last week with a fantastic interview with one of the founding fathers of concurrency; Sir Tony Hoare. This week we continue with the co-creator of Erlang, Joe Armstrong, as he walks us through his experiences with concurrency since 1985. In the mid 80s, whilst working at the Ericsson Computer Science laboratory, Joe and his colleagues were looking for an approach to developing fault-tolerant and scalable systems.  This resulted in the Erlang style concurrency as we know it today. During our visit to Cambridge University’s Department of Computer Science, we asked Joe, Tony, and Carl to discuss their experiences of concurrent systems and the future direction of concurrent software development.The panel discussion will follow, but for now, here is an insightful discussion about how concurrency models have developed, and where they will be heading in the future with Joe Armstrong.About Joe ArmstrongJoe made his name by co-creating Erlang alongside Robert Virding and Mike Williams in the 1980s at the Ericsson Computer Science Labs. Before that, he was debugging programs in exchange for beer whilst studying at University College London. He later received a Ph. D. in computer science from the Royal Institute of Technology (KTH) in Stockholm, Sweden in 2003. Joe is the author of a number of key books on the topic of Erlang and beyond this including Concurrent Programming in Erlang, Programming Erlang: Software for a Concurrent World and Coders At Work.You can read and watch more about Joe’s Erlang journey via our #OpenErlang campaign. [Transcript]Joe Armstrong: My name is Joe Armstrong. I’m here to tell you about a style of concurrent programming that we evolved from about 1985. My introduction to this was when I started working at Ericsson and I got the problem of trying to figure out how to build a fault-tolerant system. At the time, Ericsson built large telephone exchanges that had hundreds of thousands of users, and a key requirement in building these systems was that they should never go down. In other words, they had to be completely fault-tolerant.There was actually a fairly long history of this. Ericsson started building systems like this in about 1974, in the mid ‘70s. By the time I came along, which was around about 1985, they were a world-leading manufacturer of large fault-tolerant systems. I got a job in the computer science lab to see how we could program these systems in the future.Initially, I wasn’t really interested in concurrency as such, I was interested in how you make fault-tolerant systems. A characteristic of these systems were that they handle hundreds of thousands of telephone calls at the same time. If you imagine a system that has 100,000 subscribers talking to each other, you could view this as being 50,000 pairs of people talking to each other.Obviously, there is concurrency in the way the problem is set up. If we have 100,000 people using a telephone exchange, we have 100,000 parallel activities going on. The natural way to model this is with 100,000 processes grouped into pairs. That’s 100,000 people talking, it’s 50,000 pairs of two people. It seemed a natural way to describe this.There was also a tradition of doing this using multiple processes. The system that I first looked at or the one that was being used in Ericsson consisted of two processors. One with an active processor that was doing all the work, the second was a standby processor that immediately took over if the first processor failed. This was the starting point. That was back in 1985. We were in a computer science lab and I started trying to describe this in a number of different programming languages. There was a multi-programming language project to try and model this in different languages.Sooner or later, I stumbled upon Smalltalk. The way that Smalltalk described things in terms of objects and messages seemed very good, but it wasn’t a true type of concurrency I was interested in. The problem with Sm" <> ..., title: "Let's #TalkConcurrency with Joe Armstrong ", url: "https://www.erlang-solutions.com/blog/let-s-talkconcurrency-with-joe-armstrong.html"}
%{author: "by Erlang Solutions", text: "Let's #TalkConcurrency with Carl Hewitt2019-02-07\n        by Erlang Solutions\n      The last in our trio of concurrency one-on-one interviews is Carl Hewitt; the designer of logic programming language Planner. Also known for Actor models, Carl does a fantastic job of describing how he and others came up with Planner, and where he feels concurrency will go from here.About Carl HewittCarl has been highly influential in the development of logic, functional and concurrent programming, with his most recognisable work being the Planner (logic programming language) as well as his work on the Actor model of computation.During his educational years, Carl was at MIT (Massachusetts Institute of Technology), which is famed for its work with science, computing and engineering. Here, he gained his PhD in applied mathematics in 1971 and then continued to work for the Department of Electrical Engineering and Computer Science until 2000 when he became emeritus. Below is an edited transcript of Carl’s #TalkConcurrency video…[Transcript]Carl: My name is Carl Hewitt. I originally got started at the MIT Artificial Intelligence Laboratory with professors Marvin Minsky, Seymour Papert, and Mike Patterson, graduate students Terry Winograd and Gerry Sussman and Eugene Charniak, and all the hackers. We were very excited about the field, and I needed a thesis topic. I went to talk to Marvin about my bad ideas and he would say, “Well, I’ve always been interested in plans, assertions, and goals”. Then I went to my office to work some more. When I went back to talk more about my bad ideas, he said, \"I’m kind of interested in plans, and assertions, and goals”. Then it occurred to me that, by golly, I can make a programming language based on plans, assertions and goals which would be much more high level than LISP. So I designed Planner, which was used by Terry Winograd in his famous blocks world SHRDLU demo. We thought that we had really made some progress until we discovered all the things that Planner couldn’t do because of the PDP-10 was such a tiny sequential machine.A number of ideas were floating around for new computational models. For example, there were Petri nets and capability systems. I knew that Planner was inadequate and was working on extensions to add concurrency. In November 1972, Alan Kay gave a seminar at MIT about his new Smalltalk 71 programming language, which made use of message passing. To somehow unify all these disparate models of computation, we had a eureka moment that, \"We can unify all of these things into one concept, namely, that of an Actor. Actors can do all of digital computation. There’s just one fundamental abstraction, one fundamental primitive idea. If Actors can be done right, it’s going to be enormously important because it’ll enable integration between large numbers of machines to communicate with each other as well as providing enormous concurrency on a single machine.It has taken an enormous amount of time to figure out precisely what an Actor is and how to make Actors performant. Now that we can create the hardware to make these gazillions of Actors perform, we can create Scalable Intelligent Systems for the first time in history.  Creating such systems was the dream that attracted us to the MIT Al Lab. It was the dream of Marvin Minsky, Allen Newell, Herbert Simon, John McCarthy. Unfortunately, they didn’t live to see it.The funny thing is, they thought the task was to make an artificial human. Turing proposed this in his Turing test. We can’t do that for quite a while, but we can make Scalable Intelligent Systems for doing things like pain management, and a whole bunch of other things, that are scalable in the sense that they’re not bounded in any important dimensions. There are no hard barriers to improvement.For the first time in history, using massive concurrency and things like Actors, we can create Scalable Intelligent Systems for important human endeavours. It’s been a long journey of developing these kinds of systems. Developing technology for massive inconsistency robust ontologies was necessary b" <> ..., title: "Let's #TalkConcurrency with Carl Hewitt", url: "https://www.erlang-solutions.com/blog/let-s-talkconcurrency-with-carl-hewitt.html"}
%{author: "by Erlang Solutions", text: "10 Unusual Blockchain Use Cases2019-03-11\n        by Erlang Solutions\n      Digital assets have increased in the last few years, and the FinTech industry is set to continue growing throughout 2019. Blockchain obviously falls into this category, with Bitcoin and Ethereum. Crypto startups and established companies are looking to develop their business strategies by incorporating FinTech. By allowing transparency on the ledger, this offers more secure online transactions, which are increasing at a rapid rate. But what unusual blockchain cases have been emerging, in this blog post we will explore some cases that caught our eye. It’s safe to say blockchain’s transparency and accountability is a huge factor and can lend itself to a number of industries in unusual and impressive ways. Here, we look through how:1 Reducing Identity TheftForbes magazine states that 2.6 BILLION records were lost or stolen in 2017, and identified that theft accounts for 69% of all data breaches. Using blockchain to protect records offers a new level of security in the form of identification checks such as verifiable user IDs and multi-factor authentication. This means the need for countless passwords and usernames you’ll evitably end up forgetting is redundant. The Civic’s Secure Identity Platform (SIP) is the perfect example of this. The entire blockchain is decentralised, meaning there is no point of weakness and therefore a very limited chance of hackers breaking in. This includes the self-sovereign IDs as mentioned and the removal of countless passwords and paperwork connected to accounts. The result is a single key that is matched to an immutable ledger. \nYour digital ID can include social security information, social media data, and medical records, but also all the private data you gather from online actions. 2 Buying virtual cats and gamingBlockchain can be used in gaming in general by creating digital and analog gaming experiences. Cryptokitties emerged in 2017 and generated more than $1.3 million in approximately one month. By March 2018, it had raised $12 million. What’s the point? It utilises a game into an economy. By investing in CryptoKitties, players can invest, build and extend their gaming experience. BitPainting is another example where you can create and share your digital art in the form of “crypto-collectables”. A third example is a gaming platform called Chimaera that converts gaming into virtual assets to allow developers to manage, share and trade their games. 3 CannabisLegal cannabis is a booming business in the United States with an estimated $9 billion dollars spent in 2017. This estimate is set to grow, no pun intended. With this amount of money, a cashless solution could offer business owners further security. Transactions are easily trackable and offer transparency and accountability that traditional banking doesn’t. The link between cryptocurrencies and cannabis isn’t a new revelation; it has been used in the industry for a number of years. Cryptocurrencies have been created including PotCoin, DopeCoin, and ParagonCoin. However, none have fully reached their potential.There are some key differences between why blockchain would be more appropriate for the cannabis trade than cryptocurrencies, and this is similar to traditional banking. Campaignlive sums it up perfectly here: “By integrating blockchain into supply chain management, business owners could provide legislators, consumers, and banks with the data they need to build what they need to gain mainstream acceptance: trust.”Transparency is a key benefit to using blockchain within the cannabis industry. But what other advantages does it hold?Blockchain offers anonymity. As legal cannabis is still a fairly new industry, stepping towards the edge of caution is sensible business acumen. Secondly, the tax put in place for legal marijuana in the US can be crippling to small businesses. The account fee for cannabis in California can be up to $60,000 per annum. Blockchain results in less tax because the individual will be taxed as property, not currency. Thirdly, many cann" <> ..., title: "10 Unusual Blockchain Use Cases", url: "https://www.erlang-solutions.com/blog/10-unusual-blockchain-use-cases.html"}
%{author: "by Erlang Solutions", text: "Let's #TalkConcurrency panel discussion with Sir Tony Hoare, Joe Armstrong, and Carl Hewitt 2019-02-19\n        by Erlang Solutions\n      When considering the panel to discuss concurrency, you’d be pushed to find a higher calibre than Sir Tony Hoare, Joe Armstrong, and Carl Hewitt. All greats within the industry and beyond, over the past couple of weeks, we’ve been releasing their individual interviews; a storyboard into the lifeline of concurrency and models over the past few decades. Here we have the full panel discussion, hosted by Francesco Cesarini, about their experience in the concurrency field, and where they see concurrency heading in the future. [Full Panel Discussion Transcript]QU 1 - What problems were you trying to solve when you created actors concurrent sequential processes and the Erlang type of concurrency respectively?Francesco Cesarini: Concurrent programming has been around for decades. Concurrency is when your multiple events, your code snippets or programs are perceived to be executing at the same time. Unlike imperative languages, which uses routines or object-oriented languages, which use objects. Concurrency oriented languages use processes, actors, agents as the main building blocks.Whilst these concurrency foundations have remained the same and stable, the problems we’re solving today in the computer science world have changed a lot compared to when these concepts were originally put together in the ‘70s and '80s. Back then, there was no IoT. There was no web, there were no massive multi-user online games, video streaming, and automated trading or online transactions. The internet has changed it all and in doing so with these changes; it has helped propel concurrency into future mainstream languages.\nToday we’re very fortunate to have Professor Tony Hoare, Professor Carl Hewitt and Dr. Joe Armstrong; three visionaries who in the '70s and '80s helped lay the foundations to the most widely spread concurrency models as we know them today. So, welcome and thank you for being here.Interviewees: Thank you.Francesco: The first question I’d like to ask is, what problems we’re trying to solve when you created actors, concurrent sequential processes and the earliest type of concurrency respectively?Carl Hewitt: I think the biggest thing that we had was, we had some early success with Planner, right? There were these capability systems running around, there was functional programming running around. The most important realisation we came to was that logic programming and functional programming couldn’t do the kind of concurrency that needed to be done.Joe Armstrong: You’re right.Carl: At the same time, we realised it was possible to unify all these things together so that the functional programs and logic programs, all these digital things were special cases of just one concept for modeling digital computation, you can get by with just one fundamental concept and that was the real thing. Of course, we thought, “Well, there’s plenty of parallelisms out there, there are all these machines, we’ll make this work.”\nThe hardware just wasn’t there at the time and the software wasn’t there at the time but now we’re moving into a realm of having tens of thousands of cores on one chip and these aren’t wimpy GPU cores. These are the real things with extremely low latencies among them, so we’ll be able to achieve latencies between actors passing messages in the order of 10 nanoseconds with good engineering and we’re going to need that for the new class of applications that we’re going to be doing, which is scalable intelligent systems. There’s now this enormous technology race on.Francesco: What inspired CSP?Tony Hoare: It was the promise of the microprocessor. The microprocessors were then fairly small and they all had rather small stores and they weren’t connected to each other but people were talking about connecting large numbers of microprocessors mainly in order to get the requisite speed. I based CSP design on what would be efficient, controllable and reliable programming for distributed systems of that kind. S" <> ..., title: "Let's #TalkConcurrency panel discussion with Sir Tony Hoare, Joe Armstrong, and Carl Hewitt ", url: "https://www.erlang-solutions.com/blog/let-s-talkconcurrency-panel-discussion-with-sir-tony-hoare-joe-armstrong-and-carl-hewitt.html"}
%{author: "by Piotr Nosek, Mateusz Bartkowiak", text: "MongooseIM 3.3.0: Supporting happy relations2019-03-13\n        by Piotr Nosek, Mateusz Bartkowiak\n      Have you ever tried to use Mnesia with datasets larger than your transient memory? Are you confused with Erlang data types stored within Mnesia? We know some of you were. That is why we answered these problems by introducing something that is familiar to mainstream developers and also efficient with larger datasets at the same time - i.e. RDBMS backends for our PubSub plugin. Now, lets bundle that up with full support for XEP-0178, as well as, a RabbitMQ backend for our Event Pusher for a more complete package. Ladies and gentlemen welcome MongooseIM version 3.3.0.Relations meet PubSubThe Publish-Subscribe plugin was one of our main focal points for recent weeks thanks to our friends from Safaricom Alpha, who have sponsored this work. The rationale behind implementing it is simple, and yet not obvious, so let’s dig in.The XMPP protocol features an extension called Personal Eventing Protocol which is a special case of PubSub, where any entity (e.g. a user) may become a PubSub node. In turn, this can be used for many purposes. For instance, a client may publish information to its contacts about the music currently being played. Alternatively, it may announce microblog entries (e.g. personal Twitter). Nevertheless, end to end encryption is the thing of importance to us and many of MongooseIM users in regard to PEP.End to end encryption is often a selling point for many pieces of modern IM software. For example, the popular TLS encryption ensures that nobody will be able to eavesdrop on your communication with a bank website. Of course, there are many more properties but the crucial fact remains: it secures the data you exchange with the server. Therefore, when you connect to MongooseIM with TLS enabled your transmission is safe. You have to bear in mind that everything you write is still readable on the server side and if you would like to improve your privacy even further - you need to encrypt your message content as well.There are several protocols you can use to achieve it, but in most cases, you will need a way to announce public data (e.g. public key) that others may use to establish a secure session with your device. This is where PEP comes in. It provides a facility for storage and distribution that can hold, for instance, OMEMO keys and metadata to your contacts.Since this data is retrieved and updated fairly often, we have realised that a classic Mnesia backend is no longer sufficient for this purpose and we have put a lot of work into developing an efficient RDBMS backend for PubSub. Besides performance in high volume scenarios, it allows developers to use databases other than Mnesia, ones they are more familiar with.During the development, we have been also able to pinpoint bottlenecks in the core PubSub code. That is why we have the parallelised distribution of PubSub messages.The pre-3.3 extension used only a single Erlang process to handle all requests, as well as, the broadcasts triggered by them. Currently, the notification distribution is done by a new, short-lived process for every request. Requests themselves are still processed in a single queue - since parallel execution led to transaction deadlocks in Mnesia - but the extension may be configured to process them in several queues. That fixes the issue we have observed on several occasions, where the PubSub process was simply overwhelmed with messages with no reasonable overflow control and back pressure what greatly impaired user experience.Standardised PKIPassword-based authentication is still a basic method in many places. Why? Try remembering your RSA 4096-bit public key, not to mention the whole public+private key pair. (yes, we know about Keepass; but you most probably have it configured to use a master password, right?)The PKI authentication is the current industry standard though. It is more secure than a private-public key pair and, if implemented properly, much more convenient for the average user to use. Support for this method debuted in Mo" <> ..., title: "MongooseIM 3.3.0: Supporting happy relations", url: "https://www.erlang-solutions.com/blog/mongooseim-3-3-0-supporting-happy-relations.html"}
%{author: "by Bartosz Szafran", text: "Rabbit’s Anatomy - Understanding Topic Exchanges2019-03-20\n        by Bartosz Szafran\n      Topic Exchange Intro/OverviewIn RabbitMQ Exchange is the abstraction, where messages are published to. There are a few types of Exchanges, where Topic Exchange is one of them. Topic Exchange provides most flexible routing mechanisms. It depends on the Binding Key, which is provided when queue is bound to a Topic Exchange. It is kind of a pattern, which is used to make decision on routing messages by checking if a message’s Routing Key matches the pattern.A Routing Key is made up of words separated by dots, e.g.: floor_1.bedroom.temperature. The Binding Key for Topic Exchanges is similar to Routing Key, however there are two special characters, namely asterisk * and hash #. These are wildcards, allowing to create a binding in a smarter way. Asterisk * matches any single word and # matches zero or more words. Here are examples of patterns to match on messages from: - all devices on first floor in bedroom: floor_1.bedroom.*, - all devices on first floor floor_1.#.\nIt is clearly visible Topic Exchange allows to greatly simplify the routing, allowing to match only. TrieTo understand how a Topic Exchange works, the trie data structure has to be introduced. It is a tree, which holds ordered data. Typically it is used for storing string values. Each node in the tree represents a prefix of a string and holds links to child nodes, which share the same prefix. The child nodes are addressed with the next character following the prefix for the node.Such a data structure makes searching for specific strings independent of the structure’s size. The characters of string are used to traverse the tree while searching it.\nThe trie is used for storing Binding Keys in Topic Exchange. A Binding Key is split by dots and all string parts are used as pointers to the next node. So, each time when new binding is added to the Topic Exchange, the trie associated with it is updated. And each time when new message has to be routed, the trie is queried to look for the message’s destinations.Implementation of the trieTopic Exchange trie is implemented on the top of Mnesia. Nodes and edges of trie are stored in respectively rabbit_topic_trie_node and rabbit_topic_trie_edge tables.#topic_trie_node{\n    trie_node = #trie_node{\n        exchange_name,\n        node_id\n    },\n    edge_count,\n    binding_count\n}\n#topic_trie_edge{\n    trie_edge = #trie_edge{\n        exchange_name,\n        node_id, % parent\n        word\n    },\n    node_id % child\n}\nIn this case, trie_node or trie_edge records are primary keys used to identify records.\nBoth nodes and edges are assigned to one particular Topic Exchange by specifying exchange_name field in primary key. Nodes are also used to identify bindings, which should be used, they are not stored directly in the node’s table, but they can be easily obtained by node_id from rabbit_topic_trie_binding table. Edges store information about connections between parent and child nodes. Edges also contain the part of the Binding Key (word), which is used to traverse the tree.\nTherefore, traversing through the tree requires a sequence of Mnesia queries. Reading edges and nodes is done using dirty operations.Topic Exchange internalsA Exchange type is created by implementing the rabbit_exchange behaviour. In the context of tries in Topic Exchange, two operations are interesting. Namely, it is add_binding/3 and route/2, where first implements adding new binding to the structure and the latter is used to determine target for routing.Binding OperationThe arguments needed to create the binding are:- source Exchange- Binding Key- destination\nEvery trie starts with the root node, representing the empty Binding Key. It actually makes sense, as empty string is a prefix for any string.\nFirst operation is pretty straightforward - Binding Key has to be split by dots . and it is stored in a list. For example the key “a.b.c” is transformed to [“a”, “b”, “c”]. Let’s call the list Words for later. It will be used for traversing the data structure.\nThen, recursivel" <> ..., title: "Rabbit’s Anatomy - Understanding Topic Exchanges", url: "https://www.erlang-solutions.com/blog/rabbit-s-anatomy-understanding-topic-exchanges.html"}
%{author: "by Simon Benitez", text: "ex_rabbit_pool open source AMQP connection pool2019-04-02\n        by Simon Benitez\n      BackgroundA couple of months ago we started writing an open-source continuous delivery system which we called Buildex.Buildex is implemented as a collection of microservices which:- Monitor Github repositories - Respond to changes by sending notifications over AMQP (RabbitMQ)- Trigger software builds running in Docker containers- Expose credentials (SSH keys) to containers as volume mounts.\nBuildex was born of the frustrations and limitations we faced when attempting to debug production failures in other build systems. Buildex was also influenced by security, privacy, and pricing concerns we encountered while using some of the popular commercial SaaS offerings.Buildex Component overviewThe principal components of Buildex are: The Poller, which uses the excellent Tentacat Github API to poll GitHub for new tags, the Builder, which checks out and builds the project inside Docker containers, and the Datastore which uses ueberauth OAuth to delegate authorization to Github, and allows users to configure projects for the continuous integration pipeline.The following diagram provides a high-level overview of the Buildex micro-services and supporting infrastructure.Although we could have used distributed Erlang for everything, we wanted to have the ability for operations and develops to easily monitor inter-service communication and define message replication as they pleased, for example with logging or integration with 3rd party services (email, auditing, manually triggering builds, etc). We decided to use RabbitMQ for inter-service communication, which in turn led to our need for a higher level connection handling and channel management library.ex_rabbit_poolAs part of the work to support these services, we created a RabbitMQ connection management and pooling library called ex_rabbit_pool. ex_rabbit_pool is built upon the Elixir library AMQP which is an Elixir wrapper for the RabbitMQ client rabbitmq-erlang-client, and the Erlang resource pooling library poolboy. In this post, we will take you through the lessons learnt and steps taken to implement ex_rabbit_pool, but first, a quick explanation of channels and connections.Channels and connectionsConnections, as in TCP connections, to RabbitMQ, are expensive to create and a finite system resource, Channels, are a lightweight abstraction over connections. Quoting the RabbitMQ documentation, “AMQP 0-9-1 connections are multiplexed with channels that can be thought of as ‘lightweight connections that share a single TCP connection’”.In the Erlang world, you will typically assign a channel per worker process, on other platforms you would assign a channel per-thread.Basic steps involved in using AMQPOpen a connection\n{:ok, connection} =  AMQP.Connection.open(host: \"localhost\", port: 5672)\nOpen a channel with that connection\n{:ok, channel} = AMQP.Channel.open(connection)\nBind the channel to a queue via an exchange\nAMQP.Queue.bind(channel, \"test_queue\", \"test_exchange\")\n(Listening) Subscribe to the queue\nAMQP.Queue.subscribe (channel, \"test_queue\", fn(payload, meta) -> IO.puts(\"Received: \#{payload}\") end)\n(Sending) Publish message to queue\nAMQP.Basic.publish(channel, \"test_exchange\", \"\", \"Hello, World!\"\nThe process treeA supervision tree diagram is a good way to get an overview of a BEAM system, so let’s start by examining the supervision tree of ex_rabbit_pool.- PoolSupervisor supervises the ConnectionPool- ConnectionPool manages a collection of ConnectionWorker processes- Each ConnectionWorker manages a RabbitConnection- ConnectionWorker uses the RabbitConnection to create a pool of RabbitChannels \nThe principal components are the PoolSupervisor and RabbitConnection. We will examine the implementation of both components over the course of the following sections.Defining the PoolSupervisorFirst, we define a top-level supervisor, PoolSupervisor, which will be responsible for managing the connection pool. PoolSupervisor is intended to be started within an application so we leave the start-up managemen" <> ..., title: "ex_rabbit_pool open source AMQP connection pool", url: "https://www.erlang-solutions.com/blog/ex_rabbit_pool-open-source-amqp-connection-pool.html"}
%{author: "by Stuart Whitfield", text: "NEWS: Erlang Solutions partners with EMQ2019-04-09\n        by Stuart Whitfield\n      EMQ – the world’s Leading Provider of IoT Messaging and Streaming Platform – and Erlang Solutions – the world’s leading provider of Erlang and Elixir Solutions, sign channel distribution agreement across the USA and Europe.Press Release | San Jose – April 9th 2019  San Jose US, London UK and Hangzhou, China: As IoT continues its explosive growth across the world, from autonomous vehicles to smart home devices, from Smart City Infrastructure to telecom grade IoT solutions, enterprise systems seek a more efficient, secure and faster communication mechanism. Companies are continuously turning to MQTT – and specifically EMQ – for stable enterprise class solutions. And supporting customers on a local basis has become an absolute prerequisite.  “We are delighted to announce this partnership. Our business is growing rapidly and Erlang Solutions possess the architectural and network expertise and additional product solutions that complement our EMQ X broker software solutions perfectly. They have offices all over Europe and presence in the US that will enable us to support our customers with greater efficiency.” - says Feng Lee, CEO and Founder of EMQ.“We have demonstrated that we are the go-to solution for MQTT and the only open source provider to offer full MQTT V.5.0 support. We back that up with world class support and consulting services. Now EMQ and Erlang Solutions experts will be on hand in local geographies to have detailed conversations about solutions, and demonstrate how we can jointly help our customers build massively scalable and secure IoT systems.” - says Dylan Kennedy, VP of Global Operations at EMQ.“We have been following the EMQ X broker since its inception, seeing it go from strength to strength. Alongside our expertise in the XMPP and AMQP, we are delighted to add MQTT to the suite of messaging protocols we officially support.” - says Francesco Cesarini, Founder and Technical Director at Erlang Solutions. “It will allow us to jointly help our customers with the development and deployment of end to end solutions in the IoT space.”  About EMQFounded in 2012, the Hangzhou EMQ Technologies Co., Ltd.’s mission was to create a massively scalable, highly available, MQTT-based message broker using the best tool for the job, the Erlang open source language.  EMQ X Open Source was released in 2013, and is deployed in millions of IoT-connected devices worldwide.EMQ X Enterprise is the commercial version that offers a highly extensible, feature-rich security software suite, as well as world-class support deployed to support tens of millions of devices. EMQ is headquartered in Hangzhou, China, and has offices in Beijing, Frankfurt and Silicon Valley, California. Visit our partner’s website www.emqx.io for further information. To contact the team, email contact@emqx.io or call Dylan Kennedy, SVP of Global Operations,  at +1 (408) 476-1873 email: dylan@emqx.io.About Erlang SolutionsFounded in 1999, Erlang Solutions Ltd. is an international technology company building trusted, fault-tolerant systems that can scale to billions of users. Erlang Solutions offers world-leading consultancy in the Erlang and Elixir - open source programming languages and for a range of leading messaging protocols: AMQP, MQTT and XMPP.With over 80 experts based across London (HQ), Stockholm, Krakow, Budapest and satellite offices in the Americas, Erlang Solutions works with clients ranging from startups to Fortune 500, including WhatsApp, Klarna, Pivotal, Motorola, Toyota Connected, Ericsson and aeternity the blockchain company to mention a few. For more information, visit www.erlang-solutions.com or get in touch with Stuart Whitfield, CEO, at stuart.whitfield@erlang-solutions.com. We thought you might also be interested in:EMQ product pageErlang & Elixir consultancyErlang & Elixir developmentGo back to the blog\n\nTags:Erlang Solutionsemqpartnershippress releaseannouncementShare  Facebook Twitter Linkedin E-mail", title: "NEWS: Erlang Solutions partners with EMQ", url: "https://www.erlang-solutions.com/blog/news-erlang-solutions-partners-with-emq.html"}
%{author: "by Martin Gausby", text: "Thoughts on ElixirConf EU 2019-04-16\n        by Martin Gausby\n      470 Attendees & 30 SpeakersThe fifth annual ElixirConf EU was held this year in Prague, Czech Republic. It saw 470 attendees, and 30 speakers, from all over the world, where the ones that had travelled the furthest came all the way from Australia and New Zealand. I have been to all of the European editions of the conference, and it is nice to see the number of attendees grow. In just a couple of years, we have gone from the size of a major meet-up group to enough people to fill an auditorium! Exciting times. And while I cannot think of a time in the history of Elixir that has not been exciting, I would say that this year was special.New companies adopting ElixirAt this point in time, we have a language that is very stable. It is built on top of one of the most hardened foundations in the industry: The Erlang Virtual Machine. Not only that; the community has a very strong toolset for building large scale applications at their disposal. One could say we have solid answers for building software. That is why many companies and organizations, such as Flyiin; Toyota Connected; Bleacher Report; Vamp, and many more, have adopted Elixir and is now running it in production, and many have done so for a couple of years at this point. The talks reflected this as they covered library design; architectural design; stories of larger systems successfully being partly rewritten and refactored; and solutions to hard problems such as handling millions of messages were shown. All solutions to truly difficult problems.But we did not forget the newcomers to the community. For them, and more experienced community members, we had talks about the functional foundations of the language, its tooling, and various ways of testing Elixir projects. And talks about the practical, yet not so approachable areas of our toolbox, such as Evadne Wu talking about ETS (the Erlang Term Store, a built-in “Redis”-like, in-memory key/value store baked right into the Erlang Runtime System), and a comprehensive guide to what happens when you boot your application by Michał Muskała. Also, Bram Verburg gave a talk about the SSL module, this will become a valuable resource for the community going forward when we seek to secure our network applications.Broadway, Scenic, Telemetry, MQTTWhile the Elixir language itself has been announced to be a stable and feature-complete language, it is important to not stagnate. It is now up to us, the community, to build the extensions we want to see. Right now, besides pushing the boundaries of concurrent data pipelines, as Jose Valim showed in his keynote about Broadway, one of the frontiers is creating graphical applications using the Scenic framework, and we saw a couple of talks exploring this. Tonći Galić showed how far he could get building a GameBoy emulator with Elixir, and our former colleague Ju Liu showed how to implement a classic painting, both with Scenic. Another frontier is the Nerves project which enables us to build embedded hardware solutions using Elixir. The project is going strong, and Paul Wilson gave an inspiring talk about the video solution they use at their office to include their colleagues working remotely, all built with Nerves.Erlang Solutions had two speakers on the program, my colleague Arkadiusz Gil and myself. Arkadiusz announced his Telemetry project, which provides the community with a unified way of getting metrics out of an Elixir application. Personally, I see this as one of the missing pieces in our Elixir toolbox, and I am happy to see a solution that can benefit the entire community. My own talk was about my Tortoise MQTT client. I have given a couple of conference talks before, and I think this was the biggest audience I have ever spoken for. While public speaking can be scary I think the audience made it great. I got some good questions about MQTT and Tortoise, and the conversations I had after the talk in the hall were really good. I would definitely recommend the experience to anyone. It is hard work, but rewarding. Be on" <> ..., title: "Thoughts on ElixirConf EU ", url: "https://www.erlang-solutions.com/blog/thoughts-on-elixirconf-eu.html"}
%{author: "by Francesco Cesarini", text: "Remembering Joe, a Quarter of a Century of Inspiration and Friendship2019-04-23\n        by Francesco Cesarini\n      I first came across the name Joe Armstrong in 1994, when I bought the first edition of Concurrent Programming in Erlang, a book he co-authored. Our first interaction happened in 1995, when I was looking for a company interested in sponsoring my Master’s thesis. I dialled the number for Ellemtel Utvecklings AB, home of the Ericsson computer science laboratory, asking to be connected to Joe Armstrong. Getting a Hello, my unprepared opening line was Skall jag ta det på Engelska, or would you prefer if I took it in Swedish? A silent pause was followed by laughter, the same laughter many of us have come to associate with Joe.Shouting at each other through the wallsInternships at the computer science lab were an immersion in enthusiasm and creativity. The lab had an academic, non conformist, almost anti-establishment, feel to it. Segregated to the corner of the building, pipe and cigarette smoke coming from some of the rooms. I am sure the cleaning staff were asked to “forget” the department existed, or maybe, they did not dare venture in there after hours. ISO 9000 reviews (and office moves) were a conspiracy to get Joe (and Robert) to clean their desks. But what mattered was not how neat your desk was, but the drive to innovate with an aim to further our understanding in computer science. You did not use an existing web server, you wrote your own so as to understand how HTTP worked and suggest improvements and extensions. You did not take Ericsson’s high security for granted, you found your way around firewalls and tried to outsmart the highly paid system administrators. When I got distributed Erlang working between my University and Ericsson UNIX accounts, I asked Joe if this was right. He walked in the hall and laughed loudly. It was his call for a show and tell, sharing knowledge with his curious colleagues who quickly make their way to his office. Sometimes, there was no need to make it there in person. Mike and Robert were always given the office next to his, so they could shout at each other through the walls. Ahead of his timeBrainstorming sessions with Joe were the best. We once spent a good part of an afternoon finding a solution to a problem. I ended up working into the early hours of the morning on the implementation, and indeed, it worked. When Joe walked into the office the following day, he pops his head into my room and says You know the solution we came up with yesterday? Forget about it, it will not work. My jumping up and down saying it does work, it works, here it is, was fruitless. He replied, no, we were wrong, and walked off. He was often ahead of his time, in both thoughts and problems he was solving, and had probably discovered some edge and borderline cases to our solution which was too frivolous to share. This is where you learnt to filter his ideas, take those you understood or believed in and parked those you did not like or understand.    Solution to a problemSometimes, you would be walking outside his office, he would wave you in and share one of his daily epiphanies, hacks or articles and academic papers on a one-on-one basis. One of these hacks happened in conjunction with a major Erlang release in 1995. They had snuck in List Comprehensions and Funs in the language (product management had prioritized other features) and Joe showed me how they allowed you to implement clean and easy to maintain code, hiding recursive patterns and isolating side effects in a single location. Showing me the shortest implementation of QuickSort I had ever seen, he mentions you can solve the Eight Queens problem in six lines of code. I spent two nights trying to figure out a solution in my head, to no avail. Weary of a third sleepless night, I ask Joe for a solution only to be told: I have no idea, I never solved it myself. Look on the internet. WebCrawler and Lycos, whom had been around for a year, failed to provide a solution. Whilst I love Joe to bits, that particular day, I could have strangled h" <> ..., title: "Remembering Joe, a Quarter of a Century of Inspiration and Friendship", url: "https://www.erlang-solutions.com/blog/remembering-joe-a-quarter-of-a-century-of-inspiration-and-friendship.html"}
%{author: "by Arkadiusz Gil", text: "Introducing Telemetry2019-04-30\n        by Arkadiusz Gil\n      We need monitoring“Let it crash” has been a long-running mantra in the BEAM world. While it might be misinterpreted, there is some merit to it - our software will do unexpected things, and more often than not, the only viable choice is to crash and start over. But simply restarting parts of our application is not sufficient - we should understand what was the cause of the error, and handle it properly in the future releases. We also need to know that the error occurred at all and how it affected our customers! To enable both of these things, we need a way to introspect and analyze our app’s behaviour at runtime - we need monitoring.Telemetry is a new open source project aiming at unifying and standardising how the libraries and applications on the BEAM are instrumented and monitored. It is a suite of libraries, developed for the last couple of months by Erlang Solutions in collaboration with the Elixir core team and other contributors. But with existing metrics projects such as exometer and folsom, which have both served the community well over the years, why would we need yet another solution? It might start to feel like in the popular comic strip:By design, Telemetry does not try to cover every use case out there. Rather, it provides a small and simple interface for instrumenting your code, and allows anyone to hook into the instrumentation points at runtime. This enables modularity - projects like Ecto or Plug only need to rely on the core library, and engineers building applications can use the data exposed by those libraries for monitoring their systems.Let’s dive a little bit deeper into the rationale behind Telemetry and its design.The tree has fallen in the forest..At the core of Telemetry lies the event. The event indicates that something has happened: an HTTP request was accepted, a database query returned a result, or the user has signed in. Each event can have many handlers attached to it, each performing a specific action when the event is published. For example, an event handler might update a metric, log some data, or  enrich a context of distributed trace.This becomes extremely convenient when libraries emit Telemetry events. Usually, we don’t write our own web framework or database client, we use an existing package. The library can provide the instrumentation data via events, and our code can handle it in a way that suits our needs. The only thing we need to do is to implement the handlers and attach them when our application starts!For example, Ecto since version 3.0.0 publishes an event on each database query. We could write a handler which logs whenever a total query time exceeds 500ms:defmodule MyApp.Monitoring do\n  require Logger\n\n  def log_slow_queries(_event, measurements, metadata, _config) do\n    if System.convert_time_unit(measurements.total_time, :native, :millisecond) > 500 do\n      Logger.warn(\"Query \#{inspect(metadata.query)} completed in \#{measurements.total_time}ms\")\n    end\n  end\nEnd\nHere measurements and metadata are properties of a single event - each Telemetry event carries these values.This handler needs to be attached at runtime, for example when our application starts. Assuming that our Ecto repo is called MyApp.Repo, we attach the handler using the code below::telemetry.attach(\n  \"slow-query-logger\",\n  [:my_app, :repo, :query],\n  &MyApp.Monitoring.log_slow_queries/4,\n  :no_config\n  )\nWe specify the name of our handler (which needs to be unique across the system), the event we are attaching it to, the function to be invoked  each time  the event is emitted, and the handler config  which is passed as the last argument to our handler on every invocation...and there was no one around to hear itBecause Telemetry is designed to have a small performance footprint, there is almost no cost associated with including it even in the most popular Elixir libraries - it is already used by Ecto and Plug, and it is coming to Phoenix soon. Telemetry requires only a single ETS lookup when an event is published, and all handlers are execut" <> ..., title: "Introducing Telemetry", url: "https://www.erlang-solutions.com/blog/introducing-telemetry.html"}
%{author: "by Dominic Perini", text: "Blockchain No Brainer Ownership in the Digital Era2019-05-28\n        by Dominic Perini\n      IntroductionSeven months of intense activity have passed since the release of Blockchain 2018 Myth vs. Reality article. As a follow-up to that blog post, I would like to take the opportunity to analyse in further detail the impact that this new technology has on our perceptions of asset ownership and value, how we are continuously exploring new forms of transactional automation and then conclude with the challenge to deliver safe and fair governance. Since the topic to cover is vast, I have decided to divide it into two separate blog posts, the first of which will cover how the meaning and perception of ownership is changing, while the second will discuss how Smart Contract automation can help deliver safe, fair, fast, low-cost, transparent and auditable transactional interoperability.My intention is to provide an abstract and accessible summary that describes the state-of-the-art of blockchain technology and what motivations have led us to the current development stage. While these posts will not focus on future innovation, they will serve as a prelude to more bold publications I intend to release in the future.Digital Asset Ownership, Provenance and HandlingHow we value Digital vs. Physical AssetsIn order to understand how the notion of ownership is currently perceived in society, I propose to briefly analyse the journey that has brought us to the present stage and the factors which have contributed to the evolution of our perceptions. Historically people have been predominantly inclined to own and trade physical objects. This is probably best explained by the fact that physical objects stimulate our senses and don’t require the capacity to abstract, as opposed to services for instance. Ownership was usually synonymous with possession.Let us try to break down and extract the fundamentals of the economy of physical goods: \nwe originally came to this world and nothing was owned by anyone; possession by individuals then gave rise to ownership ‘rights’ (obtained through the expenditure of labour - finding or creating possessions); later we formed organisations that exercised territorial control and supported the notion of ownership (via norms and mores that evolved into legal frameworks), as a form of protection of physical goods. Land and raw materials are the building blocks of this aspect of our economy.When we trade (buy or sell) commodities or other physical goods, what we own is a combination of the raw material, which comes with a limited supply, plus the human/machine work required to transform it to make it ready to be used and/or consumed. Value was historically based on a combination of the inherent worth of the resource (scarcity being a proxy) plus the cost of the work required to transform that resource into an asset. Special asset classes (e.g. art) soon emerged where value was related to intangible factors such as provenance, fashion, skill (as opposed to the quantum of labour) etc.We can observe that even physical goods contain an abstract element: the design, the capacity to model it, package it and make it appealing to the owners or consumers.In comparison, digital assets have a stronger element of abstraction which defines their value, while their physical element is often negligible and replaceable (e.g. software can be stored on disk, transferred or printed). These types of assets typically stimulate our intellect and imagination, as our senses get activated via a form of rendering which can be visual, acoustic or tactile. Documents, paintings, photos, sculptures and music notations have historical equivalents that predate any form of electrically-based analog or digital representations.The peculiarity of digital goods is that they can be copied exactly at very low cost: for example, they can be easily reproduced in multiple representations on heterogeneous physical platforms or substrates thanks to the discrete nature in which we store them (using a simplified binary format). The perceivable form can be recon" <> ..., title: "Blockchain No Brainer Ownership in the Digital Era", url: "https://www.erlang-solutions.com/blog/blockchain-no-brainer-ownership-in-the-digital-era.html"}
%{author: "by Gabor Olah", text: "A guide to tracing in Elixir!2019-06-06\n        by Gabor Olah\n      Greetings! I’m Gabor, an Erlang programmer. I like tracing, and I use it whenever I need it. When I started working with Elixir, I asked the obvious question, how do I do tracing in Elixir-land? The Elixir community have improved the user experience for so many things (mix vs pre-rebar3, macros vs parse-transforms, etc, etc, ad-infinitum). Naturally, I was looking forward to using all the great tools for tracing in Elixir. Although there are some good tools, namely Rexbug and Tracer, I was a bit surprised to see that there is very little talk about tracing. I couldn’t find all the great blog posts, tutorials explaining the battle stories, and the wonders of tracing. There are some, but this powerful feature of the BEAM virtual machine seems to be somewhat underrepresented in the Elixir community.In this blog post, I will discuss “what is tracing”, and “when is it appropriate to use tracing?” and provide a high-level overview of the available tracing tools for the BEAM.What is tracing?Tracing is defined by Wikipedia as the following: “tracing involves a specialised use of logging to record information about a program’s execution.” This definition is not only useful but also provides an idea of where tracing fits in the spectrum of logging and debugging. Logging is an invaluable tool to see what is happening in our system, it can give insights to errors and bugs. But this narrow definition has a big flaw, the places where we choose to emit log messages are hard-coded into our program logic. Choosing where to insert log messages is entirely subjective, dependent upon assumptions and prior experience. Some of the time the logging statement is inserted into a useful location, but if not, you will have to recompile your code and insert extra log statements, this can be a very tedious activity (and is the norm in the vast majority of computer languages). In the pathological scenario, gratuitous use of log statements can even become a significant drain on system IO (process 500 records, generate 50000 lines of logging statements).Logging can be useful in order to explain what the system is doing, but is less helpful for understanding system behaviour in an unexpected failure state.At the other end of the spectrum is debugging with the traditional step-by-step debugger such as the GNU debugger (gdb). This requires no modification of your code, we observe the program as it executes and the data as it evolves one step at a time. This is a fine way to observe how an algorithm works or how a data structure changes. But it is very problematic in a distributed system because many operations are handled by transient processes with short timeouts, taking a single example, gen_server has a call timeout of 5000 milliseconds, and there are very few Elixir or Erlang systems which are not making significant use of OTP to implement system functionality.The key here is observing the system while it is working without stopping the world. Does that sound impossible?Here comes tracing to the rescue. Tracing is a window through which we can observe the machinations of the system. Starting with top-level function calls and message passing with configurable stack traces, right the way through to monitoring the behaviour of the scheduler, port interaction, and garbage collection. In this regard, tracing is very close to a step-by-step debugger, but it turns the debugging steps into a stream of log messages which we can analyse at our leisure in order to determine what was happening in the system at a given point in time.MythsIf you have good monitoring, then you don’t need tracing.Let us assume that diligent monitoring is already in place. Tracing is by no means a substitute for logging. But monitoring has the same problems as logging. If you know beforehand what are the parts to monitor for every possible event, then you will probably never need tracing. But for any sufficiently complex application, you cannot monitor everything. So there will be many parts of the system, which are n" <> ..., title: "A guide to tracing in Elixir!", url: "https://www.erlang-solutions.com/blog/a-guide-to-tracing-in-elixir.html"}
%{author: "by Mark Cowan", text: "The problem of connecting to Smart Meters was solved 30 years ago! Powered by scalable technology.2019-06-18\n        by Mark Cowan\n      Electricity Utilities around the globe are starting to undergo a radical transformation to address a range of economic, environmental and technical challenges. Global drivers for change are rising emissions, domestic energy resource constraints, growing demand for electricity, financing constraints for new generation assets development, cost of electricity, and ageing infrastructure. In addition, the increasing prominence of electric vehicles (EVs) and battery storage at end-users is underlining the need for a sophisticated grid.Key to understanding the smart grid is smart metering. According to GlobalData, global smart meter installations were 88.2 million in 2017, and these are expected to grow to over 588 million units installed in 2022. China has led the market with 406.9 million smart meter installations to the end of 2017, the US and Japan followed with 38.7 million and 36.5 million smart meters installation respectively. The total number of data messages may be low today, but as the smart grid continues to roll out, systems will need to scale to billions of messages and be fault tolerant. For instance, each meter will need to be provisioned onto the system, it needs to link with billing, control platforms, data analysis and more. \nWe’re only just beginning to imagine how this data can be used to enable new innovations in the industry. The future of smart meters could empower and transform sustainability, healthcare and peer-to-peer power sharing. Luckily, the problem of how to connect and control billions of devices was solved 30 years ago in the 1980s by the team at Ericsson who developed Erlang.  It’s a language that was built specifically for fault-tolerance, high availability and concurrently running for critical systems. \nWhile it was built for the telecommunications industry, it’s now used across a range of industry leaders in betting, health, advertising, online gaming, anywhere that high availability and fault-tolerance is pivotal.   Erlang’s concurrency, its no-shared memory architecture and built-in ‘fail and recover’ approach makes it behave extremely gracefully and predictably under highly variable stochastic load. Erlang excels in handling message explosion and multiplexing – the generation of a cascade of messages out to individual users starting from a single event – a message cascade that can span hundreds of servers in a coherent way that maintains message delivery order. Erlang is the foundation for EMQ X MQTT distributed message broker for all major IoT protocols as well as M2M, NB-IoT and other mobile applications.To find out more about our partnership with EMQ and how it can help you, head here. Go back to the blog\n\nTags:emqscalabilityiotInternet of thingsShare  Facebook Twitter Linkedin E-mail", title: "The problem of connecting to Smart Meters was solved 30 years ago! Powered by scalable technology.", url: "https://www.erlang-solutions.com/blog/the-problem-of-connecting-to-smart-meters-was-solved-30-years-ago-powered-by-scalable-technology.html"}
%{author: "by Attila Nohl", text: "Using CircleCI for Continuous Integration of Elixir projects.2019-06-25\n        by Attila Nohl\n      Continuous integration is vital to ensure the quality of any software you ship. Circle CI is a great tool that provides effective continuous integration. In this blog, we will guide you through how to set up CircleCI for an Elixir project. We’ve set up the project on GitHub so you can follow along. In the project we will: Build the projectRun tests and check code coverageGenerate API documentationCheck formattingRun Dialyzer check.\nYou can follow the actual example here. Some inspiration for this blog post comes from this blog and this post. \nPrerequisites: For this project you will need an account on CircleCI and GitHub. You also need to connect the two accounts. Lastly, you will need Erlang/OTP and Elixir installed. Create an Elixir projectTo begin with, we need a project, for this demonstration we wanted to use the most trivial possible example, so we generated a classic ‘Hello World’ program.\n\nTo create the project, simply type the following into the shell:mix new hello_world\nWe also added a printout, because the generated constant-returning function can be optimised away and that will confuse the code coverage checking.Add code coverage metricCode coverage allows us to identify how much of the code is being executed during the testing. Once we know that, we can also understand what lines are not executed because these lines could be where bugs can hide undetected or that we have forgotten to write tests for. If those lines of code are unreachable or not used, they should obviously be removed. \nTo get this metric, I add the excoveralls package to our project (see here for details). Beware that even if you have 100% code coverage, it does not mean the code is bug-free. Here’s an example (inspired by this):defmodule Fact do\n\n  def fact(1), do: 1\n  def fact(n), do: n*fact(n-1)\nend\nIf the test executes Fact.fact(10), we get 100% test coverage, but the code is still faulty, it won’t terminate if the input is e.g. -1.\nFor a new project, it should be easy to keep the code coverage near 100%, especially if the developers follow test-driven principles. However, for a “legacy” or already established project without adequate test coverage, reaching 100% code coverage might be unreasonably expensive. In this case, we should still strive to increase (or at least not decrease) the code coverage.To run the tests with code coverage, execute:mix coveralls.html\nIn the project root directory (hello_world). Apart from the printout, a HTML report will be generated in the cover directory too.Add Dialyzer checkingDialyzer is a static analyzer tool for Erlang and Elixir code. It can detect type errors (e.g. when a function expects a list to be an argument, but is called with a tuple), unreachable code and other kinds of bugs. Although Elixir is a dynamically typed language, it is possible to add type specifications (specs) for function arguments, return values, structs, etc. The Elixir compiler does not check for this, but the generated API documentation uses the information and it is extremely useful for users of your code. \nAs a post-compilation step , you can run Dialyzer to check the type specifications in addition to writing unit-tests, you can regard this type checking as an early warning to detect incorrect input before you start debugging a unit-test or API client. To enable a Dialyzer check for  this code, I’ll use the Dialyzer mix task (see this commit for more details). \nDialyzer needs PLT (persistent lookup table) files to speed up its analysis. Generating this file for the Elixir and Erlang standard libraries takes time, even on fast hardware, so it is vital to reuse the PLT files between CI jobs.To run the dialyzer check, execute ‘mix dialyzer’ in the project root directory (hello_world). The output will be printed on the console. The first run (which generates the PLT file for the system and dependencies) might take a long time!Add documentation generationElixir provides support for written documentation. By default this docum" <> ..., title: "Using CircleCI for Continuous Integration of Elixir projects.", url: "https://www.erlang-solutions.com/blog/using-circleci-for-continuous-integration-of-elixir-projects.html"}
%{author: "by Francesco Cesarini", text: "Which companies are using Erlang, and why? #MyTopdogStatus2019-09-11\n        by Francesco Cesarini\n      Once upon a time, Cisco, Ericsson, Klarna, Goldman Sachs, T-Mobile, WhatsApp, Amazon and many other top companies kept a secret. Erlang was that badly kept secret. \nMany have heard of it, but few realise that it controls vast amounts of infrastructure, including the fixed and mobile networks we use on a daily basis. It was monumental when Cisco revealed that it ships 2 million devices per year running Erlang at the Code BEAM Stockholm conference in 2018. This translates to 90% of all internet traffic going through routers and switches controlled by Erlang. And have you heard about Ericsson? It has Erlang at the core of its GPRS, 3G, 4G and 5G infrastructure. With a market share of 40%, there’s a high probability a program written in Erlang assigned the IP address your smartphone is using today (amongst other things). Since being released as open source, Erlang has been spreading beyond Telecoms, establishing itself in other verticals such as FinTech, Gaming, Healthcare, Automotive, IoT and Blockchain. How can a technology created to switch phone calls make its way into these verticals? And why should you not only care but consider using it for your server-side development? Erlang and Elixir are the top dogs in any tech stack and it’s time we let more people and companies know about the BEAM technologies. We are kicking off with this first blog being part of the #MyTopdogStatus series, to showcase Erlang’s success stories. We will follow with the Elixir focus next- so you have the bigger picture of both technologies!A Solution to a ProblemOne of the first things I try to find out when I meet a programming language inventor is what problem were they trying to solve when creating the language. The range of answers is fascinating, and often reveals if it is -or is not- fit for purpose. Ask any of the co-inventors of Erlang and you will get a unanimous response. They were trying to understand how to better build the next generation of telecom systems, the only systems back in the late 90s which had to be scalable, fault-tolerant, predictable and maintainable. They never set off with the intention of inventing a programming language, but the solution to their problem happened to be just that. Programming languages successfully created to solve a problem are the ones to keep an eye out for, as they are, without a doubt, the right tool for the job. If the answer to why a language was invented is experimenting with esoteric computer science concepts, listen, learn, but beware.   At the time of Erlang’s conception, telecom systems were the only systems which had to be scalable, handle peak loads predictably and never fail. The internet changed it all. When Erlang was released as open source, telecom grade resilience and scale gave way to web-scale, which in turn gave way to mobile applications and connected devices, which, through the inception of 4G and 5G gave way to IoT. How was this transition possible, and why was it so seamless? If you are switching phone calls, SMSs, publish/subscribe, instant and mobile messages, credit card transactions, money, stocks, medical records, online gaming command sequences, blockchain propagation or telemetry data, the business logic is still the same. And whilst it might be ok to lose the odd SMS, or message, or for a device to be offline for hours and not transmit any data, it is absolutely not cool to lose a financial transaction which involves money, stocks or cryptocurrencies. Basically, what changes in all these systems are the tradeoffs in scalability, reliability and consistency of the data, all items which are programming language agnostic and taken care of in the business logic of the system. Everything else remains the same. There is no better example of Erlang’s reliability than the English National Health Service (NHS). The NHS obviously requires high availability and handles over 65 million record requests every day through its Spine, a centralised point allowing the exchange o" <> ..., title: "Which companies are using Erlang, and why? #MyTopdogStatus", url: "https://www.erlang-solutions.com/blog/which-companies-are-using-erlang-and-why-mytopdogstatus.html"}
%{author: "by Manuel Rubio", text: "Which companies are using Elixir, and why? #MyTopdogStatus2019-09-19\n        by Manuel Rubio\n      How do you choose the right programming language for a project? As a developer or a key-decision maker you could decide based on your personal preference, or what is fashionable at the time, but if you’re not considering real experiences and use cases, you may end up making a decision that becomes difficult to execute, expensive to complete and a nightmare to maintain. As Francesco mentioned in the Erlang blog of our #MyTopdogStatus series, you could start by asking why a language was created. This will help ensure that you’re choosing a language designed to fix a problem suited to your needs. On a number of occasions, José Valim has stated he wanted to give the power and productivity of Erlang to more developers. Another great tip for choosing a language is to look under the hood and see what powers it. For that, the previously mentioned Erlang blog gives you a great insight into  the OTP and Virtual Machine (VM) that helps make Elixir the powerful language that it is. Lastly, you can look at case studies to see how other companies have used the language, why they’ve chosen it, and what they were able to achieve. In practice, it’s not easy to find this information, as we still don’t know exactly how many companies use Elixir or their exact use case. Luckily, we can refer to www.elixir-companies.com or openly ask the community. You could even subscribe to the newsletter of Plataformatec who funded the initial creation of Elixir and always share fantastic stories about the language in use.  And we hope this blog post will be helpful too! Simply put, here is a checklist of common benefits that a company gets from using Elixir:Need to grow or scale - If you have a service that you expect to be used by millions, then you’ll benefit from the reliability and scalability of the BEAM VM.Handling a lot of incoming requests - Even if you don’t have millions of users, if all of your users make intense use of the system and generate a high volume of requests, you will need a system built for concurrency.Easy to develop and maintainable - One of the priorities of Erlang and Elixir is keeping the code simple. As a result, one of the advantages most companies will see is ease of usage and fast development for everything from fixing bugs to adding new features.Now, without further ado, let’s look at who’s using Elixir and how.Event handling by PinterestHave you heard that Pinterest are using Elixir? Well, now you have. They use it to handle the routing of the events generated in their system. Think about all of the actions taking place on Pinterest in a day. How many do you think there are? The answer is around 30 thousand events per second that need to be processed. In addition, they have over 200 million active users.Keep in mind, 20 years ago, it would have been impressive to achieve 10 thousand concurrent connections. Luckily, the way the BEAM works lets us handle and deal with huge spikes in concurrent connections in a way that would be very difficult to replicate in other technologies. Elixir is a good example of a language which takes advantage of the BEAM VM, which is why it was a great choice for Pinterest. Not only were they able to handle the demands of their users, but they were also able to significantly reduce the lines of code needed by simplifying it and clustering it. The end result being, they were able to half the number of servers needed, down to just 15, allowing their solution to scale up with simple, maintainable code and lower operating costs. And, it’s better for the environment too.Faster distributed data by Moz ProCompanies often look for alternatives to SQL for data storage. In the case of Moz Pro, one of the leading SEO analytics companies in the world, they decided to replace their traditional MySQL databases with a distributed indexing data system built in Elixir. In doing this, they managed to get responses of 50ms, significantly quicker than the previous +800ms. Elixir’s ability to be distributed in differe" <> ..., title: "Which companies are using Elixir, and why? #MyTopdogStatus", url: "https://www.erlang-solutions.com/blog/which-companies-are-using-elixir-and-why-mytopdogstatus.html"}
%{author: "by Oleg Tarasenko", text: "Web scraping with Elixir2019-09-20\n        by Oleg Tarasenko\n      IntroductionBusinesses are investing in data. The big data analytics market is expected to grow to $103 billion (USD) within the next five years. It’s easy to see why, with everyone of us on average generating 1.7 megabytes of data per second.  As the amount of data we create grows, so too does our ability to inherent, interpret and understand it. Taking enormous datasets and generating very specific findings are leading to fantastic progress in all areas of human knowledge, including science, marketing and machine learning. To do this correctly, we need to ask an important question, how do we prepare datasets that meet the needs of our specific research. When dealing with publicly available data on the web, the answer is web scraping. What is web scraping?Wikipedia defines web scraping as: Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites.[1] While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis. (See: https://en.wikipedia.org/wiki/Web_scraping).Web scraping with ElixirWeb scraping can be done differently in different languages, for the purposes of this article we’re going to show you how to do it in Elixir, for obvious reasons ;). \nSpecifically, we’re going to show you how to complete web scraping with an Elixir framework called Crawly.Crawly is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival. You can find out more about it on the documentation page.Getting startedFor the purposes of this demonstration, we will build a web scraper to extract the data from Erlang Solutions Blog. We will extract all the blog posts, so they can be analyzed later (let’s assume we’re planning to build some machine learning to identify the most useful articles and authors).First of all, we will create a new Elixir project:mix new esl_blog --sup\nNow that the project is created, modify the deps` function of the mix.exs file, so it looks like this:     #Run \"mix help deps\" to learn about dependencies.\n\n    defp deps do\n    [\n      {:crawly, \"~> 0.1\"},\n    ]\n  end\nFetch the dependencies with: mix deps.get, and we’re ready to go! So let’s define our crawling rules with the help of… spiders.The spider.Spiders are behaviours which you create an implementation, and which Crawly uses to extract information from a given website. The spider must implement the spider behaviour (it’s required to implement the parse_item/1, init/0`, `base_url/0 callbacks).\nThis is the code for our first spider. Save it in to file called  esl.ex under the lib/esl_blog/spiders directory of your project.defmodule Esl do\n  @behaviour Crawly.Spider\n\n  @impl Crawly.Spider\n  def base_url() do\n    \"https://www.erlang-solutions.com\"\n  end\n\n  @impl Crawly.Spider\n  def init() do\n    [\n      start_urls: [\"https://www.erlang-solutions.com/blog.html\"]\n    ]\n  end\n\n  @impl Crawly.Spider\n  def parse_item(_response) do\n    %Crawly.ParsedItem{:items => [], :requests => []}\n  end\nend\nHere’s a more detailed run down of the above code:base_url(): function which returns base_urls for the given Spider, used in order to filter out all irrelevant requests. In our case, we don’t want our crawler to follow links going to social media sites and other partner sites (which are not related to the crawled target).init(): must return a KW list which contains start_urls list which Crawler will begin to crawl from. Subsequent requests will be generated from these initial urls.parse_item(): function which will be called to handle response downloaded by Crawly. It must return the Crawly.ParsedItem structure.Crawling the websiteNow it’s time to run our first spider: Start" <> ..., title: "Web scraping with Elixir", url: "https://www.erlang-solutions.com/blog/web-scraping-with-elixir.html"}
%{author: "by Stuart Whitfield", text: "MyTopdogStatus by Stuart Whitfield 2019-10-02\n        by Stuart Whitfield \n      Meet Stuart Whitfield, the CEO here at Erlang Solutions.Stuart began working at Erlang Solutions in 2010 through a business partner of Francesco, the founder of the company. Before joining Erlang Solutions, he spent 20 years as a commercial lawyer and then as managing partner of a law firm. Stuart first joined the team as a part-time Commercial Director and then joined permanently as CEO in 2011. What is the most exciting thing about working with Erlang and Elixir developers? \nI like working with curious, problem-solving people who are always questioning how things work and how they could be made better. These are characteristics shared by good Erlang and Elixir developers. What is your greatest underdog achievement working at Erlang Solutions?\nPossibly my greatest ‘underdog’ achievement working at Erlang Solutions was working with the team to persuade Vocalink (now MasterCard Vocalink) to adopt at scale what was, at the time, seen as a fairly niche technology to create its new Immediate Payment Solution (“IPS”). IPS provides real-time bank-to-bank payments and is now live in Thailand, Singapore and New York with further deployments to come. What is the biggest success (Top Dog) story you’ve seen on the BEAM?\nBEAM-based technologies are silently underpinning so many parts of modern technical infrastructures, it’s hard to pick one particular success story: whether it’s the global 4G and 5G mobile telephony and data infrastructure; WhatsApp’s 1.5 billion users; RabbitMQ’s 30,000+ deployments; or the extensive use of Erlang and Elixir in the adtech, gaming, messaging, social media, IoT and FinTech spaces, these technologies are enabling businesses to reach unprecedented numbers of customers reliably and with very little downtime. What excites you about the future of Erlang and Elixir as programming languages?\nI’m less interested in their value as programming languages per se, more in the paradigm shift that the thinking behind them represents. By adopting this way of thinking about and designing systems, businesses can solve web-scale problems reliably and scalably using proven technologies and approaches. Businesses’ need for scale and resilience increases each year and Elixir and Erlang are able to meet these challenges.Which industries do you think would most benefit from working with the BEAM?\nFinTech, although any industry needing systems that are resilient and can scale predictably (i.e. fault-tolerant and reliable) will benefit from the use of BEAM-based technologies and their ways of thinking.What excites you about the future of Erlang Solutions?\nWe’ve only just scratched the surface in terms of the addressable market for BEAM-based technologies. We’re seeing growing adoption in various FinTech businesses, particularly those disrupting existing markets and ways of working, and the rapid prototyping capabilities of Elixir and Erlang lend themselves well to taking new products to market quickly.What is your favourite part of working at Erlang Solutions in general?\nThe variety of our customer base; the geographical spread of our offices and people and the passion everyone has for working with our chosen technology.Now let’s meet your dog, Lexi.Where did you get the inspiration for the name?\nWe had a litter of pups with her mum and kept her, as she was the cutest. I think one of our children named her. Why, I don’t know.What breed is she?\nYellow labrador. She’s 6 in September.What is your favourite way to spend a day with Lexi? \nWalking in the woods then wild swimming amongst the ducks and lilypads.Tell us one great story about you and your dog? \nHer two brothers live within 400m of our house, so we meet up with them regularly and each year on their birthday.MyTopdogStatus \nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack? \nWe’re " <> ..., title: "MyTopdogStatus by Stuart Whitfield ", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-stuart-whitfield.html"}
%{author: "by Phuong Van", text: "MyTopdogStatus by Phuong Van 2019-10-02\n        by Phuong Van \n      Meet Phuong Van, one of the talented developers in our Stockholm office.Phuong is an Erlang specialist who spent nearly three years working as a consultant on an Ericsson product before joining the Erlang Solutions team. After graduating, she had the opportunity to work in Java, C or Erlang and jumped at the chance to continue working with Erlang. How did you discover Erlang?\nI was studying in Gothenburg, Sweden, and in my first year, the first programming language we focused on was Java. In my second year, we did a functional programming course, and as part of that, we learned Erlang.What is your favourite part of working with Erlang?\nFrom the moment I was introduced to Erlang, I found it easier to use than Java which I’d previously learned. The exercises were fun, and I found myself really enjoying reading about Erlang. Making a function work is so much simpler in Erlang. You don’t have to spend as much time and energy defining the right object. Everything is straight forward. I also found all the concurrency exercises I struggled to complete with Java in the first year, were so much easier when I was working with Erlang. \nIn my first job, I was very focused on pattern matching in Erlang, and now I’m getting to explore other amazing parts of the ecosystem, such as working with the OTP library. The language is really versatile, and the libraries are powerful, which makes it fun to work with. Are there any Erlang trends that you are excited about?\nFinTech and Erlang seem to be an exciting trend. There are a lot of big banks and new neo-banks using Erlang in their tech stack. It’s exciting for Erlang because FinTech is such a huge, growing space, and it’s excellent for FinTech because Erlang is such an excellent fit for their needs. FinTech has a lot of the same requirements as the telecom industry, the need to handle a lot of processes, with high availability. The need to be scalable and fault-tolerant. That’s precisely what Erlang was built for. What is your favourite thing about working at Erlang Solutions? \nThe team structure is great for learning. We have monthly E-day’s where we can learn from each others experience which is excellent. There is so much knowledge within the team, I get to sit next to Robert Virding, so I can learn directly from one of the creators of the language, which is cool. Learning is always fun. And now introduce us to Abbe.Abbe is my parent’s dog, he’s a labrador, my step-father named him, his name had to start with an A because his mum’s name began with an A. He is such a spoilt child, my mum spoils him. He likes to bark at the wild cats that we feed in our feed garden, he tries to scare them away when my mum is around. But if the cats ever come up to him, he goes running away.What’s your favourite thing about Abbe?\nHe’s so funny and diplomatic. When I go to the countryside to visit my parents he tries to spread his time evenly between my parents and I. He will go into each room throughout the night to make sure he’s fair and visits us equally. It’s so cute. MyTopdogStatus \nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack? \nWe’re always looking for amazing talent to join our team, head to our careers page for open opportunities and apply to the one that suits you. Go back to the blog\n\nTags:teamstaff#MyTopdogStatusShare  Facebook Twitter Linkedin E-mail", title: "MyTopdogStatus by Phuong Van ", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-phuong-van.html"}
%{author: "by Simon Benitez", text: "MyTopdogStatus by Simon Benitez 2019-10-02\n        by Simon Benitez \n      Meet Simon, one of the talented developers from our team in The Americas.Simon is a highly experienced developer who spent seven years working with Ruby and JavaScript before coming over to the BEAM. How did you start working on the BEAM?\n\nI’d heard a lot about functional programming. I love building complex projects. I saw a fantastic demonstration at a conference and it looked like functional programming was the best way to do the kinds of projects I liked. I tried a number of other functional programming languages, but none of them felt right. When I found Erlang and Elixir, I just found my ‘happy place’. What’s your favourite part of working on the BEAM?\n\nWorking with the BEAM makes development more precise. I like coding with immutable data; it means you’re always thinking about how to transport your data into the format you need. It is a way of thinking that helps you focus on what you’re trying to deliver, what you need to do and how you need to do it. It also helps when you’re designing systems, because when you’re reading and writing a line of code, you don’t need to worry about other lines of code in the system changing its behaviour. \nThe end result is that you can build something that works every time, you know that what you’re building can handle spikes and loads, you don’t need to be nervous on days like Black Friday. What’s your biggest underdog success story working on the BEAM?\n\nI’m currently working on a project to hack network protocols, which has been really challenging. Because I come from a web-development background, I hadn’t had much experience in networking, but with the support of our team and the ease of the technology we use, I have been able to push myself and create something I am really proud of. What’s your favourite part of working at Erlang Solutions?\n\nI wanted to start working with Erlang and Elixir, and Erlang Solutions was one of the major companies working with the languages. I also love the open-source work Erlang Solutions does; it’s really cool to work with a company that puts its time and money where its mouth is and supports the open-source community.\n\nI get to work with big companies, like Toyota Connected. The nice thing about working with bigger projects is that you are always learning and growing. There are great managers and leadership, which helps make you a better developer. Working with smaller start-ups on front-end projects can feel like you are always doing the same basic tasks. With the projects I work on, they’re more complex, you need to meet unique challenges. What excites you most about the future of the BEAM?\n\nI think it would be great to see Erlang used to scale artificial intelligence projects. Erlang is perfect for scaling, and AI needs a lot of processing, with Erlang, you can process more data in less time. Are there any industries that you think could benefit from moving to the BEAM?\n\nAnyone using Java right now! Now let’s talk about your dogs, introduce us to them?\n\nI have three great dogs, Kiro, the Siberian Husky, Pluto, the Labrador cross and Jack, who is a rescue. What’s your favourite way to spend a day with them?\n\nI love taking them out to play with other dogs around the rivers and streams. What’s your favourite thing about your dogs?\n\nThey’ve all got such unique personalities. It’s kind of like having three dumb children. Pluto is the crazy one who just needs a lot of attention. Kiro is the oldest, so he’s kind of like the grumpy older brother, and Jack is a rescue, so he’s the shy one, but he’s really humble. MyTopdogStatus\n\nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack?\n\nWe’re always looking for amazing talent to join our team, head to our careers page for open opportunities and apply to the one that suits you. Go back to the blog\n\nTags:staffteam#MyTopdogStatu" <> ..., title: "MyTopdogStatus by Simon Benitez ", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-simon-benitez.html"}
%{author: "by Product Team", text: "MongooseIM: Designed with privacy in mind2019-10-09\n        by Product Team\n      Let’s face it. We are living in an age where all technology players gather and process huge piles of user data, starting from our behavioural patterns and finishing on our location data. Hence, we receive personalized emails from online retail stores we have visited for just a second or personalized ads of stores in our vicinity that are displayed in our social media streams. Consequently, more and more people become aware of how their privacy could be at risk with all of that data collection. In turn, the European Union strived to fight for consumer rights by implementing privacy guidelines in the form of the General Data Protection Regulation (GDPR), which governs how consumer data can be handled by third parties. In fact, over 200,000 privacy violation cases have been filed during the course of the last year followed with over €56m in fines for data breaches. Therefore, the stakes are high for all messaging service providers out there.You might wonder: “Why should this matter to me? After all, my company is not in Europe.” Well, if any of the users of your messaging service are located in the EU, you are affected by GDPR as if you would host your service right there. Feeling uneasy? Don’t worry, MongooseIM team has got you covered. Please welcome the new MongooseIM that brings us full GDPR compliance.Privacy by DesignA new concept has been defined with the dawn of GDPR - privacy by default. It is assumed that the software solution being used follows the principles of minimising and limiting, hiding and protecting, separating, aggregating, as well as, providing privacy by default.Minimise and limitThe minimise and limit principle regards the amount of personal data gathered by a service. The general principle here is to take only the bare minimum required for a service to run instead of saving unnecessary data just in case. If more data is taken out, the unnecessary part should be deleted. Luckily, MongooseIM is using only the bare minimum of personal data provided by the users and relies on the users themselves to provide more if they wish to - e.g. by filling out the roster information. Moreover, since it is implementing XMPP and is open source, everybody has an insight as to how the data is processed.Hide and protectThe hide and protect principle refers to the fact that user data should not be made public and should be hidden from plain view disallowing third parties to identify users through personal data or its interrelation. We have tackled that by handling the creation of JIDs and having recommendations regarding log collection and archiving.What is this all about? See, JIDs are the central and focal point of MongooseIM operation as they are user unique identifiers in the system. As long as the JID does not contain any personally identifiable information like a name or a telephone number, the JID is far more than pseudo-anonymous and cannot be linked to the individual it represents. This is why one should refrain from putting personally identifiable information in JIDs. For that reason, our release includes a mechanism that allows automatic user creation with random JIDs that you can invoke by typing ‘register’ in the console. Specific JIDs are created by intentionally invoking a different command (register_identified).Still, it is possible that MongooseIM logs contain personally identifiable information such as IP addresses that could correlate to JIDs. Even though the JID is anonymous, an IP address next to a JID might lead to the person behind it through correlation. That is why we recommend that installations with privacy in mind have their log level set to at least ‘warning’ level in order to avoid breaches of privacy while still maintaining log usability.  Separate and aggregateThe separate principle boils down to partitioning user data into chunks rather than keeping them in a monolithic DB. Each chunk should contain only the necessary private data for its own functioning. Such a separation creates issues when trying to iden" <> ..., title: "MongooseIM: Designed with privacy in mind", url: "https://www.erlang-solutions.com/blog/mongooseim-designed-with-privacy-in-mind.html"}
%{author: "by Bartłomiej Górny", text: "MyTopdogStatus by Bartłomiej Górny 2019-10-11\n        by Bartłomiej Górny \n      Meet Bartek, one of the talented developers working on MongooseIM.Bartek started his professional life as an economist but felt a lack of satisfaction in his work because there was nothing tangible to show for it at the end of the day. He moved into computer programming because it allowed him to build things with a finished end product. He originally started programming in Python; he then used Perl, C++ and Java.  When Bartek eventually found Erlang, he knew that it was the language he wanted to work with.  How did you start working on the beam?\n\nI was working on a complex project in Python; it was a real struggle. I found RabbitMQ, and it worked like a charm. The project got so much easier. So, I took a look under the hood of RabbitMQ and discovered Erlang. That was a lightbulb moment, I thought ‘bloody hell’ this is the language I should have been working with all along. I even went back and rewrote some of the old code in Erlang. What makes Erlang the top dog in the programming world?\n\nI think it is the most intuitive way to code, in that it matches a real-world mindset. The notion of a strict separation of concerns just makes sense. For example; one process does one thing, while another process does another. The way message passing happens in Erlang kind of acts the way a team would in the real world. What is your greatest achievement working at Erlang Solutions?\n\nTwo years ago, I noticed an opportunity for significant improvement in MongooseIM, but it required a major refactoring, it impacted nearly every line of code. Pure refactoring was really needed. Luckily, the team are supportive and want to make the best product. As a result, we were able to improve the product. What is the best thing about working at Erlang Solutions?\n\nYou get to work all over the world, I’ve worked in Russia, Bangladesh and India, just to name a few. Working with overseas teams is a real eye-opener; it makes you wiser. You get to make friends from all over the world. When you’re a tourist, you see the parts of a country that is designed for tourists, but when you’re working with people, you see what life in the country is really like. \nAlso, working on MongooseIM, in Erlang, we can make deep and advanced customisations in weeks, using a relatively small amount of code. That would be difficult to do at other companies or in any technologies. Now, tell us about your awesome dog Bonnie.\n\nMy dog Bonnie is a mixed breed, but she definitely looks like a Belgian Shepherd, only smaller. I got her from a shelter, and she’s just exceptional. She may look like a Belgian Shepherd, but she has the spirit of a Border Collie, she’s so fit and full of energy and a bit crazy. She’s a total workaholic; she never leaves you alone because she always wants to be chasing something, she tires me out sometimes. You can see all your crazy tricks and skills in the video below. We’re actually trying to get her into the Guinness Book of World Records in the next month. Watch this space. \nMyTopdogStatus \nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack? \nWe’re always looking for amazing talent to join our team, head to our careers page for open opportunities and apply to the one that suits you. Go back to the blog\n\nTags:staffteamMyTopdogStatusShare  Facebook Twitter Linkedin E-mail", title: "MyTopdogStatus by Bartłomiej Górny ", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-bartlomiej-gorny.html"}
%{author: "by Basia Trojecka", text: "MyTopdogStatus by Basia Trojecka 2019-10-11\n        by Basia Trojecka \n      Meet Basia, one of our hard working Conference CoordinatorsBasia began her career in cultural events. This included time at art galleries, youth culture centres and the Krakow Festival Office. Working for the Krakow Festival Office gave her a unique insight into the way organisations planned multiple overlapping events.  The office handled over 7 regular major festivals in the city, as well as festivities for public days such as Christmas, Easter and New Year’s Eve. She was able to work with over 200 events professionals who came together to put on an array of wonderful festivities. What are the differences between working in technology events and cultural events?\n\nThe audience is very different; technology audiences are more specific and have a much narrower focus. I think the most significant change is the exposure to different teams, different tools and new procedures. At an office like Krakow Festival Office, I specialised in a small part of running the event, but here I get to be more holistic. We have smaller teams, so we get exposure to almost everything, which is excellent. What’s your favourite thing about running events for Erlang and Elixir developers?\n\nThey’re an excited and passionate audience. The community has a real appetite for learning, and we help connect them with senior community figures and feed that appetite to upskill. It also feels like the Erlang and Elixir community put a huge effort towards supporting diversity which is nice to be part of. Why do you think Erlang Solutions is the top dog?\n\nIt’s always very rewarding to hear that people are happy with your events. I get to work with local partners and co-organisers to run extremely successful events. We’ve worked with some team who had never organised an event bigger than a Meetup. Through collaboration and planning, we’ve helped them run successful full-day conferences. What’s your favourite thing about working here?\n\nThe company culture is hugely employee focused. Staff happiness is clearly a priority of the company, and people have an active say in their role. The trust that the management team puts in us is tremendous and empowers us to do the best in our role. It’s rewarding to know that if I have an idea, the company will support me and help make it a reality. We have the freedom to create our own procedures, that work for us and deliver the best results. It also is a really family-friendly company too. For example, at our annual G2G get together events we are encouraged to bring our family with us.   On the subject of family, tell us about your dogs?I have two dogs, Franklin & Theodore; we adopted them both so we don’t know what breed they are. We got them from this really cool privately run shelter. The woman who runs it is a Police Officer, but she volunteers to run this shelter. She takes care of up to 30 dogs at a time and tries to find new homes for them. We’d been following her story and her shelter on social media when we decided to get a dog and eventually come across Franklin and really wanted him. He has a great personality; he’s so expressive, smart and energetic. \nA year later we decided we wanted to get him a friend, so we went back to the same shelter and picked Theodore. It was kind of sweet because they actually already knew each other. Theodore was at the shelter when Franklin was there, so they’d been at the shelter together. \nTheodore hasn’t had as much human interaction so he can still be pretty shy. He took a while to get used to his new home, but he’s doing so well now. It’s really rewarding to see him get more comfortable with us. MyTopdogStatus\n\nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack?\n\nWe’re always looking for amazing talent to join our team, head to our careers page for open opportunities and apply to the one that sui" <> ..., title: "MyTopdogStatus by Basia Trojecka ", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-basia-trojecka.html"}
%{author: "by Grigory Starinkin & Oleg Tarasenko", text: "How to build a machine learning project in Elixir. 2019-10-23\n        by Grigory Starinkin & Oleg Tarasenko\n      Introduction to machine learningMachine learning is an ever-growing area of interest for developers, businesses, tech enthusiasts and the general public alike. From agile start-ups to trendsetting industry leaders, businesses know that successful implementation of the right machine learning product could give them a substantial competitive advantage. We have already seen businesses reap significant benefits of machine learning in production through automated chat bots and customised shopping experiences.\n\nGiven we recently demonstrated how to complete web scraping in Elixir, we thought we’d take it one step further and show you to apply this in a machine learning project.The classic algorithmic approach VS machine learningThe traditional approach has always been algorithm centric. To do this, you need to design an efficient algorithm to fix edge cases and meet your data manipulation needs. The more complicated your dataset, the harder it becomes to cover all the angles, and at some point, an algorithm is no longer the best way to go. Luckily, machine learning offers an alternative. When you’re building a machine learning-based system, the goal is to find dependencies in your data. You need the right information to train the program to solve the questions it is likely to be asked. To provide the right information, incoming data is vital for the machine learning system. You need to provide adequate training datasets to achieve success. \nSo without further adieu, we’re going to provide an example tutorial for a machine learning project and show how we achieved success. Feel free to follow along. The project descriptionFor this project, we’re going to look at an ecommerce platform that offers real-time price comparisons and suggestions. The core functionality of any ecommerce machine learning project is to: Extract data from websites Process this data Provide intelligence and suggestions to the customer Variable step depending on actions and learnings Profit One of the most common problems is the need to group data in a consistent manner. For example, let’s say we want to unify the categories of products from all men’s fashion brands (so we can render all products within a given category, across multiple data sources). Each site (and therefore data source) will likely have inconsistent structures and names, these need to be unified and matched before we can run an accurate comparison. For the purpose of this guide, we will build a project which :Extracts the data from a group of websites (in this case we will demonstrate how to extract data from the harveynorman.ie shop)Train a neural network to recognise a product category from the product imageIntegrate the neural network into the Elixir code so it completes the image recognition and suggests products Build a web app which glues everything together.Extracting the dataAs we mentioned at the beginning, data is the cornerstone of any successful machine learning system. The key to success at this step is to extract real-world-data that is publicly available and then prepare it into training sets. For our example, we need to gather the basic information about the products (title, description, SKU and image URL etc). We will use the extracted images and their categories to perform the machine learning training. The quality of the trained neural network model is directly related to the quality of datasets you’re providing. So it’s important to make sure that the extracted data actually makes sense.We’re going to use a library called Crawly to perform the data extraction. Crawly is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival. You can find out more about it on the documentations page. Or you can visit our guide on how to complete web scraping in Elixir. Now that is explained, let’s get started! First of all, we wil" <> ..., title: "How to build a machine learning project in Elixir. ", url: "https://www.erlang-solutions.com/blog/how-to-build-a-machine-learning-project-in-elixir.html"}
%{author: "by Michał Piotrowski", text: "MyTopdogStatus by Michał Piotrowski2019-10-11\n        by Michał Piotrowski\n      Meet Michal one of the talented developers in our Krakow office.Michal has been working as a developer for over ten years. He started his career working in PHP in the education space for a subsidiary of the brainly.com, and it was there that he stumbled upon his love for Erlang. How did you start working on the BEAM?\n\nI was working on a project where we needed to have real-time experiences and notifications. Our education app wanted the functionality to have new questions deployed live. We decided the best way to handle it was to use an XMPP server to distribute the events and serve them to the connected users. That was the first time I came across Erlang. I realised it gave me the power to do things that I just couldn’t in PHP. I really enjoyed working with it and wanted to use it more. What makes Erlang the top dog in the programming world?\n\nThe philosophy of the BEAM VM offered me a way of programming that just wasn’t possible in PHP. I found the concurrency model especially fantastic, and it meant I could build more complex systems than I had been able to in the past. The clustering provided by the Erlang VM prevents you from having to create a custom solution every time. You can just connect BEAM nodes together and distribute the load. What is your greatest achievement working at Erlang Solutions?\n\nMongooseIM is able to scale to millions of concurrent users. The scalability of the platform is pretty much unparalleled, and it’s something that would be very difficult to achieve if it had been written in a language like Java. What is the best thing about working at Erlang Solutions?\n\nI get the opportunity to work on a variety of projects for different customers. Even within MongooseIM, there are still unique needs to every project and use-case. We have a great mix of experienced colleagues, which makes it easy to find advice, feedback and support when you need it. The entire team is always very supportive. It’s also a company that makes knowledge sharing a priority which is great because you get different perspectives, and you are introduced to new ideas that can be helpful at a later date. Now, tell us about your dog?\n\nSpark is a 6-year-old German Shepard; we wanted our dog to be smart and active, so my wife named him Spark to reflect that? And did the name work?\n\nHe is so smart, my wife trains him regularly, and he goes to group classes once a week, so he knows so many commands now.What’s his coolest trick?\n\nHe can do the downward dog, very zen.What’s your favourite way to spend time with Spark?\n\nWhen he was younger, I used to love to take him running. Now that I’ve gotten faster, he’s started to slow me down, so we don’t run together as often. He is still very fast though, we ran a race for dog and human teams, there were about 100 dog and human teams, and we came 7th. MyTopdogStatus\n\nDo you love Erlang, Elixir and dogs? Then don’t miss any of the action from #MyTopdogStatus. Head to our hub page for more profiles from the team, videos from the community and blogs about who is using Erlang and the companies using Elixir. Want to join the pack?\n\nWe’re always looking for amazing talent to join our team, head to our careers page for open opportunities and apply to the one that suits you. Go back to the blog\n\nTags:staffteamMyTopdogStatusShare  Facebook Twitter Linkedin E-mail", title: "MyTopdogStatus by Michał Piotrowski", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-michal-piotrowski.html"}
%{author: "by Szymon Mentel", text: "RabbitMQ Mirrored Queues Gotchas2019-10-25\n        by Szymon Mentel\n      Mirrored Queues are a popular RabbitMQ feature that provides High Availability (HA). HA, in this context simply means that RabbitMQ nodes in the cluster can fail and the queues will still be available for the clients.\n\nHowever, the HA queues can lead to some unexpected behaviour in failure scenarios or when combined with specific queue properties. In this blog post, we share three examples of these unpredictable behaviours that we have come across in RabbitMQ. \nThis blog will help us explain some of the intricacies of HA queues. In doing so, we’ll also demonstrate how one can analyze the behaviours of a RabbitMQ cluster on a laptop or a single machine using common tools. Thus the next chapter briefly discusses the requirements to do so and scripts in the assisting repository that allow us to test the presented cases.  SetupIf you want to reproduce the examples from the post you will need the following dependencies installed:  Make\nGit\nDocker\nPython3\nPipenv\nRabbitmq-perf-test 2.8.0\nWireshark (optional)    All the scenarios are based on a 2-node cluster consisting of RabbitMQ Docker containers - rmq1 and rmq2 - running Rabbit in version 3.7.15. Both containers expose ports 5672 (AMQP) and 15672 (management plugin) which are mapped to 5672/15672 and 5673/15673 for rmq1 and rmq2 respectively. In other words, once you set up the cluster, AMQP port for rmq1 is available at amqp://localhost:5672 and the management interface at http://localhost:15672.The cluster is started with make up and tore down with make down. The up command will start the containers, attach them to a rmq network and install the following policy: To see the logs run make logs1 to attach the output of the rmq1 container. \nAlso, Python scripts are in use, thus pipenv install and pipenv shell need to be run to install the Python dependencies and start a shell within the python virtualenv respectively. Auto-delete property for an HA queueA queue in RabbitMQ can have the auto-delete property set. A queue with this property will be deleted by the broker once the last consumer unsubscribes. But what does this mean in a distributed environment where consumers are connected to different nodes and queue slaves are promoted to masters on failure? \nLet’s explore this example by setting up an environment for testing. Run make up which will spawn and cluster the RabbitMQ containers. The command should finish with an output similar to the below: Cluster status of node rabbit@rmq1 ...  \n[{nodes,[{disc,[rabbit@rmq1,rabbit@rmq2]}]},  \n{running_nodes,[rabbit@rmq2,rabbit@rmq1]},  \n{cluster_name,<<\"rabbit@rmq1\">>},  \n{partitions,[]}, {alarms,[{rabbit@rmq2,[]},{rabbit@rmq1,[]}]}]  \nNow we want to create a Mirrored Queue with the master at node rmq2 and the slave at rmq1. The queue should have the auto-delete property set.  For this purpose, we will use the PerfTest tool that we will connect to the second node and make it act as a producer. It will create haq queue (which matches the policy), bind it to the direct exchange with the key routing key and start producing 1 message per second: # producer at rmq2\nperf_test/bin/runjava com.rabbitmq.perf.PerfTest \\\n--uri amqp://localhost:5673 \\\n--producers 1 \\\n--consumers 0 \\\n--rate 1 \\\n--queue haq \\\n--routing-key key \\\n--auto-delete true \nThroughout the example, we assume perf_test is installed in the ./perf_test directory. \nAs the producer is running, the queue should appear in the management UI and messages should be piling up:   Now let’s connect a consumer to our queue. Again, PerfTest will be our tool of choice but this time it will be used as a consumer attached to the first node (rmq1):  # consumer at rmq1 \nperf_test/bin/runjava com.rabbitmq.perf.PerfTest \\ --uri amqp://localhost:5672 \\\n--producers 0 \\ \n--consumers 1 \\ \n--queue haq \nThe perf_test output should reveal that the messages are flowing:   # consumer at rmq1  \nid: test-114434-950, time: 73.704s, received: 1.00 msg/s, min/median/75th/95th/99th consumer latency: 0/0/0/0/0 μs  \n# producer id: test-11" <> ..., title: "RabbitMQ Mirrored Queues Gotchas", url: "https://www.erlang-solutions.com/blog/rabbitmq-mirrored-queues-gotchas.html"}
%{author: "by John Baughen", text: "MyTopdogStatus by John Baughen2019-10-30\n        by John Baughen\n      Meet John Baughen, Conference Business Development Manager at Erlang Solutions.John has a rich array of experience in sponsorship and media sales. Before joining ESL, he worked at traditional media organisations and ran his own sponsorship company. His experience has allowed him to earn valuable experience, all over the world, which he shares with the team at ESL.   What is the most exciting thing about working with Erlang and Elixir developers?\n\nWe work with niche languages, so our development team often face hesitancies from companies who might prefer to work with a more mainstream technology. But, once companies see the tremendous benefits that Erlang and Elixir can offer there is no going back. We’re on the forefront of making scalable and fault tolerant systems commonplace.What is your proudest achievement working at Erlang Solutions?\n\nThe events team helps ESL build support and richen its relationship with the community. The work we do facilitates knowledge sharing that pushes the languages forward. Code Sync conferences help connect our company to ideas, talent and build relationships with other companies using the technology. What is the biggest success story you’ve seen on the BEAM?\n\nWhatsApp - it blows my mind every time you look at the figures. 450 million daily users, 65B daily messages sent and 2B minutes of calls. How is this possible.. by a little known programme language created by Ericsson over 20 years ago!What excites you about the future of Erlang and Elixir as programming languages?\n\nErlang has always been a closely guarded secret by some of the world’s tech giants and will continue to be adopted for anything that requires fault tolerance and scalability to billions of users. Elixir on the other hand, is the new kid on the block and is now openly used by more and more startups and enterprises as they simply need something that can scale and adapt as they grow.\nOne of the benefits that of Erlang & Elixir that we sometimes forget, is the way that adopting them can reduce the amount of physical infrastructure a company needs. Just look at Bleacher Report, they were able to go from 150 servers to 5. You can only imagine how environmentally and financially friendly that is. Which industries do you think would most benefit from working with the BEAM?\n\nFinTech, IoT, Gaming, Transport, Infrastructure and Machine Learning. There are also some very exciting developments with the car industry using intelligent systems from driverless cars to car sharing. The future of technology requires scalability, and so Erlang & Elixir will almost always be a good fit. What excites you about the future of Erlang Solutions?\n\nWe are a company that is prepared to adapt to face the challenges of the multicore era.What is your favourite part of working at Erlang Solutions in general?\n\nWorking with a great conference and marketing team within an industry that is welcoming to everyone without any agenda.Now let’s meet your dog, Ringo.Tell us about the inspiration for the name?\n\nLong story, I am a Beatles fan, but that wasn’t the reason.What are people’s reactions to the name?\n\nIt’s a cool dog name. What breed is he?\n\nBeagle Boxer, or otherwise known as a Bogle which sounds like something from Harry PotterWhat is your favourite way to spend a day with Ringo?\n\nOn the beach or long walks in the country followed by curling up on the sofa with a beer and a bone. (Beers for me)Tell us one great story about you and your dog?\n\nMost are too disgusting and usually involves him eating something he shouldn’t. But one less offensive tale… My wife likes to bake and one Christmas she had just baked 3 fruit cakes for our relatives. Ringo obviously felt left out so literally as soon as my wife turned her back he ate half from each in seconds. He was immediately rushed to the vet to have his stomach pumped. After the cakes were brought back up a vet nurse walked into the room and declared “oh what a beautiful smell of cake”.Anything else we should know about Ringo?\n\nHe seems to " <> ..., title: "MyTopdogStatus by John Baughen", url: "https://www.erlang-solutions.com/blog/mytopdogstatus-by-john-baughen.html"}
%{author: "by Tyr Chen, ArcBlock", text: "Why ArcBlock is using the BEAM to build their next-generation blockchain framework2019-11-05\n        by Tyr Chen, ArcBlock \n      Who are ArcBlock, and why do they love the BEAM?ArcBlock is on a mission to take the complexity out of blockchain and fast track its adoption into everyday life. To do this, they’ve developed an all-inclusive blockchain development platform \nthat gives developers everything they need  to build, run and deploy decentralized applications (dApps) easily. At the heart of their platform is the BEAM VM. They’re such big believers and supporters in the Erlang Ecosystem that they joined the Erlang Ecosystem foundation as a founding sponsor. In this guest blog Tyr Chen, VP of Engineering at ArcBlock, will discuss why they love the BEAM VM and the benefits of using it as a cornerstone for anyone wanting to build dApps.   An introduction to the BEAM and blockchainErlang is one of the best programming languages for building highly available, fault tolerant, and scalable soft real-time systems. The BEAM is the virtual machine - and the unsung hero from our viewpoint. The benefits of the BEAM apply to other languages run on the VM, including Elixir. No matter what high-level programming language people are using, it all comes down to the BEAM. It is this essential piece of technology that helps achieve the all-important nine-nines of availability.  Today, the BEAM powers more than half of the world’s internet routers and we don’t think you have to look much further than that for validation. Below are some of the benefits of the BEAM that make it perfect for building blockchains.  Network ConsensusOur decision to leverage the BEAM as a critical component for building decentralized applications (dApss) was an easy one. To start, blockchain and decentralized applications, need to achieve a consistent state across all the nodes in the network. We accomplish this by using a state replica engine (also known as a consensus engine). Consensus is important as this mechanism ensures that the information is added to a blockchain ledger is valid. To achieve consensus, the nodes on the network need to agree on the information, and once consensus happens, the data can be added to the ledger. There are multiple engines available, including our current platform choice, Tendermint, to support the state replica engine. The BEAM + dAppsApart from the consensus engine, the BEAM is the perfect solution to satisfy several other critical requirements for decentralized applications. For decentralized applications to work in our development framework, we need to have an embedded database to store the application state and an index database for the blockchain data. While this is happening, we also need the blockchain node(s) to have the ability to listen to peers on the network and “vote” for the next block of data. For these requirements, the system needs to be continuously responsive and available.  Now, it’s also important to note that in addition to being continually responsive, we also need to account for CPU-tasks. In particular, our blockchain platform and services cannot stop working when the system encounters CPU-intensive tasks. If the system becomes unresponsive, a potentially catastrophic error could occur. Hot Code ReloadingBesides BEAM’s Scheduler, another feature we love is hot code reloading. It lets you do virtually anything on the fly without ever needing to take the BEAM down. For example, our blockchain application platform ships with lots of different smart contracts that developers can use to make their decentralized applications feature-rich. However, with blockchain, you have a distributed network and need to ensure that every node behaves the same.  In most cases, developers have to update and reboot their nodes to get the latest software enabled, which causes potential issues and unnecessary downtime. With ArcBlock, we utilize the hot code reloading feature of BEAM to let the nodes enable/disable smart contracts on the fly across the entire network. This is simply done by sending a transaction that tells th" <> ..., title: "Why ArcBlock is using the BEAM to build their next-generation blockchain framework", url: "https://www.erlang-solutions.com/blog/why-arcblock-is-using-the-beam-to-build-their-next-generation-blockchain-framework.html"}
%{author: "by Kacper Mentel", text: "How to debug your RabbitMQ2019-11-07\n        by Kacper Mentel \n      What you will learn in this blog.Our RabbitMQ consultancy customers come from a wide range of industries. As a result, we have seen almost all of the unexpected behaviours that it can throw at you. RabbitMQ is a complex piece of software that employs concurrency and distributed computing (via Erlang), so debugging it is not always straightforward. To get to the root cause of an unexpected (and unwanted) behaviour, you need the right tools and the right methodology. In this article, we will demonstrate both to help you learn the craft of debugging in RabbitMQ.  The problem of debugging RabbitMQ.The inspiration for this blog comes from a real-life example. One of our customers had the RabbitMQ Management HTTP API serving crucial information to their system. The system relied on the API heavily, specifically on /api/queues endpoint because the system needed to know the number of messages ready in each queue in a RabbitMQ cluster. The problem was that sometimes a HTTP request to the endpoint lasted up to tens of seconds (in the worst case they weren’t even able to get a response from the API).\n\nSo what caused some requests to take so much time? To answer that question, we tried to reproduce the issue through load testing.    Running load testsWe use a platform that we created for MongooseIM to run our Continuous Load Testing. Here are some of the most important aspects of the platform:  all the services that are involved in a load test run inside docker containersthe load is generated by Amoc; it’s an open source tool written in Erlang for generating massively parallel loads of any kind (AMQP in our case) metrics from the system under test and Amoc site are collected for further analysis.\nThe diagram below depicts a logical architecture of an example load test with RabbitMQ:In the diagram, the left-hand side, shows a cluster of Amoc nodes that emulate AMQP clients which, in turn, generate the load against RabbitMQ. On the other side, we can see a RabbitMQ cluster that serves the AMQP clients. All the metrics from both the Amoc and RabbitMQ services are collected and stored in an InfluxDB database.    Slow Management HTTP API queriesWe tried to reproduce the slow queries to Management HTTP API in our load tests. The test scenario was fairly simple. A bunch of publishers were publishing messages to default exchange. Messages from each publisher were routed to a dedicated queue (each publisher had a dedicated queue). There were also consumers attached to each queue. Queue mirroring was enabled.\n\nFor concrete values, check the table below:   That setup stressed the Rabbit servers on our infrastructure. As seen in the graphs below:   Every RabbitMQ node consumed about 6 (out of 7) CPU cores and roughly 1.4GB of RAM except for rabbitmq-1 which consumed significantly more than the others. That was likely because it had to serve more of the Management HTTP API requests than the other two nodes.   During the load test /api/queues endpoint was queried every two seconds for the list of all queues together with corresponding messages_ready values. A query looked like this:   http://rabbitmq-1:15672/api/queues?columns=name,messages_readyHere are the results from the test:  The figure above shows the query time during a load test. It’s clear that things are very slow. The median equals 1.5s while the 95, 99, 999 percentiles and max reach 20s.    DebuggingOnce the issue is confirmed and can be reproduced, we are ready to start debugging. The first idea was to find the Erlang function that is called when a request to the RabbitMQ Management HTTP API comes in and determine where that function spends its execution time. If we were able to do this it would allow us to localise the most time expensive code behind the API.     Finding the entrypoint functionTo find the function we were looking for we took the following steps:  looked through the RabbitMQ Management Plugin to find the appropriate “HTTP path to function” mapping,used the Erlang tracing feature to verify if a foun" <> ..., title: "How to debug your RabbitMQ", url: "https://www.erlang-solutions.com/blog/how-to-debug-your-rabbitmq.html"}
%{author: "by Arzu Toren", text: "The big questions for enterprise blockchain. 2019-11-13\n        by Arzu Toren\n      Meet Arzu Toren, Finance Industry expert and banking academic.Arzu Toren is a Global Banker with 20 years of experience working in international and Turkish commercial banks in the areas of asset management, trade finance, debt instruments and business development.  She is currently continuing her independent research to drive value through the application of blockchain and for the blockchain ecosystem. In this blog, Arzu offers an up-to-date take on the key discussion points in the field of blockchain. Blockchain for good.Blockchain is a game-changing technology which is due to have fundamental impacts on enterprises as it can transform moving, storing, lending, exchanging value, funding, investing and managing risk. It is moving 3Ps – people, process and paperwork. In the digital era, data is power and blockchain is a universal bus to carry the data by ensuring its validity.Like every radical innovation, blockchain encapsulates hurdles for adoption and diffusion. It is complicated in legal, regulatory, financial and operational aspects and its challenges need technical, behavioural, educational and business solutions. Long-term adoption is due to take time with a gradual transition. The process is not linear, you learn along the way and reducing complexity is the key. Blockchain should not be considered as a magic stick but as one of the technologies that will be a part of the next-generation infrastructure and developed according to needs. Distributed ledger based on blockchain is a form of database; it will not make decisions for enterprises, they need to learn how to use it to create value. Blockchain is expanding and moves quickly in new businesses. Resistance, lack of education, issues of interoperability and scalability are the main reasons why it is moving slowly in some incumbent and large organizations. The ideal implementation steps of blockchain in enterprises are:choosing the right use caseselecting the right platformstarting small for testing purposesThe end-customer doesn’t need to know how blockchain works, they don’t even need to know the word ‘blockchain’. While technology-side is the enabler and business-side is the main driver, the primary focus should be on the use case and outcome.InteroperabilityBlockchain requires a solid legal foundation to allow for interoperability. Regulations are rules imposed by an authority representing the interests of the public while governance embodies a set of rules imposed by the participants of a system to protect their own interests. Blockchain faces major uncertainties in both fields. Internationally accepted regulations need to be developed and new principles need to be introduced in order to incorporate blockchain to the market infrastructure, comply with cross border & domestic guidelines and identify the legal ownership of documents. All these arrangements need careful engineering and take time. Blockchain is designed to support networks and requires cooperation to flourish. If the ecosystem is not connected, blockchain is not much of a use. Enterprises, innovators and regulators need to collaborate to make blockchain work in practice. In the case of consortiums, the answers to questions like ‘Who has jurisdiction when a network is spread over a large number of regions and companies?’ need to be clear. A blockchain would also need a governing body, which can be challenging when stakeholders have divergent interests. Moreover, industry alignment is required in major issues such as design and interaction principles. Scalability, Security & ResilienceTo make full use of blockchain, high standards are required for security, robustness, and performance. Resolving challenges such as network capacity, transaction speed, verification process and data limits would be critical. Without scalability, higher energy costs could eliminate the benefits of any blockchain. If the technology does not receive sufficient market scale, the shared benefits will be muted and there will only be a margi" <> ..., title: "The big questions for enterprise blockchain. ", url: "https://www.erlang-solutions.com/blog/the-big-questions-for-enterprise-blockchain.html"}
%{author: "by Shi Shu", text: "Erlang and Elixir for Blockchain - 4 key advantages2019-11-20\n        by Shi Shu \n      I first came to know Erlang/OTP through one of Joe Armstrong’s talks, where he broke down the world into processes that can talk to each other like humans. When I started at ArcBlock, we were tasked with building a blockchain platform, and we decided to use Erlang/OTP extensively for our backend services, as well as our blockchain framework - Forge. The reasons for that are described in this article, and because of the functions of OTP, we have been able to build a highly practical, production-ready blockchain framework that not only delivers critical services to run a blockchain network but greatly simplifies what is required for next-generation applications and services.  A Blockchain Framework PrimerForge is a tool that significantly simplifies the process of building a framework to support multi-chain networks or the concept of Build Your Own Chain (BYOC). Before Forge, it was challenging to build a chain. If people wanted to start their own blockchain, they would first need to set up different components of a blockchain system, including a consensus algorithm, p2p network, and the many other parts. After they went to the effort of making the components work together, they would need to decide how to adjust the different parameters of the blockchain, like total token supplies and distribution, specific transaction settings and admin access control. If they were lucky enough to get the blockchain running and found even the slightest thing wrong, they would need to stop all the running nodes go through the process of setting it again.   With Forge, we used the already available features and benefits of Erlang/OTP to deliver a framework that does all the hard work for the developer. For example, if you start a blockchain with Forge, the only requirement is to set the behaviours by enabling or disabling them in the configuration or at runtime. What’s more, if you want to update something when the chain has started, individual parts of the system can be hot-upgraded without rebooting the entire node — a critical feature for any product-grade application or service.   During the design and planning phase for our framework, we also evaluated other popular languages in the blockchain community, such as Golang. Golang has its benefits, including some pretty advanced libraries; however, to build the robust platform we wanted to deliver to our customers, there are three things that really pushed us towards Elixir.   Processes Simplify ProblemsFirst is the need to breakdown complicated problems into processes. Blockchain itself is a mixture of solutions to many problems, and OTP allows us to deconstruct and tackle them one by one. The flexibility of grouping different processes into applications also helps us to maintain our codebase.   For example, when a user needs to build a blockchain node, it’s a very similar process to building an operating system. We need to orchestrate a list of “applications” to work together for exchanging events (for example, transactions for a blockchain system), executing these events and then storing the updated states. To help everyone understand how this works, it is very easy to break down the structure into several core applications:  consensus application: processes that manage consensus related tasksstorage application: processes that manage file system related tasksForge application: processes that execute smart contract and support RPC interfaceevent application: processes that manage event subscription indexer application: processes that continuously pull data from states database and index them into a relational databaseWithin these applications,  Forge has some additional processes that collaborate to help process and handle the transactional activity for the blockchain. For example:   when a user sends a transaction, there is a gRPC server that will process it and push it to the queue of mempoolif the transaction is valid, it will be inserted into mempool, then flooded to the entire network; otherwis" <> ..., title: "Erlang and Elixir for Blockchain - 4 key advantages", url: "https://www.erlang-solutions.com/blog/erlang-and-elixir-for-blockchain-4-key-advantages.html"}
%{author: "by Michael Jaiyeola", text: "Fintech 2.0 Incumbents vs Challengers - Banking’s Battle Royale2019-11-28\n        by Michael Jaiyeola\n      The fundamental building blocks of finance and financial services (FS) are transforming driven by emerging technologies and changing societal, regulatory, industrial, commercial and economic demands. Fintech or financial technology is changing the FS industry via infrastructure-based technology and open APIs. The venue for last week’s World Fintech Forum was filled with fintechs from across the ecosystem and representatives from big banks. The agenda promised two days of talks that would cover the spectrum of discussion points that are occupying the industry and this blog post will look at the Top 10 Takeaways for those unable to attend the event.Key takeawaysGreat user experience is vitalThere’s a lot of regional variation in fintech disruptionMore challengers and incumbents are partneringBig Tech’s strength is in data Open Banking: regulations proving a boost to fintechsBlockchain: A dramatic increase in levels of investment For Cryptocurrencies - the jury’s still out AI is key Talent recruitment is one of the biggest challenges RegTech enables conforming with the changing regulatory landscape1. The customer really is kingConsumers and business customers alike have embraced the idea of on-demand finance, thanks to mobile and cloud computing. Fintech trends show that people are more comfortable managing their money and business online, and they’re less willing to put up with the comparatively slower and less flexible processes of traditional financial services. Present on day one of the conference was Laurence Krieger, COO of SME lender Tide, who views customer experience as the key advantage held by challengers. At Tide, they spotted the gap in SME banking where incumbents were simply offering the same type of products as those offered to retail customers but just repackaged as being for SMEs. Meanwhile, Filip Surowiak from ViaCash looked at how they are bridging the gap between cash and digital cash solutions by addressing the movement away from branch and ATM use to a more convenient model. It is these customer-centric approaches which will both win and retain business for fintechs and incumbents alike.  2. The West is moving at a different pace to AsiaWhile there are over 1,600 UK fintech companies, a figure set to double by 2030 according to the UK Government’s Tech Nation report, it’s emerging economies which lead the global charge in the sector. In the UK there is a 71 percent adoption of fintech while it’s 87 percent in both China and India.Chinese fintech ecosystems have scaled and innovated faster than their counterparts in the West. In Asia there are singular platforms or super apps which combine FS entertainment and lifestyle products, as yet the equivalent does not exist elsewhere.3. Partnerships are the favoured way to go for incumbents and fintechsDespite recent announcements such as of HSBC’s Kinetic platform and Bo from RBS, for banks to build their own digital solutions takes significant investment and resources with no guarantees of success. It also takes significant capital to acquire a successful competing fintech. Strategic investments and partnerships was the approach most favoured by the incumbents present at Fintech Forum. According to McKinsey’s report, Synergy and Disruption: Ten trends shaping fintech, 80 percent of financial institutions have entered fintech partnerships. Meanwhile, 82 percent expect to increase fintech partnerships in the next three to five years, according to a Department for International Trade report entitled UK FinTech State of the Nation.At the conference BNY Mellon, RBS, Citi Ventures and others were all present and positioning their organisation as being a willing and accessible partner for budding fintech startups. Luis Valdich, MD at Citi Ventures, spoke of their success stories with Pindrop Security and Trulioo and warned us all to avoid being pushed towards a focus on services instead of on the product in collaborations. Udita Banerjee from RBS and Christia" <> ..., title: "Fintech 2.0 Incumbents vs Challengers - Banking’s Battle Royale", url: "https://www.erlang-solutions.com/blog/fintech-2-0-incumbents-vs-challengers-banking-s-battle-royale.html"}
%{author: "by Erlang Solutions", text: "Erlang Highlights 2019 - Best Of The Beam. 2019-12-06\n        by Erlang Solutions \n      Despite being over 30 years old (and open source for 21), Erlang continues to be evolving, finding new industries to impact, fresh use cases and exciting stories. \nIn February 2019, the Erlang Ecosystem Foundation was announced at Code BEAM San Francisco. This group brings together a diverse community of BEAM users, including corporate and commercial interests, in the Erlang and Elixir Ecosystem. It encourages the continued development of technologies and open source projects based on/around the BEAM, its runtime and languages. This is an exciting step to ensure the ongoing success of the technologies we specialise in as their hashtag so aptly puts it, #weBEAMtogether.  Erlang’s own enigmatic standing in the developer community was best summed up by StackOverflow’s annual developer survey. This year Erlang was featured as one of the top 10 paid languages for developers. It also featured in all three of the most loved, dreaded and wanted technologies.  Throughout 2019, there have been many fantastic articles, guides, podcasts and talks given by members of the community showing off the capabilities of the technology. If you’re looking for inspiration, or want to see why a language that is over 30 years old is still provides some of the best paid jobs, check out these fantastic stories.  Top Erlang Resources 2019TalkConcurrencyWe were privileged to host a panel of industry legends including Sir Tony Hoare, Carl Hewitt and the late Joe Armstrong. What followed was an open discussion about the need for concurrency and how it is likely to evolve in the future. Carl Hewitt is the designer of logic programming language Planner, he is known for his work on evolving the actor model. Sir Tony Hoare developed the sorting algorithm Quicksort. He has been highly decorated for his work within Computer Science including six Honourary Doctorates and a Knighthood in the year 2000. Most in our community will be familiar with Joe Armstrong as being one of the inventors of Erlang, and someone whose work was highly influential to the field of concurrency. Each of our three guests are highly celebrated for their work and approaches to concurrency and impact it in their own way, whilst using different technologies. The wisdom that these three legends hold is clearly on show during the discussion. It is a truly must-watch talk for anyone with a passing interest in Erlang, Elixir and the BEAM.\nHow to introduce dialyser to a large projectDialyser is a fantastic tool to identify discrepancies and errors in Erlang code. Applying dialyser to a considerable codebase can lead to performance issues, particularly when you are working with a large codebase that has never been analysed with dialyser before. In this blog, Brujo Benavides demonstrates how the team at NextRoll were able to reduce discrepancies in the code by a third, in just a week while also setting up the system to be able to include dialyser in the ongoing development. \nRead the blog here.Five 9’s for five years at the UK’s National Health ServiceMartin Sumner joined the Elixir Talk podcast for a fantastic discussion of the work they’re doing at the NHS. Their centralised exchange point handles over 65 million record requests a day. Availability is vital due to the nature of medical information. Using Riak, they have managed to maintain 99.999% availability for over five years, an impressive effort. Listen to the podcast here.Saša Jurić shared the Soul of ErlangOne of the most shared and talked about conferences videos of 2019 was Sasa Juric’s ‘the soul of Erlang’ at GoTo Chicago 2019, and with good reason. It is an articulate, passionate summary of what makes Erlang so unique, and why it can achieve things that are so difficult in other technologies. Watch the video here.Who is using Erlang & why?When we launched our blog on the companies using Erlang and why we had no idea just how much it would resonate with the community. To date, there have been over 25,000 visits to the page. It was the top story" <> ..., title: "Erlang Highlights 2019 - Best Of The Beam. ", url: "https://www.erlang-solutions.com/blog/erlang-highlights-2019-best-of-the-beam.html"}
%{author: "by Erlang Solutions", text: "Elixir Highlights 2019 - Best Of The BEAM.2019-12-11\n        by Erlang Solutions\n      Elixir is a relatively young, but rapidly maturing technology. This year, new organisations discussing the use of Elixir in their tech stack (such as retail giants PepsiCo) showed the continued adoption of the language from a commercial perspective. Meanwhile, the emergence of Phoenix LiveView showed growth in the technologies capabilities. LiveView offers the promise of web applications without JavaScript for Elixir developers. Stack Overflow Developers Survey 2019 reflected the ongoing upward trajectory of the language, with Elixir featuring as one of the most popular languages, it was also one of the top 10 most loved languages, and listed as one of the best paid. 2019 felt like a turning point for closer collaboration between the Erlang and Elixir communities, with both languages benefitting from the development of The Erlang Ecosystem Foundation, and the Telemetry library. From Machine Learning to IoT and connected devices, there were also a vast array of impressive examples of Elixir being used in some of the biggest growth sectors in technology. As these areas continue to grow and shape development, it is both exciting and important that we develop and share in-production examples of how the fault-tolerance, reliability and developer community of Elixir can provide ideal solutions. With so many great conference talks, webinars, guides and podcasts shared throughout the year, it is understandable that you may have missed some. To help inspire you and spread the stories worth sharing, we’ve curated our Best Of The BEAM 2019 list for Elixir. Top Elixir Resources 2019Phoenix LiveView ReleaseThe release of Phoenix LiveView was a game-changer in late 2018, and it continued to be a largely influential story this year. Chris McCord showed off how Elixir Developers can build real-time, interactive web apps without JavaScript using Phoenix LiveView at ElixirConf EU. He also joined the team at Elixir Talk podcast twice over the course of the year in episode 140 and episode 157 to discuss the library. Tetris in Phoenix LiveViewOne fantastically fun example of Phoenix LiveView in action is this version of Tetris. It’s fully playable and looks great. We’ve got Sandesh who developed this game as our first webinar guest in 2020. He’ll be doing a live coding demonstration of a new and improved version of the game. You can register for the webinar here.Who is using ElixirFrom Pinterest to PepsiCo, we took a look at some of the biggest names using Elixir in their tech stack. The article offers a high-level explanation of who is using Elixir, what features they are using and the results they are getting. With companies in travel, online gaming and FinTech, it is clear to see the broad scope of companies that can benefit from Elixir. Read the blog here.TelemetryThe Telemetry library is an open source interface for telemetry data. It aims to unify and standardise how libraries and applications on the BEAM are instrumented and monitored. The project was developed by Arkadiusz Gil, representing Erlang Solutions, in conjunction with the Elixir core team and is continually being evolved by an active and passionate community. You can find Telemetry on GitHub and read more about it on our blog announcing its release.Machine learningMachine learning can help businesses obtain a substantial competitive advantage by reducing operating costs, building business insights and improving conversion rates. In an eCommerce environment, machine learning can lead to a significant improvement in ROI. Our team used their experience building a machine learning platform to develop this helpful guide. You can learn how Elixir can be used for machine learning at our blog.Elixir makes you a better programmerAs we mentioned in the introduction, Elixir was amongst the best-paid technologies for developers in 2019, according to StackOverflow’s developer survey. Learning Erlang and Elixir is valuable for many reasons, one of which is that it will give you a fresh perspective that" <> ..., title: "Elixir Highlights 2019 - Best Of The BEAM.", url: "https://www.erlang-solutions.com/blog/elixir-highlights-2019-best-of-the-beam.html"}
%{author: "by Erlang Solutions", text: "FinTech Highlights 2019 - Best Of The BEAM2019-12-19\n        by Erlang Solutions\n         In 2019 we’ve been delighted to begin relationships with several global financial services leaders on some mission-critical projects that are powered by Erlang, Elixir and BEAM VM technology. Although the specifics of the work are under strict NDAs, we have outlined some of the projects in this article along with those ubiquitous end-of year musings on the broader FinTech ecosystem. You’re also invited to visit our industry hub page for more info on our experience in building scalable, reliable systems for the FinTech industry.    Our 2019 FinTech projectsUniversal multichannel bank-insurerThis firm focuses on private clients and SMEs in Northern Europe and South-East Asia.  We supported the building of a mobile app which uses the highly scalable message server powered by XMPP, MongooseIM, as one of its core components. Major African based financial services groupThe Erlang-based message broker software using AMQP and MQTT, RabbitMQ, is used here for various business applications to implement critical banking operations around offers of personal and business banking, credit cards, corporate and investment banking and wealth and investment management. We reviewed the existing RabbitMQ architecture and suggested performance enhancements to deliver high availability on a Kubernetes platform in a new data centre.US financial services organisationThis financial service firm combines traditional banking services with the offerings of a technology company to provide a comprehensive suite of products in a banking-as-a-platform solution, encompassing lending, payments and risk management. We came onboard to review the existing RabbitMQ architecture and code and to advise on a scaleup strategy to take the bank to the next level.To keep up to date with all that we’re doing in the FinTech space involving building scalable, fault-tolerant systems you should subscribe for updates here.   What else has been happening in the FinTech space? \n\nGlobal FinTech investment trends remain strong following on from a record year in 2018 (fuelled by Ant Financial’s massive $14bn deal in China). According to Innovate Finance’s report ‘A Fine Year for Fintech’, investment levels in the first eight months of 2019 were strong – with just under $17bn raised from more than 1,000 deals. According to the EY Global FinTech Index 2019 - there is a 71% UK adoption of FinTech while it’s 87% in both China and India and 46% in the US. The UK Government’s 2019 ‘UK FinTech - State of the Nation’ report, found of the 89,000 finance and insurance firms in the UK, there are over 1,600 UK FinTech companies, a figure set to double by 2030.   World FinTech ForumIn November we attended the World Fintech Forum in London. Global operators form throughout the FinTech ecosystem came together to debate important and, at times, controversial topics. You can read our blog post on the 10 Key Takeaways from the conference, we’d be happy to hear your thoughts on any of the topics covered.Barclays Rise appearance - building scalable systemsRise is a global community of the world’s top innovators working together to create the future of financial services. We visited them earlier this year to discuss how startups could future proof their applications via building distributed, massively scalable and fault-tolerant systems with high availability.Dominic Perini, our Scalability Architect and Technical Lead, was presenting and you can view his presentation slides for How to Build Systems that Scale on our LinkedIn channel.We’ll be returning to host another technical session on scalable systems for FinTech startups at Rise during the new year, stay in touch and make sure you’re the first to hear about it.Working with FinTech AllianceThis new online portal for the global FinTech community connects the UK to a worldwide ecosystem in partnership with the UK Government. Fintech Alliance provides a multifaceted digital engagement platform to bring the global FinTech ecosystem together to explore, engage" <> ..., title: "FinTech Highlights 2019 - Best Of The BEAM", url: "https://www.erlang-solutions.com/blog/fintech-highlights-2019-best-of-the-beam.html"}
%{author: "by Erlang Solutions", text: "RabbitMQ Highlights 2019 - Best Of The BEAM2019-12-20\n        by Erlang Solutions\n      RabbitMQ is arguably the most popular open source message broker for large commercial enterprises. Every day, tens of thousands of companies, many of which are household names, rely on RabbitMQ to handle their message passing and microservices. In 2019, it was named as the seventh-highest paying tech skill according to Dice’s tech salary report. It is a finding that reflects the size and scope of the companies using RabbitMQ, as well as the importance of the technology to their tech stack.\n\nTo make sure you head into 2020 up-to-date with all the latest trends and resources in the world of RabbitMQ, we’ve prepared our highlights from 2019, including stories of releases, conference talks and use case blogs.     RabbitMQ Highlights 2019   RabbitMQ 3.8The release of RabbitMQ 3.8. was widely anticipated and has received great feedback from the community. The highlights from the release include:\nQuorum queues - which provides an alternative to mirrored queues for achieving high availability.\nFeature flags - which allows RabbitMQ nodes with different versions to communicate and act cohesively despite the differences in versions.\nPrometheus integration - RabbitMQ 3.8 ships with built-in Prometheus integration which enables easy access to monitoring for metrics such as run-time and the state of nodes running on the system. \nYou can read full details on the release at the official RabbitMQ blog.       Scaling financial applications at BloombergThere are few bigger names in the finance world than Bloomberg. Their many engineering teams right around the world access a fully-managed RabbitMQ platform. In their talk at this year’s RabbitMQ summit, Will Hoy and David Liu demonstrated how they have built a system that scales to handle billions of financial data requests every day. Watch the talk here.   API Fortress - distributed software architectureSimone Pezzano, CTO of API Fortress was kind enough to give the world an insight into the way in which they’ve used the actor-model to power a microservices-based massively distributed software architecture. This is an incredibly deep-dive complete with oversized schemas to demonstrate the digital symphony that is their architecture. Read the blog to find out more.   Debugging RabbitMQOur RabbitMQ team helps customers from a wide variety of industries, this exposes them to almost all of the unexpected behaviours that one may come across on the platform. Kacper Mentel shared his experience to provide a valuable resource into how to identify the causes of wanted behaviour so that you can improve the performance of your RabbitMQ. Read the blog here.   Moving legacy RabbitMQ applications to the cloudAs serverless environments increasingly become the norm, the challenge of moving legacy RabbitMQ applications to the cloud becomes more and more common. This blog provides one solution that could prove to be a handy resource. Learn more here.   Innovative design patterns in RabbitMQAyanda Dube is a highly respected RabbitMQ consultant and trainer. He delivered his talk at Code BEAM STO to a standing room only crowd. The talk dissects some of the unorthodox Erlang design patterns of RabbitMQ, which are some of the most creative internal design patterns in the Erlang Ecosystem. This is a great talk to help understand what happens under the hood of RabbitMQ. Watch the talk here.   Comparing EMQx to RabbitMQGrigory Starinkin works on both RabbitMQ and EMQx projects at Erlang Solutions. In his talk at this year’s RabbitMQ summit, Grigory compared the two MQTT message brokers, giving a detailed summary of their strengths, weaknesses and the kinds of applications each is suited for. Watch the talk here.   SummaryRabbitMQ 3.8 was an exciting release that empowers developers with a new option for achieving high availability and new reporting metrics. These features, as well as the Pivotal enterprise offering, which is in development, will fuel the continued growth and adoption in 2020. In 2020, there will be not one but t" <> ..., title: "RabbitMQ Highlights 2019 - Best Of The BEAM", url: "https://www.erlang-solutions.com/blog/rabbitmq-highlights-2019-best-of-the-beam.html"}
